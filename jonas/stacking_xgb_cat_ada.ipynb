{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for the custom stacking model, using catboost an LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import pandas as pd \n",
    "%store -r dm\n",
    "\n",
    "dm = dm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our model \n",
    "\n",
    "We are training two models in parallel, then we are training a model on the weighted sum of the predictions of the two other models. \n",
    "\n",
    "catboost -> catboost_preds\n",
    "adaBoost -> adaboost_preds\n",
    "\n",
    "-> randomforest -> final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [I 2023-10-08 00:40:41,291] Trial 21 finished with value: 0.9862843295936936 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.10931167365445349, 'colsample_bylevel': 0.09963123954233088, 'max_depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 21 with value: 0.9862843295936936.\n",
    "\n",
    "cat_A = CatBoostRegressor(objective=\"MultiRMSE\", learning_rate=10931167365445349, colsample_bylevel=0.09963123954233088, max_depth=15, boosting_type=\"Plain\", bootstrap_type=\"MVS\")\n",
    "ada_A = AdaBoostRegressor()\n",
    "xgb_A = XGBRegressor()\n",
    "\n",
    "cat_B = CatBoostRegressor(objective=\"MultiRMSE\", learning_rate=10931167365445349, colsample_bylevel=0.09963123954233088, max_depth=15, boosting_type=\"Plain\", bootstrap_type=\"MVS\")\n",
    "ada_B = AdaBoostRegressor()\n",
    "xgb_B = XGBRegressor()\n",
    "\n",
    "cat_C = CatBoostRegressor(objective=\"MultiRMSE\", learning_rate=10931167365445349, colsample_bylevel=0.09963123954233088, max_depth=15, boosting_type=\"Plain\", bootstrap_type=\"MVS\")\n",
    "ada_C = AdaBoostRegressor()\n",
    "xgb_C = XGBRegressor()\n",
    "\n",
    "forest_A = RandomForestRegressor()\n",
    "forest_B = RandomForestRegressor()\n",
    "forest_C = RandomForestRegressor()\n",
    "\n",
    "\n",
    "estimators = [\n",
    "    (\"cat\", CatBoostRegressor(objective=\"MultiRMSE\", learning_rate=0.10931167365445349, colsample_bylevel=0.09963123954233088, max_depth=15, boosting_type=\"Plain\", bootstrap_type=\"MVS\")),\n",
    "    (\"xbg\", XGBRegressor()),\n",
    "    (\"ada\", AdaBoostRegressor())\n",
    "]\n",
    "\n",
    "reg_A = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor()\n",
    ")\n",
    "\n",
    "reg_B = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor()\n",
    ")\n",
    "\n",
    "reg_C = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data\n",
    "\n",
    "X_A = dm.data_A.iloc[:,2:-1] #independent columns\n",
    "y_A = dm.data_A.iloc[:,0]   #target column i.e pv measurement\n",
    "\n",
    "X_B = dm.data_B.iloc[:,2:-1] #independent columns\n",
    "y_B = dm.data_B.iloc[:,0]    #target column i.e pv measurement\n",
    "\n",
    "X_C = dm.data_C.iloc[:,2:-1] #independent columns\n",
    "y_C = dm.data_C.iloc[:,0]   #target column i.e pv measurement\n",
    "\n",
    "\n",
    "X_A_train, X_A_test, y_A_train, y_A_test = train_test_split(X_A, y_A)\n",
    "X_B_train, X_B_test, y_B_train, y_B_test = train_test_split(X_B, y_B)\n",
    "X_C_train, X_C_test, y_C_train, y_C_test = train_test_split(X_C, y_C)\n",
    "\n",
    "X_test_A = dm.X_test_estimated_a[dm.X_test_estimated_a.columns.intersection(X_A_train.columns)]\n",
    "X_test_B = dm.X_test_estimated_b[X_B_train.columns.intersection(dm.X_test_estimated_b.columns)]\n",
    "X_test_C = dm.X_test_estimated_c[X_C_train.columns.intersection(dm.X_test_estimated_c.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-07 23:54:19,415] A new study created in memory with name: no-name-e4ff9a2a-e99c-4ab3-b100-19503ae4a445\n",
      "Best trial: 0. Best value: 0.667628:   0%|          | 1/200 [01:06<3:42:01, 66.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-07 23:55:26,362] Trial 0 finished with value: 0.6676280346526495 and parameters: {'objective': 'MAE', 'learning_rate': 0.0035054867842904654, 'colsample_bylevel': 0.059479504906839134, 'max_depth': 1, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.93124545991672}. Best is trial 0 with value: 0.6676280346526495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.853601:   1%|          | 2/200 [01:59<3:12:28, 58.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-07 23:56:18,655] Trial 1 finished with value: 0.853601414723894 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.003635882536866051, 'colsample_bylevel': 0.03979924292192242, 'max_depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6458755467814817}. Best is trial 1 with value: 0.853601414723894.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.853601:   2%|▏         | 3/200 [03:06<3:24:46, 62.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-07 23:57:25,830] Trial 2 finished with value: 0.7099762449813387 and parameters: {'objective': 'MAE', 'learning_rate': 0.003982000460450549, 'colsample_bylevel': 0.019308623043597293, 'max_depth': 11, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 1 with value: 0.853601414723894.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.853601:   2%|▏         | 4/200 [04:29<3:49:51, 70.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-07 23:58:48,452] Trial 3 finished with value: 0.826399279407149 and parameters: {'objective': 'MAE', 'learning_rate': 0.002870761427327919, 'colsample_bylevel': 0.05512461826445632, 'max_depth': 7, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.609487137496304}. Best is trial 1 with value: 0.853601414723894.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.853601:   2%|▎         | 5/200 [05:14<3:19:20, 61.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-07 23:59:33,777] Trial 4 finished with value: 0.8340634783990233 and parameters: {'objective': 'MAE', 'learning_rate': 0.0024292929074243336, 'colsample_bylevel': 0.06904641638582049, 'max_depth': 6, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.19431704375599732}. Best is trial 1 with value: 0.853601414723894.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 5. Best value: 0.864068:   3%|▎         | 6/200 [16:03<14:05:00, 261.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:10:23,374] Trial 5 finished with value: 0.8640680266080638 and parameters: {'objective': 'MAE', 'learning_rate': 0.0026840787307424864, 'colsample_bylevel': 0.07215057860246354, 'max_depth': 15, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.37689611592109}. Best is trial 5 with value: 0.8640680266080638.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.970462:   4%|▎         | 7/200 [16:40<10:03:47, 187.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:10:59,471] Trial 6 finished with value: 0.9704618465860364 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.08624492006536619, 'colsample_bylevel': 0.09475985185895697, 'max_depth': 8, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5099297822966387}. Best is trial 6 with value: 0.9704618465860364.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.970462:   4%|▍         | 8/200 [17:38<7:48:49, 146.51s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:11:57,771] Trial 7 finished with value: 0.8922755298757569 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.021377193950269376, 'colsample_bylevel': 0.09535746806501581, 'max_depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3506913256350602}. Best is trial 6 with value: 0.9704618465860364.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.970462:   4%|▍         | 9/200 [19:19<7:01:20, 132.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:13:39,021] Trial 8 finished with value: 0.9594073924058611 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.025849443712435936, 'colsample_bylevel': 0.06640020109768738, 'max_depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 6 with value: 0.9704618465860364.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 6. Best value: 0.970462:   5%|▌         | 10/200 [20:26<5:55:13, 112.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:14:45,995] Trial 9 finished with value: 0.8269023481171818 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.0010966548084566648, 'colsample_bylevel': 0.0944391889643105, 'max_depth': 4, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 8.335566291100328}. Best is trial 6 with value: 0.9704618465860364.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 10. Best value: 0.980766:   6%|▌         | 11/200 [21:08<4:45:17, 90.57s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:15:27,580] Trial 10 finished with value: 0.9807663708241661 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.15465951326479635, 'colsample_bylevel': 0.0834413738682415, 'max_depth': 10, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9602811486963978}. Best is trial 10 with value: 0.9807663708241661.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.982357:   6%|▌         | 12/200 [22:01<4:08:01, 79.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:16:20,628] Trial 11 finished with value: 0.9823567966071528 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.17524389746586597, 'colsample_bylevel': 0.08594637881193697, 'max_depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9982233559478759}. Best is trial 11 with value: 0.9823567966071528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.982357:   6%|▋         | 13/200 [22:49<3:37:56, 69.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:17:09,320] Trial 12 finished with value: 0.9811316186225559 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.22567648831456744, 'colsample_bylevel': 0.0815715636207689, 'max_depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9798457634905741}. Best is trial 11 with value: 0.9823567966071528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.982357:   7%|▋         | 14/200 [24:08<3:44:32, 72.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:18:27,539] Trial 13 finished with value: 0.9817328535250294 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.2817791232752512, 'colsample_bylevel': 0.07800444007555962, 'max_depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9352398714725687}. Best is trial 11 with value: 0.9823567966071528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.982357:   8%|▊         | 15/200 [25:30<3:52:57, 75.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:19:50,328] Trial 14 finished with value: 0.9821995997690764 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.27897153166188177, 'colsample_bylevel': 0.08087398817193063, 'max_depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7997210624595146}. Best is trial 11 with value: 0.9823567966071528.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.986072:   8%|▊         | 16/200 [27:56<4:56:40, 96.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:22:16,272] Trial 15 finished with value: 0.9860722927874278 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.08510017570275764, 'colsample_bylevel': 0.09997278260045005, 'max_depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7779095038163446}. Best is trial 15 with value: 0.9860722927874278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.986072:   8%|▊         | 17/200 [30:25<5:42:26, 112.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:24:44,672] Trial 16 finished with value: 0.9856396074746052 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.07134434766466158, 'colsample_bylevel': 0.09969576429420006, 'max_depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9860722927874278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.986072:   9%|▉         | 18/200 [32:49<6:10:07, 122.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:27:09,370] Trial 17 finished with value: 0.9847666528842852 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.05889189075680605, 'colsample_bylevel': 0.09859514422418575, 'max_depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9860722927874278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.986072:  10%|▉         | 19/200 [33:12<4:38:12, 92.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:27:32,193] Trial 18 finished with value: 0.9161162805341986 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.052492271187599984, 'colsample_bylevel': 0.045494976307166736, 'max_depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9860722927874278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.986072:  10%|█         | 20/200 [36:27<6:09:00, 123.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:30:46,930] Trial 19 finished with value: 0.9852957300994807 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.10130999367497383, 'colsample_bylevel': 0.08916088643231418, 'max_depth': 14, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9860722927874278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 15. Best value: 0.986072:  10%|█         | 21/200 [38:22<5:59:53, 120.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:32:42,044] Trial 20 finished with value: 0.9796028192705675 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.03377418800104841, 'colsample_bylevel': 0.08962732530734048, 'max_depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 15 with value: 0.9860722927874278.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.986284:  11%|█         | 22/200 [46:21<11:17:10, 228.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:40:41,291] Trial 21 finished with value: 0.9862843295936936 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.10931167365445349, 'colsample_bylevel': 0.09963123954233088, 'max_depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 21 with value: 0.9862843295936936.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.986284:  12%|█▏        | 23/200 [54:25<14:59:09, 304.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 00:48:44,612] Trial 22 finished with value: 0.985865981305033 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.10975787042596942, 'colsample_bylevel': 0.09904111311137576, 'max_depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 21 with value: 0.9862843295936936.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 21. Best value: 0.986284:  12%|█▏        | 23/200 [1:01:06<7:50:18, 159.42s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2023-10-08 00:55:26,187] Trial 23 failed with parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.15597396081675063, 'colsample_bylevel': 0.09998914418344669, 'max_depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'} because of the following error: KeyboardInterrupt('').\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/r_/m51x_wn949x1s34wqwqf6hkr0000gn/T/ipykernel_19308/2526846710.py\", line 37, in objective\n",
      "    gbm.fit(X_A_train, y_A_train, eval_set = [(X_A_test, y_A_test)], verbose = 0, early_stopping_rounds = 100)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/catboost/core.py\", line 5703, in fit\n",
      "    return self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/catboost/core.py\", line 2319, in _fit\n",
      "    self._train(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/catboost/core.py\", line 1723, in _train\n",
      "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
      "  File \"_catboost.pyx\", line 4645, in _catboost._CatBoost._train\n",
      "  File \"_catboost.pyx\", line 4694, in _catboost._CatBoost._train\n",
      "KeyboardInterrupt\n",
      "[W 2023-10-08 00:55:26,191] Trial 23 failed with value None.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/group_project/custom_stacking.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X34sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X34sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X34sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m, show_progress_bar \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     _optimize(\n\u001b[1;32m    443\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    444\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    445\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    446\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    447\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    448\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    449\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    450\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    451\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    452\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/group_project/custom_stacking.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X34sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     param[\u001b[39m\"\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39msuggest_uniform(\u001b[39m\"\u001b[39m\u001b[39msubsample\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X34sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m gbm \u001b[39m=\u001b[39m catboost\u001b[39m.\u001b[39mCatBoostRegressor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparam, iterations \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X34sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m gbm\u001b[39m.\u001b[39;49mfit(X_A_train, y_A_train, eval_set \u001b[39m=\u001b[39;49m [(X_A_test, y_A_test)], verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m, early_stopping_rounds \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X34sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m accuracy \u001b[39m=\u001b[39m gbm\u001b[39m.\u001b[39mscore(X_A_test, y_A_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X34sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/catboost/core.py:5703\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5701\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[1;32m   5704\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[1;32m   5705\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5706\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/catboost/core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[1;32m   2320\u001b[0m         train_pool,\n\u001b[1;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   2322\u001b[0m         params,\n\u001b[1;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[1;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m   2325\u001b[0m     )\n\u001b[1;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/catboost/core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import catboost\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "def accuracy_score(truth, predictions): \n",
    "    e = np.abs(truth - predictions)\n",
    "\n",
    "    n = e.shape[0]\n",
    "\n",
    "    return e.sum() / n\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "\n",
    "    #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"MultiRMSE\", \"MAE\"]),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 0.001, 0.3),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 15),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
    "    }\n",
    "    \n",
    "\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_uniform(\"subsample\", 0.1, 1)\n",
    "\n",
    "    gbm = catboost.CatBoostRegressor(**param, iterations = 10000)\n",
    "\n",
    "    gbm.fit(X_A_train, y_A_train, eval_set = [(X_A_test, y_A_test)], verbose = 0, early_stopping_rounds = 100)\n",
    "\n",
    "    accuracy = gbm.score(X_A_test, y_A_test)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction = \"maximize\")\n",
    "study.optimize(objective, n_trials = 200, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "/Users/zomb-ml-platform-msk/go-agent-21.2.0/pipelines/BuildMaster/catboost.git/catboost/private/libs/options/json_helper.h:173: Can't parse parameter \"learning_rate\" with value: 10931167365445349",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/group_project/custom_stacking.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# [I 2023-10-08 00:22:16,272] Trial 15 finished with value: 0.9860722927874278 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.08510017570275764, 'colsample_bylevel': 0.09997278260045005, 'max_depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7779095038163446}. Best is trial 15 with value: 0.9860722927874278.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# [I 2023-10-08 00:10:23,374] Trial 5 finished with value: 0.8640680266080638 and parameters: {'objective': 'MAE', 'learning_rate': 0.0026840787307424864, 'colsample_bylevel': 0.07215057860246354, 'max_depth': 15, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.37689611592109}. Best is trial 5 with value: 0.8640680266080638.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# [I 2023-10-08 00:40:41,291] Trial 21 finished with value: 0.9862843295936936 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.10931167365445349, 'colsample_bylevel': 0.09963123954233088, 'max_depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 21 with value: 0.9862843295936936.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# ----------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X22sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m reg_A\u001b[39m.\u001b[39;49mfit(X_A_train, y_A_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X22sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m reg_B\u001b[39m.\u001b[39mfit(X_B_train, y_B_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/group_project/custom_stacking.ipynb#X22sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m reg_C\u001b[39m.\u001b[39mfit(X_C_train, y_C_train)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:957\u001b[0m, in \u001b[0;36mStackingRegressor.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \n\u001b[1;32m    937\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m \u001b[39m    Returns a fitted instance.\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    956\u001b[0m y \u001b[39m=\u001b[39m column_or_1d(y, warn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 957\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_stacking.py:210\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mappend(estimator)\n\u001b[1;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[39m# Fit the base estimators on the whole training data. Those\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     \u001b[39m# base estimators will be used in transform, predict, and\u001b[39;00m\n\u001b[1;32m    209\u001b[0m     \u001b[39m# predict_proba. They are exposed publicly.\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    211\u001b[0m         delayed(_fit_single_estimator)(clone(est), X, y, sample_weight)\n\u001b[1;32m    212\u001b[0m         \u001b[39mfor\u001b[39;49;00m est \u001b[39min\u001b[39;49;00m all_estimators\n\u001b[1;32m    213\u001b[0m         \u001b[39mif\u001b[39;49;00m est \u001b[39m!=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdrop\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    214\u001b[0m     )\n\u001b[1;32m    216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnamed_estimators_ \u001b[39m=\u001b[39m Bunch()\n\u001b[1;32m    217\u001b[0m est_fitted_idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_base.py:46\u001b[0m, in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m---> 46\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[1;32m     47\u001b[0m \u001b[39mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/catboost/core.py:5703\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[1;32m   5701\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m-> 5703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[1;32m   5704\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[1;32m   5705\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[1;32m   5706\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/catboost/core.py:2303\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2300\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, PATH_TYPES \u001b[39m+\u001b[39m (Pool,)):\n\u001b[1;32m   2301\u001b[0m     \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2303\u001b[0m train_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_train_params(\n\u001b[1;32m   2304\u001b[0m     X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, cat_features\u001b[39m=\u001b[39;49mcat_features, text_features\u001b[39m=\u001b[39;49mtext_features, embedding_features\u001b[39m=\u001b[39;49membedding_features,\n\u001b[1;32m   2305\u001b[0m     pairs\u001b[39m=\u001b[39;49mpairs, sample_weight\u001b[39m=\u001b[39;49msample_weight, group_id\u001b[39m=\u001b[39;49mgroup_id, group_weight\u001b[39m=\u001b[39;49mgroup_weight,\n\u001b[1;32m   2306\u001b[0m     subgroup_id\u001b[39m=\u001b[39;49msubgroup_id, pairs_weight\u001b[39m=\u001b[39;49mpairs_weight, baseline\u001b[39m=\u001b[39;49mbaseline, use_best_model\u001b[39m=\u001b[39;49muse_best_model,\n\u001b[1;32m   2307\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set, verbose\u001b[39m=\u001b[39;49mverbose, logging_level\u001b[39m=\u001b[39;49mlogging_level, plot\u001b[39m=\u001b[39;49mplot, plot_file\u001b[39m=\u001b[39;49mplot_file,\n\u001b[1;32m   2308\u001b[0m     column_description\u001b[39m=\u001b[39;49mcolumn_description, verbose_eval\u001b[39m=\u001b[39;49mverbose_eval, metric_period\u001b[39m=\u001b[39;49mmetric_period,\n\u001b[1;32m   2309\u001b[0m     silent\u001b[39m=\u001b[39;49msilent, early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds, save_snapshot\u001b[39m=\u001b[39;49msave_snapshot,\n\u001b[1;32m   2310\u001b[0m     snapshot_file\u001b[39m=\u001b[39;49msnapshot_file, snapshot_interval\u001b[39m=\u001b[39;49msnapshot_interval, init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[1;32m   2311\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[1;32m   2312\u001b[0m )\n\u001b[1;32m   2313\u001b[0m params \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2314\u001b[0m train_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mtrain_pool\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/catboost/core.py:2230\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2228\u001b[0m _check_param_types(params)\n\u001b[1;32m   2229\u001b[0m params \u001b[39m=\u001b[39m _params_type_cast(params)\n\u001b[0;32m-> 2230\u001b[0m _check_train_params(params)\n\u001b[1;32m   2232\u001b[0m \u001b[39mif\u001b[39;00m params\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39meval_fraction\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.0\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[1;32m   2233\u001b[0m     \u001b[39mif\u001b[39;00m eval_set \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m_catboost.pyx:6105\u001b[0m, in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:6124\u001b[0m, in \u001b[0;36m_catboost._check_train_params\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: /Users/zomb-ml-platform-msk/go-agent-21.2.0/pipelines/BuildMaster/catboost.git/catboost/private/libs/options/json_helper.h:173: Can't parse parameter \"learning_rate\" with value: 10931167365445349"
     ]
    }
   ],
   "source": [
    "# [I 2023-10-08 00:22:16,272] Trial 15 finished with value: 0.9860722927874278 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.08510017570275764, 'colsample_bylevel': 0.09997278260045005, 'max_depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7779095038163446}. Best is trial 15 with value: 0.9860722927874278.\n",
    "# [I 2023-10-08 00:10:23,374] Trial 5 finished with value: 0.8640680266080638 and parameters: {'objective': 'MAE', 'learning_rate': 0.0026840787307424864, 'colsample_bylevel': 0.07215057860246354, 'max_depth': 15, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.37689611592109}. Best is trial 5 with value: 0.8640680266080638.\n",
    "# [I 2023-10-08 00:40:41,291] Trial 21 finished with value: 0.9862843295936936 and parameters: {'objective': 'MultiRMSE', 'learning_rate': 0.10931167365445349, 'colsample_bylevel': 0.09963123954233088, 'max_depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 21 with value: 0.9862843295936936.\n",
    "\n",
    "\n",
    "# cat_A.fit(X_A_train, y_A_train)\n",
    "# cat_B.fit(X_B_train, y_B_train)\n",
    "# cat_C.fit(X_C_train, y_C_train)\n",
    "# # cat.fit(X_B_train, y_B_train)\n",
    "# # cat.fit(X_C_train, y_C_train)\n",
    "\n",
    "# ada_A.fit(X_A_train, y_A_train)\n",
    "# ada_B.fit(X_B_train, y_B_train)\n",
    "# ada_C.fit(X_C_train, y_C_train)\n",
    "# # ada.fit(X_B_train, y_B_train)\n",
    "# # ada.fit(X_C_train, y_C_train)\n",
    "\n",
    "# xgb_A.fit(X_A_train, y_A_train)\n",
    "# xgb_B.fit(X_B_train, y_B_train)\n",
    "# xgb_C.fit(X_C_train, y_C_train)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------\n",
    "\n",
    "reg_A.fit(X_A_train, y_A_train)\n",
    "reg_B.fit(X_B_train, y_B_train)\n",
    "reg_C.fit(X_C_train, y_C_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_preds_A = cat_A.predict(X_A_test)\n",
    "ada_preds_A = ada_A.predict(X_A_test)\n",
    "xgb_preds_A = xgb_A.predict(X_A_test)\n",
    "\n",
    "cat_preds_B = cat_B.predict(X_B_test)\n",
    "ada_preds_B = ada_B.predict(X_B_test)\n",
    "xgb_preds_B = xgb_B.predict(X_B_test)\n",
    "\n",
    "cat_preds_C = cat_C.predict(X_C_test)\n",
    "ada_preds_C = ada_C.predict(X_C_test)\n",
    "xgb_preds_C = xgb_C.predict(X_C_test)\n",
    "\n",
    "\n",
    "\n",
    "cat_A_df = pd.DataFrame(data=cat_preds_A, columns=[\"pv_preds\"])\n",
    "ada_A_df = pd.DataFrame(data=ada_preds_A, columns=[\"pv_preds\"])\n",
    "xgb_A_df = pd.DataFrame(data=xgb_preds_A, columns=[\"pv_preds\"])\n",
    "\n",
    "cat_B_df = pd.DataFrame(data=cat_preds_B, columns=[\"pv_preds\"])\n",
    "ada_B_df = pd.DataFrame(data=ada_preds_B, columns=[\"pv_preds\"])\n",
    "xgb_B_df = pd.DataFrame(data=xgb_preds_B, columns=[\"pv_preds\"])\n",
    "\n",
    "cat_C_df = pd.DataFrame(data=cat_preds_C, columns=[\"pv_preds\"])\n",
    "ada_C_df = pd.DataFrame(data=ada_preds_C, columns=[\"pv_preds\"])\n",
    "xgb_C_df = pd.DataFrame(data=xgb_preds_C, columns=[\"pv_preds\"])\n",
    "\n",
    "df_A = (cat_A_df + ada_A_df + xgb_A_df) / 3\n",
    "df_B = (cat_B_df + ada_B_df + xgb_B_df) / 3\n",
    "df_C = (cat_C_df + ada_C_df + xgb_C_df) / 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_A_train_forest, X_A_test_forest, y_A_train_forest, y_A_test_forest = train_test_split(df_A, y_A_test)\n",
    "X_B_train_forest, X_B_test_forest, y_B_train_forest, y_B_test_forest = train_test_split(df_B, y_B_test)\n",
    "X_C_train_forest, X_C_test_forest, y_C_train_forest, y_C_test_forest = train_test_split(df_C, y_C_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_A.fit(X_A_train_forest, y_A_train_forest)\n",
    "forest_B.fit(X_B_train_forest, y_B_train_forest)\n",
    "forest_C.fit(X_C_train_forest, y_C_train_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8851480412089952\n",
      "0.8470164858320357\n",
      "0.9095269377802983\n"
     ]
    }
   ],
   "source": [
    "final_score_A = forest_A.score(X_A_test_forest, y_A_test_forest)\n",
    "final_score_B = forest_B.score(X_B_test_forest, y_B_test_forest)\n",
    "final_score_C = forest_C.score(X_C_test_forest, y_C_test_forest)\n",
    "\n",
    "print(final_score_A)\n",
    "print(final_score_B)\n",
    "print(final_score_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.48095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163.75425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>681.61445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>59.77510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>25.05370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>0.01225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction\n",
       "0        0.00000\n",
       "1        0.00000\n",
       "2       14.48095\n",
       "3      163.75425\n",
       "4      681.61445\n",
       "...          ...\n",
       "2155    59.77510\n",
       "2156    25.05370\n",
       "2157     0.00000\n",
       "2158     0.00000\n",
       "2159     0.01225\n",
       "\n",
       "[2160 rows x 1 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Specify the model to be used\n",
    "\n",
    "cat_preds_A = cat_A.predict(X_test_A)\n",
    "ada_preds_A = ada_A.predict(X_test_A)\n",
    "xgb_preds_A = xgb_A.predict(X_test_A)\n",
    "\n",
    "cat_preds_B = cat_B.predict(X_test_B)\n",
    "ada_preds_B = ada_B.predict(X_test_B)\n",
    "xgb_preds_B = xgb_B.predict(X_test_B)\n",
    "\n",
    "cat_preds_C = cat_C.predict(X_test_C)\n",
    "ada_preds_C = ada_C.predict(X_test_C)\n",
    "xgb_preds_C = xgb_C.predict(X_test_C)\n",
    "\n",
    "cat_A_df = pd.DataFrame(data=cat_preds_A, columns=[\"pv_preds\"])\n",
    "ada_A_df = pd.DataFrame(data=ada_preds_A, columns=[\"pv_preds\"])\n",
    "xgb_A_df = pd.DataFrame(data=xgb_preds_A, columns=[\"pv_preds\"])\n",
    "\n",
    "cat_B_df = pd.DataFrame(data=cat_preds_B, columns=[\"pv_preds\"])\n",
    "ada_B_df = pd.DataFrame(data=ada_preds_B, columns=[\"pv_preds\"])\n",
    "xgb_B_df = pd.DataFrame(data=xgb_preds_B, columns=[\"pv_preds\"])\n",
    "\n",
    "cat_C_df = pd.DataFrame(data=cat_preds_C, columns=[\"pv_preds\"])\n",
    "ada_C_df = pd.DataFrame(data=ada_preds_C, columns=[\"pv_preds\"])\n",
    "xgb_C_df = pd.DataFrame(data=xgb_preds_C, columns=[\"pv_preds\"])\n",
    "\n",
    "df_A = (cat_A_df + ada_A_df + xgb_A_df) / 3\n",
    "df_B = (cat_B_df + ada_B_df + xgb_B_df) / 3\n",
    "df_C = (cat_C_df + ada_C_df + xgb_C_df) / 3\n",
    "\n",
    "pred_A = forest_A.predict(df_A)\n",
    "pred_B = forest_B.predict(df_B)\n",
    "pred_C = forest_C.predict(df_C)\n",
    "\n",
    "df_A = pd.DataFrame()\n",
    "\n",
    "df_A[\"prediction\"] = pred_A\n",
    "df_A[\"location\"] = \"A\"\n",
    "\n",
    "df_B = pd.DataFrame()\n",
    "\n",
    "df_B[\"prediction\"] = pred_B\n",
    "df_B[\"location\"] = \"B\"\n",
    "\n",
    "df_C = pd.DataFrame()\n",
    "\n",
    "df_C[\"prediction\"] = pred_C\n",
    "df_C[\"location\"] = \"C\"\n",
    "\n",
    "df_mid = pd.concat([df_A, df_B], ignore_index=True)\n",
    "\n",
    "df = pd.concat([df_mid, df_C], join=\"inner\", ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "df = df.drop(\"location\", axis=1)\n",
    "\n",
    "\n",
    "# df[\"id\"] = test[\"id\"]\n",
    "\n",
    "# df = df[[\"id\", \"prediction\"]]\n",
    "\n",
    "#df[df<0] = 0\n",
    "\n",
    "# NAME THE FILE \n",
    "df.to_csv(\"sub20.csv\")\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
