{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from tensorflow.keras.initializers import GlorotNormal\n",
    "import random\n",
    "import optuna\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function\n",
    "\n",
    "def plot_feature(dataset:pd.DataFrame, featureName:str):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "    dataset[['date_forecast', featureName]].set_index(\"date_forecast\").plot(ax=axs, title=featureName, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data, combine and sort\n",
    "\n",
    "data_test_A = pd.read_csv(\"current_csv_files/data_test_A.csv\", index_col='Unnamed: 0')\n",
    "data_test_B = pd.read_csv(\"current_csv_files/data_test_B.csv\", index_col='Unnamed: 0')\n",
    "data_test_C = pd.read_csv(\"current_csv_files/data_test_C.csv\", index_col='Unnamed: 0')\n",
    "\n",
    "data_test_ALL = pd.concat([data_test_A, data_test_B, data_test_C], ignore_index=True)\n",
    "data_test_ALL = data_test_ALL.sort_values(['date_forecast', 'A', 'B', 'C'], ascending=[True, False, False, False])\n",
    "#data_test_ALL = data_test_ALL.set_index('date_forecast')\n",
    "data_test_ALL.rename(columns={'pv_measurement': 'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\n",
    "data_ALL = data_test_ALL[data_test_ALL['train'] == 1]\n",
    "test_ALL = data_test_ALL[data_test_ALL['train'] == 0].drop('target', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data_ALL.drop('target', axis='columns')\n",
    "y = data_ALL[['date_forecast', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "def split_data(df, percent):\n",
    "    split_index = int( np.floor( len(df)*percent ) )\n",
    "    df_first = df[:split_index]\n",
    "    df_last = df[split_index:]\n",
    "    return df_first, df_last\n",
    "\n",
    "train_percent = 0.94 # Of all\n",
    "val_percent = 0.5 # Of non-train\n",
    "\n",
    "X_train, X_non_train = split_data(X, train_percent)\n",
    "X_val, X_test = split_data(X_non_train, val_percent)\n",
    "\n",
    "y_train, y_non_train = split_data(y, train_percent)\n",
    "y_val, y_test = split_data(y_non_train, val_percent)\n",
    "\n",
    "X_kaggle = test_ALL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/3628176894.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y['date_forecast'] = pd.to_datetime(y['date_forecast'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nX_train = X.loc[~mask_X]\\ny_train = y.loc[~mask_y]\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample DataFrame creation.\n",
    "# Assuming df is your original DataFrame and 'date' is the column with dates.\n",
    "# df = pd.DataFrame({'date': pd.date_range(start='2022-01-01', periods=100, freq='D'), 'data': range(100)})\n",
    "\n",
    "# Make sure 'date' column is datetime type\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "X['date_forecast'] = pd.to_datetime(X['date_forecast'])\n",
    "y['date_forecast'] = pd.to_datetime(y['date_forecast'])\n",
    "\n",
    "# Define your date range\n",
    "start_date = \"2022-04-01 00:00:00\"\n",
    "end_date = \"2022-08-03 23:00:00\"\n",
    "\n",
    "# Convert strings to datetime\n",
    "start_date = pd.to_datetime(start_date)\n",
    "end_date = pd.to_datetime(end_date)\n",
    "\n",
    "# Filter rows within the date range\n",
    "mask_X = (X['date_forecast'] >= start_date) & (X['date_forecast'] <= end_date)\n",
    "mask_y = (y['date_forecast'] >= start_date) & (y['date_forecast'] <= end_date)\n",
    "X_val = X.loc[mask_X]\n",
    "y_val = y.loc[mask_y]\n",
    "\n",
    "# Pop out rows within the date range if you want to remove them from the original df\n",
    "\"\"\"\n",
    "X_train = X.loc[~mask_X]\n",
    "y_train = y.loc[~mask_y]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X_test_kaggle, best sub on kaggle, sort properly (hell)\n",
    "\n",
    "test_ALL_to_sub = pd.read_csv(\"current_csv_files/test_ALL.csv\")\n",
    "test_ALL_to_sub_ABC = test_ALL_to_sub.sort_values(['A', 'B', 'C', 'date_forecast'], ascending=[False, False, False, True])\n",
    "y_hat_kaggle = pd.read_csv(\"teo_subs/kaggle_149.csv\", index_col='id')\n",
    "test_ALL_to_sub_ABC['new_index'] = range(2160)\n",
    "test_ALL_to_sub_ABC = test_ALL_to_sub_ABC.set_index('new_index')\n",
    "test_ALL_to_sub_ABC['y_hat_kaggle'] = y_hat_kaggle\n",
    "test_ALL_to_sub_sorted = test_ALL_to_sub_ABC.sort_values(['date_forecast', 'A', 'B', 'C'], ascending=[True, False, False, False])\n",
    "test_ALL_to_sub_sorted = test_ALL_to_sub_sorted.set_index('date_forecast')\n",
    "y_hat = test_ALL_to_sub_sorted['y_hat_kaggle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by summer months\n",
    "\n",
    "y = y[ X['date_forecast'].dt.month.between(4, 7) ]\n",
    "X = X[ X['date_forecast'].dt.month.between(4, 7) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/2066373975.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop('date_forecast', axis='columns', inplace=True)\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/2066373975.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y_test.drop('date_forecast', axis='columns', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X.drop('date_forecast', axis='columns', inplace=True)\n",
    "y.drop('date_forecast', axis='columns', inplace=True)\n",
    "\n",
    "X_train.drop('date_forecast', axis='columns', inplace=True)\n",
    "y_train.drop('date_forecast', axis='columns', inplace=True)\n",
    "\n",
    "X_non_train.drop('date_forecast', axis='columns', inplace=True)\n",
    "y_non_train.drop('date_forecast', axis='columns', inplace=True)\n",
    "\n",
    "X_val.drop('date_forecast', axis='columns', inplace=True)\n",
    "y_val.drop('date_forecast', axis='columns', inplace=True)\n",
    "\n",
    "X_test.drop('date_forecast', axis='columns', inplace=True)\n",
    "y_test.drop('date_forecast', axis='columns', inplace=True)\n",
    "\n",
    "X_kaggle.drop('date_forecast', axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for scaling\n",
    "\n",
    "feature_dont_touch = [\n",
    "    'date_forecast',\n",
    "    'is_day:idx',\n",
    "    'is_in_shadow:idx',\n",
    "    'pv_measurement',\n",
    "    'est',\n",
    "    'train',\n",
    "    'A',\n",
    "    'B',\n",
    "    'C',\n",
    "    'precip_type_0',\n",
    "    'precip_type_1',\n",
    "    'daily_sinus',\n",
    "    'annual_sinus',\n",
    "    'bad_cloud_data',\n",
    "    'open_sky'\n",
    "]\n",
    "\n",
    "feature_to_standardize = [\n",
    "    'absolute_humidity_2m:gm3',\n",
    "    'air_density_2m:kgm3',\n",
    "    'dew_point_2m:K',\n",
    "    'pressure_100m:hPa',\n",
    "    'relative_humidity_1000hPa:p',\n",
    "    't_1000hPa:K',\n",
    "    'wind_speed_u_10m:ms',\n",
    "    'wind_speed_v_10m:ms',\n",
    "    #'clear_sky_rad_CD', # Central difference\n",
    "\n",
    "    # Kinda useless\n",
    "    #'pressure_50m:hPa',\n",
    "    #'msl_pressure:hPa',\n",
    "    #'sfc_pressure:hPa',\n",
    "]\n",
    "\n",
    "feature_to_normalize = [\n",
    "    'cloud_base_agl:m_y',\n",
    "    'clear_sky_energy_1h:J',\n",
    "    'diffuse_rad_1h:J',\n",
    "    'direct_rad_1h:J',\n",
    "    'precip_5min:mm',\n",
    "    'rain_water:kgm2',\n",
    "    'snow_water:kgm2',\n",
    "    'super_cooled_liquid_water:kgm2',\n",
    "    'clear_sky_rad:W',\n",
    "    'diffuse_rad:W',\n",
    "    'direct_rad:W',\n",
    "    'direct_rad:W_lag_avg', # Lag\n",
    "    'direct_rad:W_lead_avg', # Lead\n",
    "    'effective_cloud_cover:p',\n",
    "    'sun_azimuth:d',\n",
    "    'total_cloud_cover:p',\n",
    "    'visibility:m',\n",
    "    'wind_speed_10m:ms',\n",
    "    'sun_elevation:d', # Clipped version\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "\n",
    "    # Kinda useless\n",
    "    #'fresh_snow_12h:cm',\n",
    "    #'fresh_snow_24h:cm'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_20254/337045013.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n"
     ]
    }
   ],
   "source": [
    "# Scale features\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "for feature in feature_to_standardize:\n",
    "    #X_train[feature] = standard_scaler.fit_transform(X_train[[feature]])\n",
    "    X[feature] = standard_scaler.fit_transform(X[[feature]])\n",
    "    \n",
    "    X_non_train[feature] = standard_scaler.transform(X_non_train[[feature]])\n",
    "    X_val[feature] = standard_scaler.transform(X_val[[feature]])\n",
    "    X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
    "    X_kaggle[feature] = standard_scaler.transform(X_kaggle[[feature]])\n",
    "    \n",
    "\n",
    "for feature in feature_to_normalize:\n",
    "    #X_train[feature] = standard_scaler.fit_transform(X_train[[feature]])\n",
    "    X[feature] = min_max_scaler.fit_transform(X[[feature]])\n",
    "    \n",
    "    X_non_train[feature] = min_max_scaler.transform(X_non_train[[feature]])\n",
    "    X_val[feature] = min_max_scaler.transform(X_val[[feature]])\n",
    "    X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
    "    X_kaggle[feature] = min_max_scaler.transform(X_kaggle[[feature]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "887/887 [==============================] - 2s 1ms/step - loss: 247.4806 - val_loss: 130.5316\n",
      "Epoch 2/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 181.8229 - val_loss: 94.3502\n",
      "Epoch 3/13\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 173.7019 - val_loss: 142.5315\n",
      "Epoch 4/13\n",
      "887/887 [==============================] - 1s 2ms/step - loss: 170.1319 - val_loss: 116.3800\n",
      "Epoch 5/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 167.0454 - val_loss: 158.8546\n",
      "Epoch 6/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 164.5978 - val_loss: 95.6815\n",
      "Epoch 7/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 163.5163 - val_loss: 109.5887\n",
      "Epoch 8/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 162.2334 - val_loss: 148.7659\n",
      "Epoch 9/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 160.2810 - val_loss: 116.1454\n",
      "Epoch 10/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 159.6425 - val_loss: 113.0017\n",
      "Epoch 11/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 159.0107 - val_loss: 86.8480\n",
      "Epoch 12/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 157.6961 - val_loss: 75.6053\n",
      "Epoch 13/13\n",
      "887/887 [==============================] - 1s 1ms/step - loss: 157.1606 - val_loss: 65.2009\n"
     ]
    }
   ],
   "source": [
    "trial_params = {'seed': 94, 'n_neurons_1': 169, 'n_neurons_2': 158, 'n_neurons_3': 100, 'n_neurons_4': 61, 'kernel_regularizer': 0.06010848923666125, 'learning_rate': 0.0008571647307496605, 'beta_1': 0.8091963165438008, 'min_delta': 470.3578972108609, 'batch_size': 32, 'patience': 15}\n",
    "\n",
    "s = trial_params['seed']\n",
    "np.random.seed(s)\n",
    "random.seed(s)\n",
    "tf.random.set_seed(s)\n",
    "\n",
    "init = 'HeNormal'\n",
    "\n",
    "\n",
    "# Define the Keras model\n",
    "model = Sequential([\n",
    "    Dense(trial_params[\"n_neurons_1\"], input_dim=X_train.shape[1], activation='tanh', kernel_initializer=init),\n",
    "    Dropout(0.1, (trial_params[\"n_neurons_1\"],)),\n",
    "    Dense(trial_params[\"n_neurons_2\"], activation='relu', kernel_initializer=init, kernel_regularizer=l2(trial_params[\"kernel_regularizer\"])),\n",
    "    Dense(trial_params[\"n_neurons_3\"], activation='relu', kernel_initializer=init),\n",
    "    Dense(trial_params[\"n_neurons_4\"], activation='relu', kernel_initializer=init),\n",
    "    Dense(1, activation='relu', kernel_initializer=init)\n",
    "])\n",
    "\n",
    "opt = Adam(learning_rate=trial_params[\"learning_rate\"], beta_1=trial_params[\"beta_1\"])\n",
    "model.compile(loss='mean_absolute_error', optimizer=opt)\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    validation_data=(X_kaggle, y_hat),\n",
    "    #validation_split=0.2,\n",
    "    epochs=13,\n",
    "    batch_size=trial_params['batch_size'],\n",
    "    verbose=1,\n",
    "    use_multiprocessing=True, workers=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 643us/step\n",
      "MAE:  61.83069806086658\n"
     ]
    }
   ],
   "source": [
    "# Preds\n",
    "\n",
    "kaggle_pred = model.predict(X_kaggle, verbose=1).ravel()\n",
    "\n",
    "# Merge with kaggle_test data\n",
    "test_ALL_merge = pd.read_csv(\"current_csv_files/test_ALL.csv\")\n",
    "test_ALL_merge['prediction'] = kaggle_pred\n",
    "\n",
    "# Correctly sort test data for submission\n",
    "test_ALL_merge_sorted = test_ALL_merge.sort_values(['A', 'B', 'C', 'date_forecast'], ascending=[False, False, False, True])\n",
    "test_ALL_merge_sorted['id'] = range(2160)\n",
    "test_ALL_merge_sorted = test_ALL_merge_sorted.set_index('id')\n",
    "test_ALL_merge_sorted['id'] = range(2160)\n",
    "\n",
    "# Comparison to best sub on kaggle\n",
    "print(\"MAE: \", mean_absolute_error(kaggle_pred, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNN</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.141681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.438430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.138146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.690308</td>\n",
       "      <td>45.634729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>631.002260</td>\n",
       "      <td>335.761563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>16.857908</td>\n",
       "      <td>29.307958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>1.460704</td>\n",
       "      <td>4.800279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.293405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DNN         cat\n",
       "id                          \n",
       "0       0.000000    1.141681\n",
       "1       0.000000    1.438430\n",
       "2       0.000000    1.138146\n",
       "3      35.690308   45.634729\n",
       "4     631.002260  335.761563\n",
       "...          ...         ...\n",
       "2155   16.857908   29.307958\n",
       "2156    1.460704    4.800279\n",
       "2157    0.000000    0.000000\n",
       "2158    0.000000    0.000000\n",
       "2159    0.000000    3.293405\n",
       "\n",
       "[2160 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average best pred with new best kaggle sub\n",
    "df_merge = pd.DataFrame()\n",
    "df_merge['DNN'] = pd.read_csv(\"dnn_kaggle3/optuna_sub_0.csv\", index_col='id')\n",
    "df_merge['cat'] = pd.read_csv(\"teo_subs/kaggle_149.csv\", index_col='id')\n",
    "\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DNN</th>\n",
       "      <th>cat</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.141681</td>\n",
       "      <td>0.570841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.438430</td>\n",
       "      <td>0.719215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.138146</td>\n",
       "      <td>0.569073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.690308</td>\n",
       "      <td>45.634729</td>\n",
       "      <td>40.662519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>631.002260</td>\n",
       "      <td>335.761563</td>\n",
       "      <td>483.381911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2155</th>\n",
       "      <td>16.857908</td>\n",
       "      <td>29.307958</td>\n",
       "      <td>23.082933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>1.460704</td>\n",
       "      <td>4.800279</td>\n",
       "      <td>3.130492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2157</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.293405</td>\n",
       "      <td>1.646703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DNN         cat  prediction\n",
       "id                                      \n",
       "0       0.000000    1.141681    0.570841\n",
       "1       0.000000    1.438430    0.719215\n",
       "2       0.000000    1.138146    0.569073\n",
       "3      35.690308   45.634729   40.662519\n",
       "4     631.002260  335.761563  483.381911\n",
       "...          ...         ...         ...\n",
       "2155   16.857908   29.307958   23.082933\n",
       "2156    1.460704    4.800279    3.130492\n",
       "2157    0.000000    0.000000    0.000000\n",
       "2158    0.000000    0.000000    0.000000\n",
       "2159    0.000000    3.293405    1.646703\n",
       "\n",
       "[2160 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge['prediction'] = df_merge.mean(axis='columns')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['DNN'].to_csv(\"teo_subs/teo_sub_11.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_merge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_DNN3_reproducable.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_DNN3_reproducable.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Comparison to best sub on kaggle\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_DNN3_reproducable.ipynb#Y112sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m this \u001b[39m=\u001b[39m df_merge[\u001b[39m'\u001b[39m\u001b[39mDNN\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_DNN3_reproducable.ipynb#Y112sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m that \u001b[39m=\u001b[39m df_merge[\u001b[39m'\u001b[39m\u001b[39mcat\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_DNN3_reproducable.ipynb#Y112sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m best_sub \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mteo_subs/best_sub.csv\u001b[39m\u001b[39m\"\u001b[39m, index_col\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_merge' is not defined"
     ]
    }
   ],
   "source": [
    "# Comparison to best sub on kaggle\n",
    "this = df_merge['DNN']\n",
    "that = df_merge['cat']\n",
    "\n",
    "best_sub = pd.read_csv(\"teo_subs/best_sub.csv\", index_col='id')\n",
    "print(\"MAE: \", mean_absolute_error(this, that))\n",
    "\n",
    "slide = 0\n",
    "start = 0 + slide\n",
    "stop = 1000 + slide\n",
    "\n",
    "plt.figure(figsize=(30, 8))\n",
    "plt.plot(range(start, stop), that.iloc[start:stop], alpha=0.5)\n",
    "plt.plot(range(start, stop), this.iloc[start:stop], alpha=0.5)\n",
    "plt.title('Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction log"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Kaggle 155:\n",
    "avg of:\n",
    "\n",
    "[I 2023-11-10 23:54:06,683] Trial 1 finished with value: 10992.103539434958 and parameters: {'seed': 27, 'n_neurons_1': 153, 'n_neurons_2': 164, 'n_neurons_3': 106, 'n_neurons_4': 62, 'Dropout': 0.10652919718384293, 'kernel_regularizer': 0.20461262510508807, 'learning_rate': 0.0008983911620431631, 'beta_1': 0.860616374689329, 'min_delta': 546.9873253147257, 'batch_size': 16}. Best is trial 1 with value: 10992.103539434958.\n",
    "Best epoch:  8\n",
    "1  MAE:  55.365434181356406\n",
    "\n",
    "[I 2023-11-10 23:54:39,601] Trial 3 finished with value: 10883.562146725197 and parameters: {'seed': 50, 'n_neurons_1': 168, 'n_neurons_2': 150, 'n_neurons_3': 119, 'n_neurons_4': 86, 'Dropout': 0.05486050096736637, 'kernel_regularizer': 0.185675216070591, 'learning_rate': 0.0006607456173325845, 'beta_1': 0.827844121917279, 'min_delta': 711.3268525503731, 'batch_size': 16}. Best is trial 3 with value: 10883.562146725197.\n",
    "Best epoch:  6\n",
    "3  MAE:  52.977136280307334\n",
    "\n",
    "[I 2023-11-10 23:55:23,990] Trial 6 finished with value: 12191.771841206151 and parameters: {'seed': 77, 'n_neurons_1': 190, 'n_neurons_2': 157, 'n_neurons_3': 114, 'n_neurons_4': 81, 'Dropout': 0.13775212505352094, 'kernel_regularizer': 0.021798644842338375, 'learning_rate': 0.0005043955372051068, 'beta_1': 0.866123497839115, 'min_delta': 784.7761888817637, 'batch_size': 16}. Best is trial 3 with value: 10883.562146725197.\n",
    "Best epoch:  3\n",
    "6  MAE:  56.603082257665044\n",
    "\n",
    "[I 2023-11-10 23:56:19,969] Trial 10 finished with value: 11826.244265847325 and parameters: {'seed': 4, 'n_neurons_1': 198, 'n_neurons_2': 180, 'n_neurons_3': 116, 'n_neurons_4': 97, 'Dropout': 0.1988867998751226, 'kernel_regularizer': 0.09213996779470579, 'learning_rate': 0.0006016098630424032, 'beta_1': 0.8114945654788179, 'min_delta': 480.0884026718145, 'batch_size': 32}. Best is trial 3 with value: 10883.562146725197.\n",
    "Best epoch:  8\n",
    "10  MAE:  56.24223896442921\n",
    "\n",
    "[I 2023-11-10 23:57:58,722] Trial 16 finished with value: 10621.873770863649 and parameters: {'seed': 18, 'n_neurons_1': 181, 'n_neurons_2': 131, 'n_neurons_3': 100, 'n_neurons_4': 77, 'Dropout': 0.1087729403143276, 'kernel_regularizer': 0.12698207731886296, 'learning_rate': 0.0008485851540543418, 'beta_1': 0.8981723406638711, 'min_delta': 784.5259687267121, 'batch_size': 16}. Best is trial 16 with value: 10621.873770863649.\n",
    "Best epoch:  7\n",
    "16  MAE:  51.51623290653486"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
