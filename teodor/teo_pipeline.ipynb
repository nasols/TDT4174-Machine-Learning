{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import random\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manager class\n",
    "\n",
    "class Data_Manager() : \n",
    "\n",
    "    def __init__(self) : \n",
    "        # Y_train\n",
    "        self.train_a = pd.DataFrame() \n",
    "        self.train_b = pd.DataFrame()\n",
    "        self.train_c = pd.DataFrame()\n",
    "\n",
    "        self.X_train_observed_a = pd.DataFrame()\n",
    "        self.X_train_observed_b = pd.DataFrame()\n",
    "        self.X_train_observed_c = pd.DataFrame()\n",
    "\n",
    "        self.X_train_estimated_a = pd.DataFrame()\n",
    "        self.X_train_estimated_b = pd.DataFrame()\n",
    "        self.X_train_estimated_c = pd.DataFrame()\n",
    "\n",
    "        self.X_test_estimated_a = pd.DataFrame()\n",
    "        self.X_test_estimated_b = pd.DataFrame()\n",
    "        self.X_test_estimated_c = pd.DataFrame()\n",
    "\n",
    "        self.data_A = pd.DataFrame()    \n",
    "        self.data_B = pd.DataFrame()\n",
    "        self.data_C = pd.DataFrame()\n",
    "\n",
    "        self.data = pd.DataFrame()\n",
    "        self.X_test_estimated = pd.DataFrame()\n",
    "\n",
    "        # X_train_obs, Y_train_obs\n",
    "        self.data_A_obs = pd.DataFrame()    \n",
    "        self.data_B_obs = pd.DataFrame()\n",
    "        self.data_C_obs = pd.DataFrame()\n",
    "        \n",
    "        # X_train_obs, Y_train_obs\n",
    "        self.data_A_es = pd.DataFrame()\n",
    "        self.data_B_es = pd.DataFrame()\n",
    "        self.data_C_es = pd.DataFrame()\n",
    "\n",
    "        self.amplitude = np.zeros(3) # amp_a, amp_b, amp_c\n",
    "\n",
    "    def data_loader(self): \n",
    "        \"\"\"\n",
    "        Function that loads the datasets into data manager, loads all data \n",
    "        \"\"\"\n",
    "\n",
    "        self.train_a = pd.read_parquet('A/train_targets.parquet')\n",
    "        self.train_a = self.train_a.rename(columns={\"time\":\"date_forecast\"})\n",
    "\n",
    "        self.train_b = pd.read_parquet('B/train_targets.parquet')\n",
    "        self.train_b = self.train_b.rename(columns={\"time\":\"date_forecast\"})\n",
    "\n",
    "        self.train_c = pd.read_parquet('C/train_targets.parquet')\n",
    "        self.train_c = self.train_c.rename(columns={\"time\":\"date_forecast\"})\n",
    "\n",
    "        self.X_train_estimated_a = pd.read_parquet('A/X_train_estimated.parquet')\n",
    "        self.X_train_estimated_b = pd.read_parquet('B/X_train_estimated.parquet')\n",
    "        self.X_train_estimated_c = pd.read_parquet('C/X_train_estimated.parquet')\n",
    "\n",
    "        self.X_train_observed_a = pd.read_parquet('A/X_train_observed.parquet')\n",
    "        self.X_train_observed_b = pd.read_parquet('B/X_train_observed.parquet')\n",
    "        self.X_train_observed_c = pd.read_parquet('C/X_train_observed.parquet')\n",
    "\n",
    "        self.X_test_estimated_a = pd.read_parquet('A/X_test_estimated.parquet')\n",
    "        self.X_test_estimated_b = pd.read_parquet('B/X_test_estimated.parquet')\n",
    "        self.X_test_estimated_c = pd.read_parquet('C/X_test_estimated.parquet')\n",
    "    \n",
    "    def dms2dm(self, dms):\n",
    "        self.train_a = dms.data['train_a']\n",
    "        self.train_b = dms.data['train_b']\n",
    "        self.train_c = dms.data['train_c']\n",
    "\n",
    "        self.X_train_estimated_a = dms.data['X_train_estimated_a']\n",
    "        self.X_train_estimated_b = dms.data['X_train_estimated_b']\n",
    "        self.X_train_estimated_c = dms.data['X_train_estimated_c']\n",
    "\n",
    "        self.X_train_observed_a = dms.data['X_train_observed_a']\n",
    "        self.X_train_observed_b = dms.data['X_train_observed_b']\n",
    "        self.X_train_observed_c = dms.data['X_train_observed_c']\n",
    "\n",
    "        self.X_test_estimated_a = dms.data['X_test_estimated_a']\n",
    "        self.X_test_estimated_b = dms.data['X_test_estimated_b']\n",
    "        self.X_test_estimated_c = dms.data['X_test_estimated_c']\n",
    "\n",
    "        self.data_A_obs = dms.data['data_A_obs']\n",
    "        self.data_B_obs = dms.data['data_B_obs']\n",
    "        self.data_C_obs = dms.data['data_C_obs']\n",
    "\n",
    "        self.data_A_es = dms.data['data_A_es']\n",
    "        self.data_B_es = dms.data['data_B_es']\n",
    "        self.data_C_es = dms.data['data_C_es']\n",
    "\n",
    "        self.data_A = dms.data['data_A']   \n",
    "        self.data_B = dms.data['data_B']\n",
    "        self.data_C = dms.data['data_C']\n",
    "\n",
    "        self.amplitude = dms.data['amplitude']\n",
    "\n",
    "    def drop_feature(self, datasets:list[pd.DataFrame], features:list[str]):\n",
    "        \"\"\"\n",
    "        Takes in list of datasets and removes features from the sets\n",
    "\n",
    "        Returns list of altered datasets\n",
    "        \"\"\"\n",
    "\n",
    "        altered_sets = []\n",
    "\n",
    "        for set in datasets: \n",
    "            for feature in features:\n",
    "\n",
    "                set = set.drop(feature, axis=1)\n",
    "\n",
    "            altered_sets.append(set)\n",
    "\n",
    "        return altered_sets\n",
    "    \n",
    "    def combine_data(self): \n",
    "        import pandas as pd\n",
    "        \"\"\"\n",
    "        Combines datasets A, B and C into one set containing all features and pv_measurements. \n",
    "\n",
    "        Combine_observed_estimated (bool) determines if you want one single set for A B C or keep the observed and estimated\n",
    "        data split \n",
    "\n",
    "        Warning! Data should have no NaN values or be of same frequency before combining! \n",
    "        \"\"\"\n",
    "        weather_data_A = pd.concat([self.X_train_observed_a, self.X_train_estimated_a], axis=0, ignore_index=True)\n",
    "        weather_data_B = pd.concat([self.X_train_observed_b, self.X_train_estimated_b], axis=0, ignore_index=True)\n",
    "        weather_data_C = pd.concat([self.X_train_observed_c, self.X_train_estimated_c], axis=0, ignore_index=True)\n",
    "\n",
    "        self.data_A = pd.merge(weather_data_A, self.train_a, how=\"left\", on=\"date_forecast\")\n",
    "        self.data_B = pd.merge(weather_data_B, self.train_b,  on=\"date_forecast\", how=\"left\")\n",
    "        self.data_C = pd.merge(weather_data_C, self.train_c, on=\"date_forecast\", how=\"left\")\n",
    "\n",
    "        if ( self.data_A.columns.__contains__(\"date_calc\") ): \n",
    "            self.data_A = self.data_A.drop(\"date_calc\", axis=1)\n",
    "            self.data_B = self.data_B.drop(\"date_calc\", axis=1)\n",
    "            self.data_C = self.data_C.drop(\"date_calc\", axis=1)\n",
    "\n",
    "        if (self.train_a.shape[0] > 35000 ) : \n",
    "            \n",
    "            self.data_A = self.makima_interpolate(self.data_A).dropna()\n",
    "            self.data_B = self.makima_interpolate(self.data_B).dropna()\n",
    "            self.data_C = self.makima_interpolate(self.data_C).dropna()\n",
    "        \n",
    "        elif (self.train_a.shape[0] < 35000) : \n",
    "            self.data_A = self.data_A.dropna()\n",
    "            self.data_B = self.data_B.dropna()\n",
    "            self.data_C = self.data_C.dropna()\n",
    "\n",
    "        if self.data_A.isna().sum().sum() > 0 :\n",
    "            warnings.warn(\"Warning! Data should have no NaN values or be of same frequency before combining! Use impute or interpolation on data before combining! This could also come from dates in the combined datasets not overlapping fully.\")\n",
    "\n",
    "        return self.data_A, self.data_B, self.data_C\n",
    "\n",
    "    def impute_data(self, datasets, advanced_imputer=False):\n",
    "\n",
    "        \"\"\"\n",
    "        imputes data to fill in missing values\n",
    "\n",
    "        takes in a list of datasets\n",
    "\n",
    "        returns list of imputed data\n",
    "\n",
    "        removes all columns consisting entirely of nan \n",
    "        \"\"\"\n",
    "\n",
    "        from sklearn.experimental import enable_iterative_imputer\n",
    "        from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "        from tqdm import tqdm\n",
    "        imputed_sets = []\n",
    "\n",
    "        for set in tqdm(datasets): \n",
    "\n",
    "            # storing columns to lable after impute, also removing date column as this does not work with impute \n",
    "            cols = set.columns \n",
    "\n",
    "            if set.columns.__contains__(\"date_forecast\"): \n",
    "                dates = set[\"date_forecast\"]\n",
    "            \n",
    "            if set.columns.__contains__(\"date_calc\"): \n",
    "                set = set.drop(\"date_calc\", axis=1)\n",
    "\n",
    "            cols = set.columns.delete(0)\n",
    "\n",
    "            set_wo_date = set.drop(\"date_forecast\", axis=1)\n",
    "\n",
    "            #imputing (estimating) missing values \n",
    "            imp = SimpleImputer(missing_values=np.nan, strategy=\"mean\", add_indicator=False)\n",
    "            imp.fit(set_wo_date)\n",
    "            set_wo_date = pd.DataFrame(imp.transform(set_wo_date), columns=imp.get_feature_names_out())\n",
    "            \n",
    "\n",
    "            # setting column lables basck\n",
    "            set = set_wo_date\n",
    "            \n",
    "            set[\"date_forecast\"] = dates\n",
    "\n",
    "            #sorting columns \n",
    "            cols = cols.tolist()\n",
    "            cols.insert(0, \"date_forecast\")\n",
    "\n",
    "            #set = set.fillna(0.0)\n",
    "\n",
    "            imputed_sets.append(set)\n",
    "\n",
    "        return imputed_sets\n",
    "    \n",
    "    def iterative_imputer(self, datasets) :\n",
    "\n",
    "        from sklearn.experimental import enable_iterative_imputer\n",
    "        from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "        from tqdm import tqdm\n",
    "        imputed_sets = []\n",
    "        imp = IterativeImputer(random_state=0, missing_values=np.nan, add_indicator=False, imputation_order=\"ascending\", skip_complete=True)\n",
    "\n",
    "        for set in tqdm(datasets): \n",
    "\n",
    "            cols = set.columns \n",
    "\n",
    "            if set.columns.__contains__(\"date_forecast\"): \n",
    "                dates = set[\"date_forecast\"]\n",
    "            \n",
    "            if set.columns.__contains__(\"date_calc\"): \n",
    "                set = set.drop(\"date_calc\", axis=1)\n",
    "            \n",
    "            cols = set.columns.delete(0)\n",
    "\n",
    "            set_wo_date = set.drop(\"date_forecast\", axis=1)\n",
    "\n",
    "            print(\"getting to imputing\")\n",
    "            #imputing (estimating) missing values \n",
    "            imp.fit(set_wo_date)\n",
    "            \n",
    "            set_wo_date = pd.DataFrame(imp.transform(set_wo_date), columns=imp.get_feature_names_out())\n",
    "\n",
    "             # setting column lables basck\n",
    "            set = set_wo_date\n",
    "            \n",
    "            set[\"date_forecast\"] = dates\n",
    "\n",
    "            # set = set.fillna(0.0)\n",
    "\n",
    "\n",
    "            #sorting columns \n",
    "            cols = cols.tolist()\n",
    "            cols.insert(0, \"date_forecast\")\n",
    "\n",
    "            imputed_sets.append(set)\n",
    "\n",
    "        return imputed_sets\n",
    "\n",
    "    def resample_data(self, datasets:[pd.DataFrame], freq:str) : \n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        resamples the given dataset into the correct frequency. \n",
    "        H : hourly \n",
    "        15T : 15min \n",
    "        \"\"\"\n",
    "        \n",
    "        corr = []\n",
    "\n",
    "\n",
    "        for set in datasets: \n",
    "\n",
    "            mean_set = set.loc[:, set.columns]\n",
    "\n",
    "            set_hourly = mean_set.resample(freq, on=\"date_forecast\").mean()\n",
    "\n",
    "            set_dates = mean_set[\"date_forecast\"].dt.date.unique().tolist()\n",
    "\n",
    "            set_hourly[\"date_forecast\"] = set_hourly.index\n",
    "\n",
    "            mean_set_corr = set_hourly[set_hourly[\"date_forecast\"].dt.date.isin(set_dates)]\n",
    "\n",
    "            mean_set_corr.index = pd.RangeIndex(0, len(mean_set_corr))\n",
    "        \n",
    "            corr.append(mean_set_corr)\n",
    "\n",
    "\n",
    "    \n",
    "        return corr\n",
    "\n",
    "    def add_feature(dataset, feature_name, data) :\n",
    "\n",
    "        added_set = dataset[feature_name] = data\n",
    "\n",
    "        return added_set\n",
    "    \n",
    "    def set_info(self, dataset:pd.DataFrame):\n",
    "\n",
    "        (dataset.info())\n",
    "\n",
    "    def plot_feature(self, dataset:pd.DataFrame, featureName:str):\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(20, 10))\n",
    "        fig.set_label(featureName)\n",
    "\n",
    "        plt.scatter(dataset[\"date_forecast\"], dataset[featureName], s=3)\n",
    "\n",
    "        #dataset[['date_forecast', featureName]].set_index(\"date_forecast\").plot(ax=axs, title=featureName, color='red')\n",
    "       \n",
    "    def KNNImputing(self, datasets) :\n",
    "        from sklearn.impute import KNNImputer\n",
    "        from tqdm import tqdm\n",
    "\n",
    "        imputed_sets = []\n",
    "\n",
    "        for set in tqdm(datasets): \n",
    "\n",
    "            # storing columns to lable after impute, also removing date column as this does not work with impute \n",
    "            cols = set.columns \n",
    "\n",
    "            if set.columns.__contains__(\"date_forecast\"): \n",
    "                dates = set[\"date_forecast\"]\n",
    "            \n",
    "            if set.columns.__contains__(\"date_calc\"): \n",
    "                set = set.drop(\"date_calc\", axis=1)\n",
    "\n",
    "            cols = set.columns.delete(0)\n",
    "\n",
    "            set_wo_date = set.drop(\"date_forecast\", axis=1)\n",
    "\n",
    "            #imputing (estimating) missing values \n",
    "            imp = KNNImputer(n_neighbors=40, weights=\"distance\", )\n",
    "            imp.fit(set_wo_date)\n",
    "            set_wo_date = pd.DataFrame(imp.transform(set_wo_date), columns=imp.get_feature_names_out())\n",
    "            \n",
    "\n",
    "            # setting column lables basck\n",
    "            set = set_wo_date\n",
    "            \n",
    "            set[\"date_forecast\"] = dates\n",
    "\n",
    "            #sorting columns \n",
    "            cols = cols.tolist()\n",
    "            cols.insert(0, \"date_forecast\")\n",
    "\n",
    "            ## set = set.fillna(0.0)\n",
    "\n",
    "            imputed_sets.append(set)\n",
    "\n",
    "        return imputed_sets\n",
    "\n",
    "    def makima_interpolate(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "        from scipy.interpolate import Akima1DInterpolator\n",
    "        # Extract non-missing values and their indices\n",
    "\n",
    "        dates = data[\"date_forecast\"]\n",
    "\n",
    "        non_nan_indices = data['pv_measurement'].dropna().index\n",
    "        non_nan_values = data['pv_measurement'].dropna().values\n",
    "\n",
    "        # Apply the Modified Akima Interpolation\n",
    "        akima = Akima1DInterpolator(non_nan_indices, non_nan_values)\n",
    "        interpolated_values = akima(data.index)\n",
    "\n",
    "        # Replace the original column with the interpolated values\n",
    "        data['pv_measurement'] = interpolated_values\n",
    "\n",
    "        data[data[\"pv_measurement\"]< 0] = 0 ; \n",
    "\n",
    "        data[\"date_forecast\"] = dates; \n",
    "\n",
    "        return data\n",
    "    \n",
    "    def normalize_data(self) : \n",
    "        from sklearn import preprocessing\n",
    "\n",
    "        if (self.data_A.empty) : \n",
    "            print( \"empty \")\n",
    "            relevant_sets = [attr for attr in dir(self) if not callable(getattr(self, attr)) and not attr.startswith(\"__\") and not attr.__contains__(\"data\") and not attr == 'amplitude' and not attr.__contains__(\"normalizing\")]\n",
    "\n",
    "        else: \n",
    "            print(\"not emptu\")\n",
    "            relevant_sets = [attr for attr in dir(self) if not callable(getattr(self, attr)) and not attr.startswith(\"__\") and attr.__contains__(\"data_\") and not attr.__contains__(\"_es\") and not attr.__contains__(\"obs\") or attr.__contains__(\"_estimated_\")]\n",
    "        self.__setattr__(\"normalizing_consts\", {})\n",
    "\n",
    "        print(relevant_sets)\n",
    "\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        normalizer = preprocessing.Normalizer()\n",
    "        \n",
    "\n",
    "        for att in relevant_sets: \n",
    "            set : pd.DataFrame = self.__getattribute__(att)\n",
    "\n",
    "            cols = set.columns \n",
    "\n",
    "            if set.columns.__contains__(\"date_forecast\"): \n",
    "                dates = set[\"date_forecast\"]\n",
    "            \n",
    "            if set.columns.__contains__(\"date_calc\"): \n",
    "                set = set.drop(\"date_calc\", axis=1)\n",
    "\n",
    "            cols = set.columns.delete(0)\n",
    "\n",
    "            set_wo_date = set.drop(\"date_forecast\", axis=1)\n",
    "\n",
    "            x = set_wo_date.values\n",
    "\n",
    "            x_normalized = min_max_scaler.fit_transform(x)\n",
    "\n",
    "            self.normalizing_consts[att] = (set_wo_date.min(), np.abs(set_wo_date.max() - set_wo_date.min())) ## storing normalizing consts for later \n",
    "            \n",
    "            normalized_set = pd.DataFrame(x_normalized)\n",
    "\n",
    "            normalized_set.columns = cols\n",
    "\n",
    "            \n",
    "\n",
    "            self.__setattr__(att, normalized_set)\n",
    "        \n",
    "    def scaling(self, preds, location:str) : \n",
    "\n",
    "        \"\"\"\n",
    "        FORMAT OF PREDICTIONS SHOULD BE 1 COLUMN WITH PREDS\n",
    "\n",
    "        LOCATION: A B or C\n",
    "        \"\"\"\n",
    "\n",
    "        relevant_sets = [attr for attr in dir(self) if not callable(getattr(self, attr)) and not attr.startswith(\"__\") and not attr.__contains__(\"data\") and not attr == 'amplitude' and (attr.__contains__(\"train_a\") or attr.__contains__(\"train_b\") or attr.__contains__(\"train_c\"))]\n",
    "        if (self.data_A.empty) : \n",
    "            print( \"empty \")\n",
    "            relevant_sets = [attr for attr in dir(self) if not callable(getattr(self, attr)) and not attr.startswith(\"__\") and not attr.__contains__(\"data\") and not attr == 'amplitude' and not attr.__contains__(\"normalizing\")]\n",
    "\n",
    "        else: \n",
    "            print(\"not emptu\")\n",
    "            relevant_sets = [attr for attr in dir(self) if not callable(getattr(self, attr)) and not attr.startswith(\"__\") and attr.__contains__(\"data_\") and not attr.__contains__(\"es\") and not attr.__contains__(\"obs\")]\n",
    "\n",
    "        \n",
    "        loc_index = 0\n",
    "\n",
    "        if location.capitalize() == \"A\" :\n",
    "\n",
    "            loc_index = 0\n",
    "\n",
    "        elif location.capitalize() == \"B\": \n",
    "        \n",
    "            loc_index = 1\n",
    "\n",
    "        elif location.capitalize() == \"C\": \n",
    "\n",
    "            loc_index = 2\n",
    "           \n",
    "        elif ( location.capitalize() == \"D\"): \n",
    "\n",
    "            A = pd.DataFrame(preds[0:720])\n",
    "            B = pd.DataFrame(preds[720:2*720])\n",
    "            C = pd.DataFrame(preds[2*720:])\n",
    "\n",
    "            min = self.normalizing_consts[\"data_A\"][0][0]\n",
    "            diff = self.normalizing_consts[\"data_A\"][1][0]\n",
    "\n",
    "            scaled_A = (A+min) * diff\n",
    "\n",
    "\n",
    "\n",
    "            min = self.normalizing_consts[\"data_B\"][0][0]\n",
    "            diff = self.normalizing_consts[\"data_B\"][1][0]\n",
    "\n",
    "            scaled_B = (B+min) * diff\n",
    "\n",
    "\n",
    "\n",
    "            min = self.normalizing_consts[\"data_C\"][0][0]\n",
    "            diff = self.normalizing_consts[\"data_C\"][1][0]\n",
    "\n",
    "            scaled_C = (C+min) * diff\n",
    "\n",
    "\n",
    "            print(A.shape)\n",
    "            scaled_set = pd.concat([scaled_A, scaled_B, scaled_C])\n",
    "\n",
    "            return scaled_set\n",
    "\n",
    "        relevant_set = relevant_sets[loc_index]\n",
    "\n",
    "    \n",
    "        min = self.normalizing_consts[relevant_set][0][0]\n",
    "        diff = self.normalizing_consts[relevant_set][1][0]\n",
    "\n",
    "        scaled_set = (preds + min) * diff\n",
    "\n",
    "        return scaled_set\n",
    "    \n",
    "    def combine_overlap_BC(self): \n",
    "        import math\n",
    "        \"\"\"\n",
    "        This function is created for merging B and C to remove the nan values apparent when merging pv_measurement to the weather data\n",
    "        This is because of the observation that B and C overlap and where one is missing the other fills in. \n",
    "        Must run combine data first to create data_A B C\n",
    "        \"\"\"\n",
    "\n",
    "        original_B = self.data_B\n",
    "        original_C = self.data_C  \n",
    "\n",
    "        b2c_scaling = original_B[\"pv_measurement\"].max()/original_C[\"pv_measurement\"].max()\n",
    "\n",
    "        print(b2c_scaling)      \n",
    "\n",
    "        original_C[original_C.isnull()] = self.data_B\n",
    "        original_B[original_B.isnull()] = self.data_C\n",
    "\n",
    "        self.data_C = original_C.dropna()\n",
    "        self.data_B = original_B.dropna()\n",
    "\n",
    "    def sorting_columns_inMainSets(self):\n",
    "\n",
    "        A = self.data_A \n",
    "        cols = A.columns.tolist()\n",
    "\n",
    "        #sorting columns \n",
    "        cols.remove(\"date_forecast\")\n",
    "        cols.remove(\"pv_measurement\")\n",
    "        cols.insert(0, \"pv_measurement\")\n",
    "        cols.insert(0, \"date_forecast\")\n",
    "\n",
    "        A = A[cols]\n",
    "        self.data_A = A\n",
    "\n",
    "        #------------------------------------------------------------# \n",
    "\n",
    "        B = self.data_B\n",
    "        cols = B.columns.tolist()\n",
    "\n",
    "        #sorting columns \n",
    "        cols.remove(\"date_forecast\")\n",
    "        cols.remove(\"pv_measurement\")\n",
    "        cols.insert(0, \"pv_measurement\")\n",
    "        cols.insert(0, \"date_forecast\")\n",
    "\n",
    "        B = B[cols]\n",
    "        self.data_B = B \n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        C = self.data_C\n",
    "\n",
    "        cols = C.columns.tolist()\n",
    "\n",
    "        #sorting columns \n",
    "        cols.remove(\"date_forecast\")\n",
    "        cols.remove(\"pv_measurement\")\n",
    "        cols.insert(0, \"pv_measurement\")\n",
    "        cols.insert(0, \"date_forecast\")\n",
    "\n",
    "        C = C[cols]\n",
    "        self.data_C = C\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        A = self.X_test_estimated_a\n",
    "\n",
    "        cols = A.columns.tolist()\n",
    "\n",
    "        #sorting columns \n",
    "        cols.remove(\"date_forecast\")\n",
    "        cols.insert(0, \"date_forecast\")\n",
    "\n",
    "        A = A[cols]\n",
    "        self.X_test_estimated_a = A\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        B = self.X_test_estimated_b\n",
    "\n",
    "        cols = B.columns.tolist()\n",
    "\n",
    "        #sorting columns \n",
    "        cols.remove(\"date_forecast\")\n",
    "        cols.insert(0, \"date_forecast\")\n",
    "\n",
    "        B = B[cols]\n",
    "        self.X_test_estimated_b = B\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        C = self.X_test_estimated_c\n",
    "\n",
    "        cols = C.columns.tolist()\n",
    "\n",
    "        #sorting columns \n",
    "        cols.remove(\"date_forecast\")\n",
    "        cols.insert(0, \"date_forecast\")\n",
    "\n",
    "        C = C[cols]\n",
    "        self.X_test_estimated_c = C\n",
    "\n",
    "        #------------------------------------------------------------#\n",
    "\n",
    "        if ( not self.data.empty) : \n",
    "            data = self.data\n",
    "\n",
    "            cols = data.columns.tolist()\n",
    "\n",
    "            #sorting columns \n",
    "            cols.remove(\"date_forecast\")\n",
    "            cols.remove(\"pv_measurement\")\n",
    "            cols.insert(0, \"pv_measurement\")\n",
    "            cols.insert(0, \"date_forecast\")\n",
    "\n",
    "            data = data[cols]\n",
    "            self.data = data\n",
    "\n",
    "    def remove_constant_periods(self, period_length, ignore_values=[]) :\n",
    "        from helpers import find_const_interval\n",
    "\n",
    "        train_a = self.data_A.reset_index(drop=True)\n",
    "        train_b = self.data_B.reset_index(drop=True)\n",
    "        train_c = self.data_C.reset_index(drop=True)\n",
    "\n",
    "        y_train_a_const_idx, ca = find_const_interval(train_a, 'pv_measurement', period_length, ignore_values)\n",
    "        print('y_train_a anomalies:',ca)\n",
    "\n",
    "        y_train_b_const_idx, cb = find_const_interval(train_b, 'pv_measurement', period_length, ignore_values)\n",
    "        print('y_train_b anomalies:',cb)\n",
    "\n",
    "        y_train_c_const_idx, cc = find_const_interval(train_c, 'pv_measurement', period_length, ignore_values)\n",
    "        print('y_train_c anomalies:',cc)\n",
    "\n",
    "\n",
    "        date_forecast_a_const = train_a.iloc[y_train_a_const_idx]['date_forecast']\n",
    "        date_forecast_a_const_values = date_forecast_a_const.values\n",
    "        train_a = train_a[~train_a['date_forecast'].isin(date_forecast_a_const_values)]\n",
    "\n",
    "        date_forecast_b_const = train_b.iloc[y_train_b_const_idx]['date_forecast']\n",
    "        date_forecast_b_const_values = date_forecast_b_const.values\n",
    "        train_b = train_b[~train_b['date_forecast'].isin(date_forecast_b_const_values)]\n",
    "\n",
    "        date_forecast_c_const = train_c.iloc[y_train_c_const_idx]['date_forecast']\n",
    "        date_forecast_c_const_values = date_forecast_c_const.values\n",
    "        train_c = train_c[~train_c['date_forecast'].isin(date_forecast_c_const_values)]\n",
    "\n",
    "        self.data_A = train_a\n",
    "        self.data_B = train_b\n",
    "        self.data_C = train_c\n",
    "                \n",
    "    def split_timeseries(self, X, y, num_splits):\n",
    "\n",
    "        num_rows = X.shape[0]\n",
    "\n",
    "        split_length = num_rows // num_splits\n",
    "\n",
    "        all_splits = []\n",
    "\n",
    "        end_idx = split_length\n",
    "\n",
    "        all_splits.append([np.arange(0, round(split_length*0.9), 1), np.arange(round(split_length*0.9), split_length, 1)])\n",
    "\n",
    "\n",
    "        while 2*end_idx < num_rows: \n",
    "\n",
    "            all_splits.append([np.arange(round(end_idx), end_idx + round(0.9*end_idx), 1), np.arange(round(end_idx*0.9)+end_idx, 2*end_idx, 1)])\n",
    "\n",
    "            end_idx += split_length\n",
    "\n",
    "        print(end_idx + split_length)\n",
    "        rest = num_rows - end_idx \n",
    "\n",
    "        all_splits.append([np.arange(round(2), )])\n",
    "\n",
    "        print(all_splits) \n",
    "\n",
    "    def add_location(self, dataset:pd.DataFrame, location):\n",
    "\n",
    "        if location == \"A\": loc = 0 \n",
    "        if location == \"B\": loc = 1 \n",
    "        if location == \"C\": loc = 2\n",
    "\n",
    "        index = dataset.index\n",
    "\n",
    "        loc_column = pd.DataFrame()\n",
    "        loc_column.index = index\n",
    "        loc_column[\"location\"] = loc\n",
    "\n",
    "        dataset[\"location\"] = loc\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    def add_lag_feature(self, target_attribute, lag):\n",
    "\n",
    "        lag_attribute = target_attribute + \"_lag_\" + str(lag)\n",
    "\n",
    "        self.data_A[lag_attribute] = self.data_A[target_attribute].shift(lag).fillna(0)\n",
    "        self.data_B[lag_attribute] = self.data_B[target_attribute].shift(lag).fillna(0)\n",
    "        self.data_C[lag_attribute] = self.data_C[target_attribute].shift(lag).fillna(0)\n",
    "\n",
    "        self.X_test_estimated_a[lag_attribute] = self.X_test_estimated_a[target_attribute].shift(lag).fillna(0)\n",
    "        self.X_test_estimated_b[lag_attribute] = self.X_test_estimated_b[target_attribute].shift(lag).fillna(0)\n",
    "        self.X_test_estimated_c[lag_attribute] = self.X_test_estimated_c[target_attribute].shift(lag).fillna(0)\n",
    "        \n",
    "    def combine_all_data(self): \n",
    "\n",
    "        relevant_sets_A = [attr for attr in dir(self) if attr.__eq__(\"data_A\") or attr.__eq__(\"X_test_estimated_a\")]\n",
    "        relevant_sets_B = [attr for attr in dir(self) if attr.__eq__(\"data_B\") or attr.__eq__(\"X_test_estimated_b\")]\n",
    "        relevant_sets_C = [attr for attr in dir(self) if attr.__eq__(\"data_C\") or attr.__eq__(\"X_test_estimated_c\")]\n",
    "\n",
    "        print(relevant_sets_A)\n",
    "        print(relevant_sets_B)\n",
    "        print(relevant_sets_C)\n",
    "\n",
    "\n",
    "        for set in relevant_sets_A : \n",
    "            self.__setattr__(set, self.add_location(self.__getattribute__(set), \"A\"))\n",
    "        for set in relevant_sets_B : \n",
    "            self.__setattr__(set, self.add_location(self.__getattribute__(set), \"B\"))\n",
    "        for set in relevant_sets_C : \n",
    "            self.__setattr__(set, self.add_location(self.__getattribute__(set), \"C\"))\n",
    "\n",
    "\n",
    "        self.data = pd.concat([self.data_A, self.data_B, self.data_C], ignore_index=True)\n",
    "        self.X_test_estimated = pd.concat([self.X_test_estimated_a, self.X_test_estimated_b, self.X_test_estimated_c], ignore_index=True)\n",
    "\n",
    "    def remove_outliers_z_score(self, data:pd.DataFrame, threshold=3) : \n",
    "        \n",
    "        from scipy import stats\n",
    "\n",
    "        before = self.data[\"diffuse_rad:W\"][0:3*720]\n",
    "\n",
    "        dates = None \n",
    "\n",
    "        if \"date_forecast\" in data.columns: \n",
    "\n",
    "            dates = data[\"date_forecast\"]\n",
    "            data = data.drop(\"date_forecast\", axis=1)\n",
    "\n",
    "        z_scores = stats.zscore(data.astype(float))\n",
    "\n",
    "        outliers = data[z_scores > threshold]\n",
    "        #outliers = outliers.drop(\"index\", axis=1)\n",
    "        outliers = outliers.notna()\n",
    "\n",
    "        indexx = None\n",
    "\n",
    "        if (len(outliers) > 1): \n",
    "\n",
    "            for outlier in outliers: \n",
    "                # print(outliers[outlier])\n",
    "\n",
    "                # print(data[outlier])\n",
    "\n",
    "                if (outlier != \"index\"):\n",
    "\n",
    "                    index = data[outlier].loc[outliers[outlier] == True]\n",
    "\n",
    "                    data[outlier] = data[outlier].replace(index.index, np.nan)\n",
    "\n",
    "\n",
    "                    indexx = index\n",
    "            \n",
    "\n",
    "            data[\"date_forecast\"] = dates\n",
    "\n",
    "            data = self.KNNImputing([data])[0]\n",
    "            data = data.reset_index(drop=True)\n",
    "            self.sorting_columns_inMainSets()\n",
    "            print(self.set_info(self.data))\n",
    "            \n",
    "            x = np.arange(0, 3*720, 1)\n",
    "            fig, axs = plt.subplots(1, 1, figsize=(20, 10))\n",
    "            plt.plot(x, before, c=\"blue\", label=\"before\")            \n",
    "            plt.plot(x, data[\"diffuse_rad:W\"][0:3*720], c=\"orange\", label=\"after\") \n",
    "            plt.legend()           \n",
    "            plt.show()\n",
    "            return data\n",
    "\n",
    "        else: \n",
    "            print(\"no outliers\")\n",
    "            return data\n",
    "    \n",
    "    def resample_categorical(self, dataset:pd.DataFrame, feature:str): \n",
    "\n",
    "        \"resamples the categorical feature to an hourly basis, returns the categorical column\"\n",
    "\n",
    "        hour_df = dataset[dataset[\"date_forecast\"].dt.hour % 1 == 0][feature]\n",
    "\n",
    "        return hour_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciate a new datamanager \n",
    "dm = Data_Manager()\n",
    "dm.data_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features with too many NaN Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"snow_density:kgm3\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"snow_density:kgm3\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"snow_density:kgm3\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"snow_density:kgm3\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"snow_density:kgm3\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"snow_density:kgm3\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"snow_density:kgm3\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"snow_density:kgm3\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"snow_density:kgm3\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud base and Ceiling height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"ceiling_height_agl:m\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"ceiling_height_agl:m\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"ceiling_height_agl:m\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"ceiling_height_agl:m\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"ceiling_height_agl:m\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"ceiling_height_agl:m\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"ceiling_height_agl:m\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"ceiling_height_agl:m\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"ceiling_height_agl:m\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/3371666875.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.X_train_observed_a[\"cloud_base_agl:m\"][dm.X_train_observed_a[\"cloud_base_agl:m\"].isna()] = -667\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/3371666875.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.X_train_estimated_a[\"cloud_base_agl:m\"][dm.X_train_estimated_a[\"cloud_base_agl:m\"].isna()] = -667\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/3371666875.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.X_test_estimated_a[\"cloud_base_agl:m\"][dm.X_test_estimated_a[\"cloud_base_agl:m\"].isna()] = -667\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/3371666875.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.X_train_observed_b[\"cloud_base_agl:m\"][dm.X_train_observed_b[\"cloud_base_agl:m\"].isna()] = -667\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/3371666875.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.X_train_estimated_b[\"cloud_base_agl:m\"][dm.X_train_estimated_b[\"cloud_base_agl:m\"].isna()] = -667\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/3371666875.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.X_test_estimated_b[\"cloud_base_agl:m\"][dm.X_test_estimated_b[\"cloud_base_agl:m\"].isna()] = -667\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/3371666875.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.X_train_observed_c[\"cloud_base_agl:m\"][dm.X_train_observed_c[\"cloud_base_agl:m\"].isna()] = -667\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/3371666875.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.X_train_estimated_c[\"cloud_base_agl:m\"][dm.X_train_estimated_c[\"cloud_base_agl:m\"].isna()] = -667\n",
      "/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/3371666875.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dm.X_test_estimated_c[\"cloud_base_agl:m\"][dm.X_test_estimated_c[\"cloud_base_agl:m\"].isna()] = -667\n"
     ]
    }
   ],
   "source": [
    "dm.X_train_observed_a[\"cloud_base_agl:m\"][dm.X_train_observed_a[\"cloud_base_agl:m\"].isna()] = -667\n",
    "dm.X_train_estimated_a[\"cloud_base_agl:m\"][dm.X_train_estimated_a[\"cloud_base_agl:m\"].isna()] = -667\n",
    "dm.X_test_estimated_a[\"cloud_base_agl:m\"][dm.X_test_estimated_a[\"cloud_base_agl:m\"].isna()] = -667\n",
    "\n",
    "dm.X_train_observed_b[\"cloud_base_agl:m\"][dm.X_train_observed_b[\"cloud_base_agl:m\"].isna()] = -667\n",
    "dm.X_train_estimated_b[\"cloud_base_agl:m\"][dm.X_train_estimated_b[\"cloud_base_agl:m\"].isna()] = -667\n",
    "dm.X_test_estimated_b[\"cloud_base_agl:m\"][dm.X_test_estimated_b[\"cloud_base_agl:m\"].isna()] = -667\n",
    "\n",
    "dm.X_train_observed_c[\"cloud_base_agl:m\"][dm.X_train_observed_c[\"cloud_base_agl:m\"].isna()] = -667\n",
    "dm.X_train_estimated_c[\"cloud_base_agl:m\"][dm.X_train_estimated_c[\"cloud_base_agl:m\"].isna()] = -667\n",
    "dm.X_test_estimated_c[\"cloud_base_agl:m\"][dm.X_test_estimated_c[\"cloud_base_agl:m\"].isna()] = -667\n",
    "\n",
    "\n",
    "#dm.plot_feature(dm.X_train_observed_a, \"cloud_base_agl:m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the date_forecast interval\n",
    "start_date = '2020-03-25 00:00:00'\n",
    "end_date = '2020-03-27 00:00:00'\n",
    "\n",
    "# filter the data based on the date_forecast interval\n",
    "data_filtered = dm.X_train_observed_a[(dm.X_train_observed_a['date_forecast'] >= start_date) & (dm.X_train_observed_a['date_forecast'] <= end_date)]\n",
    "\n",
    "# plot the cloud_base_agl column\n",
    "#data_filtered.plot(x='date_forecast', y='cloud_base_agl:m', figsize=(20,10), style='.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_turning_point = '2020-03-26 00:00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date calc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"date_calc\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"date_calc\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"date_calc\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"date_calc\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"date_calc\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"date_calc\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"fresh_snow_1h:cm\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"fresh_snow_1h:cm\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"fresh_snow_1h:cm\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"fresh_snow_1h:cm\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"fresh_snow_1h:cm\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"fresh_snow_1h:cm\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"fresh_snow_1h:cm\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"fresh_snow_1h:cm\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"fresh_snow_1h:cm\", axis=1)\n",
    "\n",
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"fresh_snow_3h:cm\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"fresh_snow_3h:cm\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"fresh_snow_3h:cm\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"fresh_snow_3h:cm\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"fresh_snow_3h:cm\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"fresh_snow_3h:cm\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"fresh_snow_3h:cm\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"fresh_snow_3h:cm\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"fresh_snow_3h:cm\", axis=1)\n",
    "\n",
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"fresh_snow_6h:cm\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"fresh_snow_6h:cm\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"fresh_snow_6h:cm\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"fresh_snow_6h:cm\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"fresh_snow_6h:cm\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"fresh_snow_6h:cm\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"fresh_snow_6h:cm\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"fresh_snow_6h:cm\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"fresh_snow_6h:cm\", axis=1)\n",
    "\n",
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"snow_depth:cm\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"snow_depth:cm\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"snow_depth:cm\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"snow_depth:cm\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"snow_depth:cm\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"snow_depth:cm\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"snow_depth:cm\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"snow_depth:cm\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"snow_depth:cm\", axis=1)\n",
    "\n",
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"snow_drift:idx\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"snow_drift:idx\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"snow_drift:idx\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"snow_drift:idx\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"snow_drift:idx\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"snow_drift:idx\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"snow_drift:idx\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"snow_drift:idx\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"snow_drift:idx\", axis=1)\n",
    "\n",
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"snow_melt_10min:mm\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"snow_melt_10min:mm\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"snow_melt_10min:mm\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"snow_melt_10min:mm\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"snow_melt_10min:mm\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"snow_melt_10min:mm\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"snow_melt_10min:mm\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"snow_melt_10min:mm\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"snow_melt_10min:mm\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wind speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"wind_speed_w_1000hPa:ms\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"wind_speed_w_1000hPa:ms\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"wind_speed_w_1000hPa:ms\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"wind_speed_w_1000hPa:ms\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"wind_speed_w_1000hPa:ms\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"wind_speed_w_1000hPa:ms\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"wind_speed_w_1000hPa:ms\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"wind_speed_w_1000hPa:ms\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"wind_speed_w_1000hPa:ms\", axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dew or rime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndm.X_train_observed_a = dm.X_train_observed_a.drop(\"dew_or_rime:idx\", axis=1)\\ndm.X_train_observed_b = dm.X_train_observed_b.drop(\"dew_or_rime:idx\", axis=1) \\ndm.X_train_observed_c = dm.X_train_observed_c.drop(\"dew_or_rime:idx\", axis=1) \\n\\ndm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"dew_or_rime:idx\", axis=1)\\ndm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"dew_or_rime:idx\", axis=1)\\ndm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"dew_or_rime:idx\", axis=1)\\n\\ndm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"dew_or_rime:idx\", axis=1)\\ndm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"dew_or_rime:idx\", axis=1)\\ndm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"dew_or_rime:idx\", axis=1)\\n\\ndm.X_train_observed_a = dm.X_train_observed_a.drop(\"prob_rime:p\", axis=1)\\ndm.X_train_observed_b = dm.X_train_observed_b.drop(\"prob_rime:p\", axis=1) \\ndm.X_train_observed_c = dm.X_train_observed_c.drop(\"prob_rime:p\", axis=1) \\n\\ndm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"prob_rime:p\", axis=1)\\ndm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"prob_rime:p\", axis=1)\\ndm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"prob_rime:p\", axis=1)\\n\\ndm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"prob_rime:p\", axis=1)\\ndm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"prob_rime:p\", axis=1)\\ndm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"prob_rime:p\", axis=1)\\n'"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"dew_or_rime:idx\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"dew_or_rime:idx\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"dew_or_rime:idx\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"dew_or_rime:idx\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"dew_or_rime:idx\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"dew_or_rime:idx\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"dew_or_rime:idx\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"dew_or_rime:idx\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"dew_or_rime:idx\", axis=1)\n",
    "\n",
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"prob_rime:p\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"prob_rime:p\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"prob_rime:p\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"prob_rime:p\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"prob_rime:p\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"prob_rime:p\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"prob_rime:p\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"prob_rime:p\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"prob_rime:p\", axis=1)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.X_train_observed_a = dm.X_train_observed_a.drop(\"elevation:m\", axis=1)\n",
    "dm.X_train_observed_b = dm.X_train_observed_b.drop(\"elevation:m\", axis=1) \n",
    "dm.X_train_observed_c = dm.X_train_observed_c.drop(\"elevation:m\", axis=1) \n",
    "\n",
    "dm.X_train_estimated_a = dm.X_train_estimated_a.drop(\"elevation:m\", axis=1)\n",
    "dm.X_train_estimated_b = dm.X_train_estimated_b.drop(\"elevation:m\", axis=1)\n",
    "dm.X_train_estimated_c = dm.X_train_estimated_c.drop(\"elevation:m\", axis=1)\n",
    "\n",
    "dm.X_test_estimated_a = dm.X_test_estimated_a.drop(\"elevation:m\", axis=1)\n",
    "dm.X_test_estimated_b = dm.X_test_estimated_b.drop(\"elevation:m\", axis=1)\n",
    "dm.X_test_estimated_c = dm.X_test_estimated_c.drop(\"elevation:m\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data editing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resample(df:pd.DataFrame): \n",
    "\n",
    "    categorical_feature = [\"date_forecast\", \"is_day:idx\", \"is_in_shadow:idx\", \"clear_sky_energy_1h:J\", \"diffuse_rad_1h:J\", \"direct_rad_1h:J\", \"fresh_snow_12h:cm\", \"fresh_snow_24h:cm\", \"precip_type_5min:idx\"]\n",
    "\n",
    "    categorical_set = df.loc[:, categorical_feature][::4].copy()\n",
    "\n",
    "    resampled_set = df.resample('1H', on=\"date_forecast\").agg({\"precip_5min:mm\":np.sum, \"rain_water:kgm2\":np.sum, \"snow_water:kgm2\":np.sum, \"super_cooled_liquid_water:kgm2\":np.mean, \n",
    "                                                                \"absolute_humidity_2m:gm3\":np.mean, \"air_density_2m:kgm3\":np.mean, \"clear_sky_rad:W\":np.mean, \"dew_point_2m:K\":np.mean, \"clear_sky_rad:W\":np.mean, \"diffuse_rad:W\":np.mean, \"direct_rad:W\":np.mean, \"effective_cloud_cover:p\":np.mean, \"msl_pressure:hPa\":np.mean, \"pressure_100m:hPa\":np.mean, \"pressure_50m:hPa\":np.mean, \"relative_humidity_1000hPa:p\":np.mean, \"sfc_pressure:hPa\":np.mean, \"sun_azimuth:d\":np.mean, \"sun_elevation:d\":np.mean, \"t_1000hPa:K\":np.mean, \"total_cloud_cover:p\":np.mean, \"visibility:m\":np.mean, \"wind_speed_10m:ms\":np.mean, \"wind_speed_u_10m:ms\":np.mean, \"wind_speed_v_10m:ms\":np.mean, \"cloud_base_agl:m\":np.mean}).copy()\n",
    "\n",
    "    combined = pd.merge(categorical_set, resampled_set, how=\"left\", on=\"date_forecast\")\n",
    "    \n",
    "    return combined\n",
    "\n",
    "dm.X_train_observed_a = resample(dm.X_train_observed_a)\n",
    "dm.X_train_observed_b = resample(dm.X_train_observed_b)\n",
    "dm.X_train_observed_c = resample(dm.X_train_observed_c)\n",
    "\n",
    "dm.X_train_estimated_a = resample(dm.X_train_estimated_a)\n",
    "dm.X_train_estimated_b = resample(dm.X_train_estimated_b)\n",
    "dm.X_train_estimated_c = resample(dm.X_train_estimated_c)\n",
    "\n",
    "dm.X_test_estimated_a = resample(dm.X_test_estimated_a)\n",
    "dm.X_test_estimated_b = resample(dm.X_test_estimated_b)\n",
    "dm.X_test_estimated_c = resample(dm.X_test_estimated_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(obs:pd.DataFrame, es:pd.DataFrame, train:pd.DataFrame): \n",
    "    weather_data = pd.concat([obs, es], axis=0)\n",
    "\n",
    "    data = pd.merge(weather_data, train, how=\"left\", on=\"date_forecast\").dropna().reset_index(drop=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "dm.data_A = combine(dm.X_train_observed_a, dm.X_train_estimated_a, dm.train_a)\n",
    "dm.data_B = combine(dm.X_train_observed_b, dm.X_train_estimated_b, dm.train_b)\n",
    "dm.data_C = combine(dm.X_train_observed_c, dm.X_train_estimated_c, dm.train_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constant intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "#plt.scatter(dm.data_B[\"date_forecast\"], dm.data_B[\"pv_measurement\"], s=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm.remove_constant_periods(24)\n",
    "# dm.remove_constant_periods(3, [0])\n",
    "\n",
    "val = None\n",
    "counter = 0\n",
    "consequtive_zero_threshold = 23\n",
    "threshold = 0.0\n",
    "\n",
    "def remove_const_intervals(row):\n",
    "    global val\n",
    "    global counter\n",
    "    global consequtive_zero_threshold\n",
    "\n",
    "    if val is None: # init val as row \n",
    "        val = row\n",
    "        return False\n",
    "\n",
    "    elif val == 0.0: ## if the current value is 0.0 \n",
    "\n",
    "        counter += 1 ## we count this \n",
    "\n",
    "        if counter >= consequtive_zero_threshold: ## number of seen consequtive zeros are above threshold\n",
    "            val = row\n",
    "            counter += 1\n",
    "            return False\n",
    "        \n",
    "        else: \n",
    "            val = row\n",
    "            return True ## we have not yet gone past threshold\n",
    "\n",
    "    elif abs(row-val)<= threshold: ## we see a value (not zero) if below threshold we remove, this also indicates a break in any streak of zeros, setting counter to zero\n",
    "        val = row\n",
    "        counter = 0\n",
    "        return False\n",
    "    \n",
    "    counter = 0\n",
    "    val = row\n",
    "    return True ## if all else fails, we keep the row. \n",
    "\n",
    "\n",
    "dm.data_A = dm.data_A[dm.data_A['pv_measurement'].map(remove_const_intervals)].reset_index(drop=True)\n",
    "dm.data_B = dm.data_B[dm.data_B['pv_measurement'].map(remove_const_intervals)].reset_index(drop=True)\n",
    "dm.data_C = dm.data_C[dm.data_C['pv_measurement'].map(remove_const_intervals)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "#plt.scatter(dm.data_B[\"date_forecast\"], dm.data_B[\"pv_measurement\"], s=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-C donation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def donate_missing_pv(donating:pd.DataFrame, recieving:pd.DataFrame, scaling:float=1):\n",
    "    \n",
    "#     recieving_frame = recieving.copy()\n",
    "\n",
    "#     recieving_dates = np.array(recieving_frame[\"date_forecast\"])\n",
    "#     beginning_date = recieving_dates[0]\n",
    "\n",
    "#     for index, row in donating.iterrows():\n",
    "\n",
    "#         if row[\"date_forecast\"] not in recieving_dates and row[\"date_forecast\"] > beginning_date: \n",
    "\n",
    "#             row = row\n",
    "#             if row[\"pv_measurement\"] == 0.0 or row[\"pv_measurement\"] == -0.0: \n",
    "#                 pv = 0.0\n",
    "\n",
    "#             else : \n",
    "#                 pv = row[\"pv_measurement\"] * scaling\n",
    "\n",
    "\n",
    "#             row[\"pv_measurement\"] = pv\n",
    "\n",
    "#             recieving_frame.loc[len(recieving_frame.index)] = row \n",
    "\n",
    "    \n",
    "#     return recieving_frame.sort_values(by=\"date_forecast\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# data_B = donate_missing_pv(dm.data_C, dm.data_B, 1.2)\n",
    "# data_C = donate_missing_pv(dm.data_B, dm.data_C, 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm.data_B = data_B\n",
    "# dm.data_C = data_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X_test_estimated_a', 'data_A']\n",
      "['X_test_estimated_b', 'data_B']\n",
      "['X_test_estimated_c', 'data_C']\n"
     ]
    }
   ],
   "source": [
    "dm.combine_all_data()\n",
    "\n",
    "dm.sorting_columns_inMainSets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.data_A.dtypes \n",
    "\n",
    "dm.data_A[list(dm.data_A.select_dtypes(include='float32'))] = dm.data_A[list(dm.data_A.select_dtypes(include='float32'))].astype('float64')\n",
    "dm.data_B[list(dm.data_B.select_dtypes(include='float32'))] = dm.data_B[list(dm.data_B.select_dtypes(include='float32'))].astype('float64')\n",
    "dm.data_C[list(dm.data_C.select_dtypes(include='float32'))] = dm.data_C[list(dm.data_C.select_dtypes(include='float32'))].astype('float64')\n",
    "\n",
    "dm.X_test_estimated_a[list(dm.X_test_estimated_a.select_dtypes(include='float32'))] = dm.X_test_estimated_a[list(dm.X_test_estimated_a.select_dtypes(include='float32'))].astype('float64')\n",
    "dm.X_test_estimated_b[list(dm.X_test_estimated_b.select_dtypes(include='float32'))] = dm.X_test_estimated_b[list(dm.X_test_estimated_b.select_dtypes(include='float32'))].astype('float64')\n",
    "dm.X_test_estimated_c[list(dm.X_test_estimated_c.select_dtypes(include='float32'))] = dm.X_test_estimated_c[list(dm.X_test_estimated_c.select_dtypes(include='float32'))].astype('float64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "\n",
    "data_A = dm.data_A\n",
    "data_B = dm.data_B\n",
    "data_C = dm.data_C\n",
    "\n",
    "test_A = dm.X_test_estimated_a\n",
    "test_B = dm.X_test_estimated_b\n",
    "test_C = dm.X_test_estimated_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark estimated data\n",
    "\n",
    "est_dates_A = pd.to_datetime(dm.X_train_estimated_a['date_forecast'])\n",
    "est_dates_B = pd.to_datetime(dm.X_train_estimated_b['date_forecast'])\n",
    "est_dates_C = pd.to_datetime(dm.X_train_estimated_c['date_forecast'])\n",
    "\n",
    "data_A['est'] = (pd.to_datetime(data_A['date_forecast']).isin(est_dates_A)).astype(int)\n",
    "data_B['est'] = (pd.to_datetime(data_B['date_forecast']).isin(est_dates_B)).astype(int)\n",
    "data_C['est'] = (pd.to_datetime(data_C['date_forecast']).isin(est_dates_C)).astype(int)\n",
    "\n",
    "test_A['est'] = 1\n",
    "test_B['est'] = 1\n",
    "test_C['est'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full dataset\n",
    "\n",
    "data_A['train'] = 1\n",
    "data_B['train'] = 1\n",
    "data_C['train'] = 1\n",
    "\n",
    "test_A['train'] = 0\n",
    "test_B['train'] = 0\n",
    "test_C['train'] = 0\n",
    "\n",
    "test_A['pv_measurement'] = np.nan\n",
    "test_B['pv_measurement'] = np.nan\n",
    "test_C['pv_measurement'] = np.nan\n",
    "\n",
    "data_test_A = pd.concat([data_A, test_A], ignore_index=True)\n",
    "data_test_B = pd.concat([data_B, test_B], ignore_index=True)\n",
    "data_test_C = pd.concat([data_C, test_C], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set location as categorical\n",
    "\n",
    "data_test_A['A'] = 1\n",
    "data_test_A['B'] = 0\n",
    "data_test_A['C'] = 0\n",
    "\n",
    "data_test_B['A'] = 0\n",
    "data_test_B['B'] = 1\n",
    "data_test_B['C'] = 0\n",
    "\n",
    "data_test_C['A'] = 0\n",
    "data_test_C['B'] = 0\n",
    "data_test_C['C'] = 1\n",
    "\n",
    "data_test_A = data_test_A.drop('location', axis='columns')\n",
    "data_test_B = data_test_B.drop('location', axis='columns')\n",
    "data_test_C = data_test_C.drop('location', axis='columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precip type to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allready removed\n",
    "\n",
    "\n",
    "categories = ['precip_none', 'precip_rain', 'precip_rain_Snow', 'precip_snow', 'precip_sleet', 'precip_freezing_rain', 'precip_hail']\n",
    "\n",
    "def add_precip_category(df, categories):\n",
    "    # Assuming 'precip_type_5min:idx' contains integer category indices\n",
    "    # Ensure the indices are integers\n",
    "    df['precip_type_5min:idx'] = df['precip_type_5min:idx'].astype(int)\n",
    "\n",
    "    # Get dummies and concatenate with the original dataframe\n",
    "    dummies = pd.get_dummies(df['precip_type_5min:idx'], prefix='precip_type').astype(int)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function\n",
    "data_test_A = add_precip_category(data_test_A, categories)\n",
    "data_test_B = add_precip_category(data_test_B, categories)\n",
    "data_test_C = add_precip_category(data_test_C, categories)\n",
    "# Drop precip_type\n",
    "data_test_A = data_test_A.drop('precip_type_5min:idx', axis='columns')\n",
    "data_test_B = data_test_B.drop('precip_type_5min:idx', axis='columns')\n",
    "data_test_C = data_test_C.drop('precip_type_5min:idx', axis='columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates columns\n",
    "\n",
    "def extract_dates(df):\n",
    "    # Convert 'date_forecast' to datetime\n",
    "    df['date_forecast'] = pd.to_datetime(df['date_forecast'])\n",
    "\n",
    "    # Extract year, month, and day\n",
    "    df['year'] = df['date_forecast'].dt.year\n",
    "    df['month'] = df['date_forecast'].dt.month\n",
    "    df['day'] = df['date_forecast'].dt.day\n",
    "\n",
    "    return df\n",
    "\n",
    "data_test_A = extract_dates(data_test_A)\n",
    "data_test_B = extract_dates(data_test_B)\n",
    "data_test_C = extract_dates(data_test_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add daily and annual sinus curve\n",
    "\n",
    "def hour_func(x): \n",
    "    return np.cos(2*np.pi/24 * x)\n",
    "\n",
    "data_test_A[\"daily_sinus\"] = hour_func(data_test_A[\"date_forecast\"].dt.hour)\n",
    "data_test_B[\"daily_sinus\"] = hour_func(data_test_B[\"date_forecast\"].dt.hour)\n",
    "data_test_C[\"daily_sinus\"] = hour_func(data_test_C[\"date_forecast\"].dt.hour)\n",
    "\n",
    "#plot_feature(data_test_A.iloc[:40], 'daily_sinus')\n",
    "\n",
    "def day_func(x): \n",
    "    return np.cos(2*np.pi/365 * x - 2*np.pi/365 * 173)\n",
    "\n",
    "data_test_A[\"annual_sinus\"] = day_func(data_test_A[\"date_forecast\"].dt.dayofyear)\n",
    "data_test_B[\"annual_sinus\"] = day_func(data_test_B[\"date_forecast\"].dt.dayofyear)\n",
    "data_test_C[\"annual_sinus\"] = day_func(data_test_C[\"date_forecast\"].dt.dayofyear)\n",
    "\n",
    "#plot_feature(data_test_A.iloc[8000:10000], 'annual_sinus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark weird cloud data as category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_A['bad_cloud_data'] = (data_test_A['date_forecast'] < pd.to_datetime('2020-03-26 00:00:00')).astype(int)\n",
    "data_test_B['bad_cloud_data'] = (data_test_B['date_forecast'] < pd.to_datetime('2020-03-26 00:00:00')).astype(int)\n",
    "data_test_C['bad_cloud_data'] = (data_test_C['date_forecast'] < pd.to_datetime('2020-03-26 00:00:00')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip sun elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When sun elevation is below ca. -5, no pv_measurement is recorded\n",
    "\n",
    "data_test_A['sun_elevation:d'] = data_test_A['sun_elevation:d'].clip(lower=0)\n",
    "data_test_B['sun_elevation:d'] = data_test_B['sun_elevation:d'].clip(lower=0)\n",
    "data_test_C['sun_elevation:d'] = data_test_C['sun_elevation:d'].clip(lower=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mask for open sky, clip negative values for clouds\n",
    "\n",
    "data_test_A['open_sky'] = ( data_test_A['cloud_base_agl:m'] < 0).astype(int)\n",
    "data_test_B['open_sky'] = ( data_test_B['cloud_base_agl:m'] < 0).astype(int)\n",
    "data_test_C['open_sky'] = ( data_test_C['cloud_base_agl:m'] < 0).astype(int)\n",
    "\n",
    "#data_test_A['cloud_base_agl:m'] = data_test_A['cloud_base_agl:m'].clip(lower=0)\n",
    "#data_test_B['cloud_base_agl:m'] = data_test_B['cloud_base_agl:m'].clip(lower=0)\n",
    "#data_test_C['cloud_base_agl:m'] = data_test_C['cloud_base_agl:m'].clip(lower=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag and lead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag and lead for direct sun rad\n",
    "\n",
    "def create_lag_average_column(df, column_name, lag_window):\n",
    "    \"\"\"\n",
    "    Creates a new column in the DataFrame which is the average of the last 3 rows of the specified column.\n",
    "    For the first two rows, it uses the available values for averaging.\n",
    "\n",
    "    :param df: Pandas DataFrame.\n",
    "    :param column_name: The name of the column for which the lagged average is calculated.\n",
    "    :return: DataFrame with the new lag average column added.\n",
    "    \"\"\"\n",
    "    # Ensure that the DataFrame has the specified column\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    # Calculate the rolling average of the last 3 rows\n",
    "    df[f'{column_name}_lag_avg'] = df[column_name].rolling(window=lag_window, min_periods=1).mean()\n",
    "\n",
    "    return df\n",
    "\n",
    "lag_window = 10\n",
    "\n",
    "data_test_A = create_lag_average_column(data_test_A, 'direct_rad:W', lag_window)\n",
    "data_test_B = create_lag_average_column(data_test_B, 'direct_rad:W', lag_window)\n",
    "data_test_C = create_lag_average_column(data_test_C, 'direct_rad:W', lag_window)\n",
    "\n",
    "#data_test_A = create_lag_average_column(data_test_A, 'diffuse_rad:W', lag_window)\n",
    "#data_test_B = create_lag_average_column(data_test_B, 'diffuse_rad:W', lag_window)\n",
    "#data_test_C = create_lag_average_column(data_test_C, 'diffuse_rad:W', lag_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuing with lead\n",
    "\n",
    "def create_lead_average_column(df, column_name, lead_window):\n",
    "    \"\"\"\n",
    "    Creates a new column in the DataFrame which is the average of the next 3 rows of the specified column.\n",
    "    For the last two rows, it uses the available values for averaging.\n",
    "\n",
    "    :param df: Pandas DataFrame.\n",
    "    :param column_name: The name of the column for which the lead average is calculated.\n",
    "    :return: DataFrame with the new lead average column added.\n",
    "    \"\"\"\n",
    "    # Ensure that the DataFrame has the specified column\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    # Reverse the DataFrame, calculate the rolling average, and then reverse it back\n",
    "    df_reversed = df.iloc[::-1].copy()\n",
    "    df_reversed[f'{column_name}_lead_avg'] = df_reversed[column_name].rolling(window=lead_window, min_periods=1).mean()\n",
    "    df[f'{column_name}_lead_avg'] = df_reversed[f'{column_name}_lead_avg'].iloc[::-1].values\n",
    "\n",
    "    return df\n",
    "\n",
    "lead_window = 1\n",
    "\n",
    "data_test_A = create_lead_average_column(data_test_A, 'direct_rad:W', lead_window)\n",
    "data_test_B = create_lead_average_column(data_test_B, 'direct_rad:W', lead_window)\n",
    "data_test_C = create_lead_average_column(data_test_C, 'direct_rad:W', lead_window)\n",
    "\n",
    "#data_test_A = create_lead_average_column(data_test_A, 'diffuse_rad:W', lead_window)\n",
    "#data_test_B = create_lead_average_column(data_test_B, 'diffuse_rad:W', lead_window)\n",
    "#data_test_C = create_lead_average_column(data_test_C, 'diffuse_rad:W', lead_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create central derivative column\n",
    "\n",
    "def create_central_difference_column(df, column_name, new_column_name):\n",
    "    \"\"\"\n",
    "    Creates a new column in the DataFrame which is the central difference of the specified column with respect\n",
    "    to the previous and next row. For the first and last rows, forward and backward differences are used.\n",
    "\n",
    "    :param df: Pandas DataFrame.\n",
    "    :param column_name: The name of the column for which the central difference is calculated.\n",
    "    :param new_column_name: The name of the new column to store the central difference.\n",
    "    :return: DataFrame with the new central difference column added.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that the DataFrame has the specified column\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    # Calculate the central difference\n",
    "    df[new_column_name] = (df[column_name].shift(-1) - df[column_name].shift(1)) / 2\n",
    "\n",
    "    # Handle the first row using forward difference\n",
    "    df.at[0, new_column_name] = df.at[1, column_name] - df.at[0, column_name]\n",
    "\n",
    "    # Handle the last row using backward difference\n",
    "    last_idx = df.index[-1]\n",
    "    df.at[last_idx, new_column_name] = df.at[last_idx, column_name] - df.at[last_idx - 1, column_name]\n",
    "\n",
    "    return df\n",
    "\n",
    "data_test_A = create_central_difference_column(data_test_A, 'direct_rad:W', 'direct_rad_CD')\n",
    "data_test_B = create_central_difference_column(data_test_B, 'direct_rad:W', 'direct_rad_CD')\n",
    "data_test_C = create_central_difference_column(data_test_C, 'direct_rad:W', 'direct_rad_CD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create difference between columns\n",
    "\n",
    "def create_difference_column(df, column1, column2, new_column_name):\n",
    "    \"\"\"\n",
    "    Creates a new column in the DataFrame which is the difference between two specified columns.\n",
    "\n",
    "    :param df: Pandas DataFrame.\n",
    "    :param column1: The name of the first column.\n",
    "    :param column2: The name of the second column.\n",
    "    :param new_column_name: The name of the new column to store the difference.\n",
    "    :return: DataFrame with the new difference column added.\n",
    "    \"\"\"\n",
    "    # Ensure that the DataFrame has the specified columns\n",
    "    if column1 not in df.columns:\n",
    "        raise ValueError(f\"Column '{column1}' not found in the DataFrame.\")\n",
    "    if column2 not in df.columns:\n",
    "        raise ValueError(f\"Column '{column2}' not found in the DataFrame.\")\n",
    "\n",
    "    # Calculate the difference and store it in the new column\n",
    "    df[new_column_name] = df[column1] - df[column2]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#data_test_A = create_difference_column(data_test_A, 'is_day:idx', 'is_in_shadow:idx', 'diff_day_shadow')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless columns\n",
    "useless_col = [\n",
    "    'fresh_snow_12h:cm',\n",
    "    'fresh_snow_24h:cm',\n",
    "    'pressure_50m:hPa',\n",
    "    'msl_pressure:hPa',\n",
    "    'sfc_pressure:hPa',\n",
    "    'precip_type_2',\n",
    "    'precip_type_3',\n",
    "]\n",
    "\n",
    "data_test_A = data_test_A.drop(useless_col, axis='columns')\n",
    "data_test_B = data_test_B.drop(useless_col, axis='columns')\n",
    "data_test_C = data_test_C.drop(useless_col, axis='columns')\n",
    "\n",
    "data_test_A = data_test_A.drop(['precip_type_5', 'precip_type_6'], axis='columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split, combine, sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by train / test\n",
    "\n",
    "data_A = data_test_A[ data_test_A['train'] == 1 ]\n",
    "data_B = data_test_B[ data_test_B['train'] == 1 ]\n",
    "data_C = data_test_C[ data_test_C['train'] == 1 ]\n",
    "\n",
    "test_A = data_test_A[ data_test_A['train'] == 0 ]\n",
    "test_B = data_test_B[ data_test_B['train'] == 0 ]\n",
    "test_C = data_test_C[ data_test_C['train'] == 0 ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN pv_measurement\n",
    "test_A = test_A.drop('pv_measurement', axis='columns')\n",
    "test_B = test_B.drop('pv_measurement', axis='columns')\n",
    "test_C = test_C.drop('pv_measurement', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "data_ALL = pd.concat([data_A, data_B, data_C], ignore_index=True)\n",
    "test_ALL = pd.concat([test_A, test_B, test_C], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date forecast\n",
    "data_ALL = data_ALL.sort_values(['date_forecast', 'A', 'B', 'C'], ascending=[True, False, False, False])\n",
    "test_ALL = test_ALL.sort_values(['date_forecast', 'A', 'B', 'C'], ascending=[True, False, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename\n",
    "data_ALL.rename(columns={'pv_measurement': 'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data_ALL.drop('target', axis='columns')\n",
    "y = data_ALL[['date_forecast', 'target']]\n",
    "X_kaggle = test_ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "def split_data(df, percent):\n",
    "    split_index = int( np.floor( len(df)*percent ) )\n",
    "    df_first = df[:split_index]\n",
    "    df_last = df[split_index:]\n",
    "    return df_first, df_last\n",
    "\n",
    "train_percent = 0.92 # Of all\n",
    "val_percent = 0.5 # Of non-train\n",
    "\n",
    "X_train, X_non_train = split_data(X, train_percent)\n",
    "X_val, X_test = split_data(X_non_train, val_percent)\n",
    "\n",
    "y_train, y_non_train = split_data(y, train_percent)\n",
    "y_val, y_test = split_data(y_non_train, val_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set val data to summer last year (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX[\\'date_forecast\\'] = pd.to_datetime(X[\\'date_forecast\\'])\\ny[\\'date_forecast\\'] = pd.to_datetime(y[\\'date_forecast\\'])\\n\\n# Define your date range\\nstart_date = \"2022-04-01 00:00:00\"\\nend_date = \"2022-08-03 23:00:00\"\\n\\n# Convert strings to datetime\\nstart_date = pd.to_datetime(start_date)\\nend_date = pd.to_datetime(end_date)\\n\\n# Filter rows within the date range\\nmask_X = (X[\\'date_forecast\\'] >= start_date) & (X[\\'date_forecast\\'] <= end_date)\\nmask_y = (y[\\'date_forecast\\'] >= start_date) & (y[\\'date_forecast\\'] <= end_date)\\nX_val = X.loc[mask_X]\\ny_val = y.loc[mask_y]\\n\\n# Pop out rows within the date range to remove them from the original df\\nX_train = X.loc[~mask_X]\\ny_train = y.loc[~mask_y]\\n'"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X['date_forecast'] = pd.to_datetime(X['date_forecast'])\n",
    "y['date_forecast'] = pd.to_datetime(y['date_forecast'])\n",
    "\n",
    "# Define your date range\n",
    "start_date = \"2022-04-01 00:00:00\"\n",
    "end_date = \"2022-08-03 23:00:00\"\n",
    "\n",
    "# Convert strings to datetime\n",
    "start_date = pd.to_datetime(start_date)\n",
    "end_date = pd.to_datetime(end_date)\n",
    "\n",
    "# Filter rows within the date range\n",
    "mask_X = (X['date_forecast'] >= start_date) & (X['date_forecast'] <= end_date)\n",
    "mask_y = (y['date_forecast'] >= start_date) & (y['date_forecast'] <= end_date)\n",
    "X_val = X.loc[mask_X]\n",
    "y_val = y.loc[mask_y]\n",
    "\n",
    "# Pop out rows within the date range to remove them from the original df\n",
    "X_train = X.loc[~mask_X]\n",
    "y_train = y.loc[~mask_y]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter X and y by summer months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y[ X['date_forecast'].dt.month.between(4, 8) ]\n",
    "#X = X[ X['date_forecast'].dt.month.between(4, 8) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load external data (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ALL_to_sub = pd.read_csv(\"current_csv_files/test_ALL.csv\")\n",
    "test_ALL_to_sub_ABC = test_ALL_to_sub.sort_values(['A', 'B', 'C', 'date_forecast'], ascending=[False, False, False, True])\n",
    "y_hat_kaggle = pd.read_csv(\"teo_subs/kaggle_149.csv\", index_col='id')\n",
    "test_ALL_to_sub_ABC['new_index'] = range(2160)\n",
    "test_ALL_to_sub_ABC = test_ALL_to_sub_ABC.set_index('new_index')\n",
    "test_ALL_to_sub_ABC['y_hat_kaggle'] = y_hat_kaggle\n",
    "test_ALL_to_sub_sorted = test_ALL_to_sub_ABC.sort_values(['date_forecast', 'A', 'B', 'C'], ascending=[True, False, False, False])\n",
    "test_ALL_to_sub_sorted = test_ALL_to_sub_sorted.set_index('date_forecast')\n",
    "y_hat = test_ALL_to_sub_sorted['y_hat_kaggle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set date as index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.set_index('date_forecast')\n",
    "y = y.set_index('date_forecast')\n",
    "\n",
    "X_train = X_train.set_index('date_forecast')\n",
    "y_train = y_train.set_index('date_forecast')\n",
    "\n",
    "X_non_train = X_non_train.set_index('date_forecast')\n",
    "y_non_train = y_non_train.set_index('date_forecast')\n",
    "\n",
    "X_val = X_val.set_index('date_forecast')\n",
    "y_val = y_val.set_index('date_forecast')\n",
    "\n",
    "X_test = X_test.set_index('date_forecast')\n",
    "y_test = y_test.set_index('date_forecast')\n",
    "\n",
    "X_kaggle = X_kaggle.set_index('date_forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for scaling\n",
    "\n",
    "feature_dont_touch = [\n",
    "    'date_forecast',\n",
    "    'is_day:idx',\n",
    "    'is_in_shadow:idx',\n",
    "    'pv_measurement',\n",
    "    'est',\n",
    "    'train',\n",
    "    'A',\n",
    "    'B',\n",
    "    'C',\n",
    "    'daily_sinus',\n",
    "    'annual_sinus',\n",
    "    'bad_cloud_data',\n",
    "    'open_sky',\n",
    "\n",
    "    # Kinda useless\n",
    "    'dew_or_rime:idx'\n",
    "]\n",
    "\n",
    "feature_to_standardize = [\n",
    "    'absolute_humidity_2m:gm3',\n",
    "    'air_density_2m:kgm3',\n",
    "    'dew_point_2m:K',\n",
    "    'pressure_100m:hPa',\n",
    "    'relative_humidity_1000hPa:p',\n",
    "    't_1000hPa:K',\n",
    "    'wind_speed_u_10m:ms',\n",
    "    'wind_speed_v_10m:ms',\n",
    "    'direct_rad_CD', # Central difference\n",
    "\n",
    "    # Kinda useless\n",
    "    #'pressure_50m:hPa',\n",
    "    #'msl_pressure:hPa',\n",
    "    #'sfc_pressure:hPa',\n",
    "]\n",
    "\n",
    "feature_to_normalize = [\n",
    "    'cloud_base_agl:m',\n",
    "    'clear_sky_energy_1h:J',\n",
    "    'diffuse_rad_1h:J',\n",
    "    'direct_rad_1h:J',\n",
    "    'precip_5min:mm',\n",
    "    'rain_water:kgm2',\n",
    "    'snow_water:kgm2',\n",
    "    'super_cooled_liquid_water:kgm2',\n",
    "    'clear_sky_rad:W',\n",
    "    'diffuse_rad:W',\n",
    "    'direct_rad:W',\n",
    "    'direct_rad:W_lag_avg', # Lag\n",
    "    'direct_rad:W_lead_avg', # Lead\n",
    "    'effective_cloud_cover:p',\n",
    "    'sun_azimuth:d',\n",
    "    'total_cloud_cover:p',\n",
    "    'visibility:m',\n",
    "    'wind_speed_10m:ms',\n",
    "    'sun_elevation:d', # Clipped version\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "\n",
    "    # Kinda useless\n",
    "    #'fresh_snow_12h:cm',\n",
    "    #'fresh_snow_24h:cm'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "for feature in feature_to_standardize:\n",
    "    #X_train[feature] = standard_scaler.fit_transform(X_train[[feature]])\n",
    "    X[feature] = standard_scaler.fit_transform(X[[feature]])\n",
    "    \n",
    "    X_non_train[feature] = standard_scaler.transform(X_non_train[[feature]])\n",
    "    X_val[feature] = standard_scaler.transform(X_val[[feature]])\n",
    "    X_test[feature] = standard_scaler.transform(X_test[[feature]])\n",
    "    X_kaggle[feature] = standard_scaler.transform(X_kaggle[[feature]])\n",
    "    \n",
    "\n",
    "for feature in feature_to_normalize:\n",
    "    #X_train[feature] = standard_scaler.fit_transform(X_train[[feature]])\n",
    "    X[feature] = min_max_scaler.fit_transform(X[[feature]])\n",
    "    \n",
    "    X_non_train[feature] = min_max_scaler.transform(X_non_train[[feature]])\n",
    "    X_val[feature] = min_max_scaler.transform(X_val[[feature]])\n",
    "    X_test[feature] = min_max_scaler.transform(X_test[[feature]])\n",
    "    X_kaggle[feature] = min_max_scaler.transform(X_kaggle[[feature]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split by location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_A = X[ X['A'] == 1 ]\\nX_B = X[ X['B'] == 1 ]\\nX_C = X[ X['C'] == 1 ]\\n\\ny_A = y[ X['A'] == 1 ]\\ny_B = y[ X['B'] == 1 ]\\ny_C = y[ X['C'] == 1 ]\\n\\nX_A_kaggle = X_kaggle[ X_kaggle['A'] == 1 ]\\nX_B_kaggle = X_kaggle[ X_kaggle['B'] == 1 ]\\nX_C_kaggle = X_kaggle[ X_kaggle['C'] == 1 ]\\n\\ny_A_hat = y_hat[ X_kaggle['A'] == 1 ]\\ny_B_hat = y_hat[ X_kaggle['B'] == 1 ]\\ny_C_hat = y_hat[ X_kaggle['C'] == 1 ]\\n\""
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X_A = X[ X['A'] == 1 ]\n",
    "X_B = X[ X['B'] == 1 ]\n",
    "X_C = X[ X['C'] == 1 ]\n",
    "\n",
    "y_A = y[ X['A'] == 1 ]\n",
    "y_B = y[ X['B'] == 1 ]\n",
    "y_C = y[ X['C'] == 1 ]\n",
    "\n",
    "X_A_kaggle = X_kaggle[ X_kaggle['A'] == 1 ]\n",
    "X_B_kaggle = X_kaggle[ X_kaggle['B'] == 1 ]\n",
    "X_C_kaggle = X_kaggle[ X_kaggle['C'] == 1 ]\n",
    "\n",
    "y_A_hat = y_hat[ X_kaggle['A'] == 1 ]\n",
    "y_B_hat = y_hat[ X_kaggle['B'] == 1 ]\n",
    "y_C_hat = y_hat[ X_kaggle['C'] == 1 ]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModelCheckpoint(Callback):\n",
    "    def __init__(self, best_weights, best_epochs, i):\n",
    "        self.best_weights = best_weights  # Dictionary to store best weights\n",
    "        self.best_epochs = best_epochs    # Dictionary to store best epoch numbers\n",
    "        self.best_loss = np.inf\n",
    "        self.model_index = i  # Index to handle the specific model in the list\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Monitor the validation loss\n",
    "        current_val_loss = logs.get('val_loss')\n",
    "        if current_val_loss < self.best_loss:\n",
    "            # Update the best loss, best weights, and best epoch\n",
    "            self.best_loss = current_val_loss\n",
    "            self.best_weights[self.model_index] = self.model.get_weights()\n",
    "            self.best_epochs[self.model_index] = epoch\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    \n",
    "    trial_params = {\n",
    "        'seed': trial.number + 50,\n",
    "        'N': trial.suggest_int('N', 1, 3),\n",
    "        'n_neurons_1': trial.suggest_int('n_neurons_1', 140, 180),\n",
    "        'n_neurons_2': trial.suggest_int('n_neurons_2', 150, 200),\n",
    "        'n_neurons_3': trial.suggest_int('n_neurons_3', 150, 200),\n",
    "        'n_neurons_3.5': trial.suggest_int('n_neurons_3', 90, 130),\n",
    "        'n_neurons_4': trial.suggest_int(\"n_neurons_4\", 60, 90),\n",
    "        'Dropout': trial.suggest_float('Dropout', 0.05, 0.2),\n",
    "        'kernel_regularizer': trial.suggest_float('kernel_regularizer', 0.05, 0.25),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.00075, 0.0012),\n",
    "        'beta_1': trial.suggest_float('beta_1', 0.75, 0.9),\n",
    "        'min_delta': trial.suggest_float('min_delta', 5, 20),\n",
    "        'patience': 10, #trial.suggest_int('patience', 3, 8),\n",
    "        'batch_size': trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    }\n",
    "\n",
    "    s = trial_params['seed']\n",
    "    print(\"Seed: \", str(s))\n",
    "    np.random.seed(s)\n",
    "    random.seed(s)\n",
    "    tf.random.set_seed(s)\n",
    "\n",
    "    N = trial_params['N']\n",
    "    nets = []\n",
    "    init = 'HeNormal'\n",
    "\n",
    "    # Initialize dictionary to store the best weights for each model\n",
    "    best_weights_during_training = {}\n",
    "    best_epochs_during_training = {}\n",
    "\n",
    "    for i in range(N):\n",
    "        # Define the Keras model\n",
    "        model = Sequential([\n",
    "            Dense(trial_params[\"n_neurons_1\"], input_dim=X.shape[1], activation='relu', kernel_initializer=init),\n",
    "            Dropout(trial_params['Dropout']),\n",
    "\n",
    "            Dense(trial_params[\"n_neurons_2\"], activation='relu', kernel_initializer=init, kernel_regularizer=l2(trial_params[\"kernel_regularizer\"])),\n",
    "            Dropout(trial_params['Dropout']),\n",
    "\n",
    "            Dense(trial_params[\"n_neurons_3\"], activation='relu', kernel_initializer=init, kernel_regularizer=l2(trial_params[\"kernel_regularizer\"])),\n",
    "            Dropout(trial_params['Dropout']),\n",
    "\n",
    "            Dense(trial_params[\"n_neurons_3.5\"], activation='relu', kernel_initializer=init, kernel_regularizer=l2(trial_params[\"kernel_regularizer\"])),\n",
    "            Dropout(trial_params['Dropout']),\n",
    "            \n",
    "            Dense(trial_params[\"n_neurons_4\"], activation='relu', kernel_initializer=init, kernel_regularizer=l2(trial_params[\"kernel_regularizer\"])),\n",
    "            Dense(1, kernel_initializer=init)\n",
    "        ])\n",
    "        nets.append(model)\n",
    "\n",
    "        adam = Adam(learning_rate=trial_params[\"learning_rate\"], beta_1=trial_params[\"beta_1\"])\n",
    "        model.compile(loss='mean_absolute_error', optimizer=adam)\n",
    "\n",
    "        # Define early stopping\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=trial_params['min_delta'], patience=trial_params['patience'])\n",
    "\n",
    "        # Create an instance of the custom checkpoint for the current model\n",
    "        custom_checkpoint = CustomModelCheckpoint(best_weights_during_training, best_epochs_during_training, i)\n",
    "        \n",
    "        # Fit the model\n",
    "        history = model.fit(\n",
    "            X, y,\n",
    "            validation_data=(X_kaggle, y_hat),\n",
    "            #validation_split=0.2,\n",
    "            epochs=100,\n",
    "            batch_size=trial_params['batch_size'],\n",
    "            callbacks=[early_stopping, custom_checkpoint],\n",
    "            verbose=0,\n",
    "            use_multiprocessing=True, workers=4,\n",
    "        )\n",
    "\n",
    "\n",
    "        if i not in best_weights_during_training:\n",
    "            # If the model didn't improve, just save the last weights and epoch number\n",
    "            best_weights_during_training[i] = model.get_weights()\n",
    "            best_epochs_during_training[i] = len(history.epoch)\n",
    "\n",
    "\n",
    "    # Set weights and print epoch\n",
    "    for i in range(N):\n",
    "        nets[i].set_weights(best_weights_during_training[i])\n",
    "        print(\"Best epoch: \", best_epochs_during_training[i] +1) # It's plus one for some reason. Idk it works\n",
    "    \n",
    "    # Make kaggle prediction\n",
    "    best_kaggle_preds = []\n",
    "\n",
    "    for i in range(N):\n",
    "        best_kaggle_preds.append(nets[i].predict(X_kaggle, verbose=0).ravel())\n",
    "    \n",
    "    # Create dataframe for kaggle pred\n",
    "    df_kaggle_preds = pd.DataFrame(best_kaggle_preds).T\n",
    "    df_kaggle_preds['avg'] = df_kaggle_preds.mean(axis='columns')\n",
    "\n",
    "    # Merge with kaggle_test data\n",
    "    test_ALL_merge = pd.read_csv(\"current_csv_files/test_ALL.csv\")\n",
    "    test_ALL_merge['prediction'] = df_kaggle_preds['avg']\n",
    "    \n",
    "\n",
    "    # Correctly sort test data for submission\n",
    "    test_ALL_merge_sorted = test_ALL_merge.sort_values(['A', 'B', 'C', 'date_forecast'], ascending=[False, False, False, True])\n",
    "    test_ALL_merge_sorted['id'] = range(2160)\n",
    "    test_ALL_merge_sorted = test_ALL_merge_sorted.set_index('id')\n",
    "    test_ALL_merge_sorted['id'] = range(2160)\n",
    "\n",
    "    # Comparison to best sub on kaggle\n",
    "    #best_sub = pd.read_csv(\"teo_subs/best_sub.csv\", index_col='id')\n",
    "    objective_metric = mean_absolute_error(df_kaggle_preds['avg'], y_hat)\n",
    "    print(trial.number,\" MAE: \", mean_absolute_error(df_kaggle_preds['avg'], y_hat))\n",
    "    print(trial.number,\" RMSE: \", np.sqrt(mean_squared_error(df_kaggle_preds['avg'], y_hat)))\n",
    "\n",
    "    file_loc = \"dnn_kaggle3/optuna_sub_\"+str(trial.number)+\".csv\"\n",
    "    test_ALL_merge_sorted[['id', 'prediction']].to_csv(file_loc, index=False)\n",
    "\n",
    "    return objective_metric\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 21:49:12,165] A new study created in memory with name: no-name-d8bcafcb-1617-4ea3-9973-056a8e943b01\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  50\n",
      "Best epoch:  2\n",
      "Best epoch:  5\n",
      "Best epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 21:52:46,170] Trial 0 finished with value: 58.35341188195377 and parameters: {'N': 3, 'n_neurons_1': 143, 'n_neurons_2': 184, 'n_neurons_3': 189, 'n_neurons_4': 62, 'Dropout': 0.06698146903599685, 'kernel_regularizer': 0.1895926421254273, 'learning_rate': 0.000985184837191271, 'beta_1': 0.8943031675139399, 'min_delta': 9.162014886489292, 'batch_size': 16}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  MAE:  58.35341188195377\n",
      "0  RMSE:  112.47948015873651\n",
      "Seed:  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n",
      "[I 2023-11-11 21:53:20,410] Trial 1 finished with value: 63.76180585626043 and parameters: {'N': 1, 'n_neurons_1': 140, 'n_neurons_2': 180, 'n_neurons_3': 156, 'n_neurons_4': 64, 'Dropout': 0.08109373800033151, 'kernel_regularizer': 0.20744873692984894, 'learning_rate': 0.001087608185587972, 'beta_1': 0.8444271552561563, 'min_delta': 19.922290826524897, 'batch_size': 32}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  8\n",
      "1  MAE:  63.76180585626043\n",
      "1  RMSE:  119.6046906302578\n",
      "Seed:  52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  8\n",
      "Best epoch:  10\n",
      "Best epoch:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 21:55:53,955] Trial 2 finished with value: 62.28714217215633 and parameters: {'N': 3, 'n_neurons_1': 145, 'n_neurons_2': 188, 'n_neurons_3': 172, 'n_neurons_4': 88, 'Dropout': 0.13656162774539302, 'kernel_regularizer': 0.149090249551807, 'learning_rate': 0.001195234403982713, 'beta_1': 0.8418322138231447, 'min_delta': 19.07647667430789, 'batch_size': 32}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  MAE:  62.28714217215633\n",
      "2  RMSE:  116.10411616975898\n",
      "Seed:  53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n",
      "[I 2023-11-11 21:57:04,306] Trial 3 finished with value: 63.07020916233849 and parameters: {'N': 2, 'n_neurons_1': 172, 'n_neurons_2': 187, 'n_neurons_3': 166, 'n_neurons_4': 71, 'Dropout': 0.173388698207306, 'kernel_regularizer': 0.22996862841930577, 'learning_rate': 0.0008069986884411531, 'beta_1': 0.7592625402048437, 'min_delta': 10.329380945525818, 'batch_size': 64}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  8\n",
      "Best epoch:  11\n",
      "3  MAE:  63.07020916233849\n",
      "3  RMSE:  122.05166734952572\n",
      "Seed:  54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n",
      "[I 2023-11-11 21:58:10,556] Trial 4 finished with value: 73.90336625019715 and parameters: {'N': 1, 'n_neurons_1': 175, 'n_neurons_2': 160, 'n_neurons_3': 177, 'n_neurons_4': 89, 'Dropout': 0.19001516412862413, 'kernel_regularizer': 0.08755886119369705, 'learning_rate': 0.0008873666137412145, 'beta_1': 0.8192539120507425, 'min_delta': 11.528945380524327, 'batch_size': 16}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  5\n",
      "4  MAE:  73.90336625019715\n",
      "4  RMSE:  137.21574535232477\n",
      "Seed:  55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  7\n",
      "Best epoch:  17\n",
      "5  MAE:  64.58494877946013\n",
      "5  RMSE:  122.29373069868096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 21:59:38,392] Trial 5 finished with value: 64.58494877946013 and parameters: {'N': 2, 'n_neurons_1': 163, 'n_neurons_2': 150, 'n_neurons_3': 199, 'n_neurons_4': 80, 'Dropout': 0.05262419728898947, 'kernel_regularizer': 0.20026899696655204, 'learning_rate': 0.0010361791991384754, 'beta_1': 0.7933087772487527, 'min_delta': 7.553274493945823, 'batch_size': 64}. Best is trial 0 with value: 58.35341188195377.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:  56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 22:00:32,924] Trial 6 finished with value: 72.62256132807742 and parameters: {'N': 1, 'n_neurons_1': 173, 'n_neurons_2': 151, 'n_neurons_3': 188, 'n_neurons_4': 71, 'Dropout': 0.08558526686893408, 'kernel_regularizer': 0.06927636000763221, 'learning_rate': 0.0009353462076619927, 'beta_1': 0.7945186610420685, 'min_delta': 8.387829395364179, 'batch_size': 32}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  7\n",
      "6  MAE:  72.62256132807742\n",
      "6  RMSE:  129.45383030581652\n",
      "Seed:  57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n",
      "[I 2023-11-11 22:01:15,680] Trial 7 finished with value: 72.45719751266418 and parameters: {'N': 1, 'n_neurons_1': 144, 'n_neurons_2': 200, 'n_neurons_3': 186, 'n_neurons_4': 69, 'Dropout': 0.1053305637469119, 'kernel_regularizer': 0.06131419095130928, 'learning_rate': 0.0011307263778571382, 'beta_1': 0.8680938421231411, 'min_delta': 14.992505945550741, 'batch_size': 64}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  13\n",
      "7  MAE:  72.45719751266418\n",
      "7  RMSE:  140.9838508664847\n",
      "Seed:  58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  3\n",
      "Best epoch:  9\n",
      "Best epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 22:03:25,046] Trial 8 finished with value: 59.91618705302105 and parameters: {'N': 3, 'n_neurons_1': 162, 'n_neurons_2': 189, 'n_neurons_3': 200, 'n_neurons_4': 66, 'Dropout': 0.10719866897110389, 'kernel_regularizer': 0.10170297257568967, 'learning_rate': 0.0008943216492775378, 'beta_1': 0.8554549924621351, 'min_delta': 11.594434613627445, 'batch_size': 32}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8  MAE:  59.91618705302105\n",
      "8  RMSE:  113.39787682118525\n",
      "Seed:  59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n",
      "[I 2023-11-11 22:04:11,650] Trial 9 finished with value: 64.78389961215012 and parameters: {'N': 1, 'n_neurons_1': 160, 'n_neurons_2': 180, 'n_neurons_3': 159, 'n_neurons_4': 67, 'Dropout': 0.05592441771978109, 'kernel_regularizer': 0.1694120702459302, 'learning_rate': 0.0008507995981765322, 'beta_1': 0.8475126021181713, 'min_delta': 5.93908980332905, 'batch_size': 32}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  14\n",
      "9  MAE:  64.78389961215012\n",
      "9  RMSE:  115.08773213108849\n",
      "Seed:  60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  13\n",
      "Best epoch:  9\n",
      "Best epoch:  17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 22:09:36,475] Trial 10 finished with value: 59.40496591769067 and parameters: {'N': 3, 'n_neurons_1': 153, 'n_neurons_2': 165, 'n_neurons_3': 186, 'n_neurons_4': 78, 'Dropout': 0.13619605831974335, 'kernel_regularizer': 0.1320188834497331, 'learning_rate': 0.0009902970953680628, 'beta_1': 0.897485861186767, 'min_delta': 5.429177823290545, 'batch_size': 16}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10  MAE:  59.40496591769067\n",
      "10  RMSE:  110.523383090567\n",
      "Seed:  61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  5\n",
      "Best epoch:  5\n",
      "Best epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-11 22:17:54,958] Trial 11 finished with value: 63.1638385571432 and parameters: {'N': 3, 'n_neurons_1': 153, 'n_neurons_2': 166, 'n_neurons_3': 188, 'n_neurons_4': 78, 'Dropout': 0.1441671309583062, 'kernel_regularizer': 0.13709674645364187, 'learning_rate': 0.0009922391415161567, 'beta_1': 0.8952059110426813, 'min_delta': 5.691696537624779, 'batch_size': 16}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11  MAE:  63.1638385571432\n",
      "11  RMSE:  121.48429068941522\n",
      "Seed:  62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  10\n",
      "Best epoch:  5\n",
      "Best epoch:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-12 07:09:07,201] Trial 12 finished with value: 60.26307834892851 and parameters: {'N': 3, 'n_neurons_1': 152, 'n_neurons_2': 168, 'n_neurons_3': 181, 'n_neurons_4': 60, 'Dropout': 0.15313374895174992, 'kernel_regularizer': 0.1165097224395385, 'learning_rate': 0.0009735481107905191, 'beta_1': 0.8996848942787259, 'min_delta': 8.750696375146786, 'batch_size': 16}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12  MAE:  60.26307834892851\n",
      "12  RMSE:  113.13688836301729\n",
      "Seed:  63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch:  14\n",
      "Best epoch:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-12 14:26:39,710] Trial 13 finished with value: 59.577933646059535 and parameters: {'N': 2, 'n_neurons_1': 149, 'n_neurons_2': 172, 'n_neurons_3': 193, 'n_neurons_4': 83, 'Dropout': 0.120843358528433, 'kernel_regularizer': 0.17234205772846012, 'learning_rate': 0.001010911252155597, 'beta_1': 0.8796547711153324, 'min_delta': 5.106453050509141, 'batch_size': 16}. Best is trial 0 with value: 58.35341188195377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13  MAE:  59.577933646059535\n",
      "13  RMSE:  111.14712158324281\n",
      "Seed:  64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/trial/_trial.py:677: RuntimeWarning: Inconsistent parameter values for distribution with name \"n_neurons_3\"! This might be a configuration mistake. Optuna allows to call the same distribution with the same name more than once in a trial. When the parameter values are inconsistent optuna only uses the values of the first call and ignores all following. Using these values: {'log': False, 'step': 1, 'low': 150, 'high': 200}\n",
      "  warnings.warn(\n",
      "[W 2023-11-12 14:31:11,782] Trial 14 failed with parameters: {'N': 3, 'n_neurons_1': 155, 'n_neurons_2': 159, 'n_neurons_3': 181, 'n_neurons_4': 76, 'Dropout': 0.1550401106447224, 'kernel_regularizer': 0.12592333612327503, 'learning_rate': 0.0007663612949711176, 'beta_1': 0.8862247051819403, 'min_delta': 7.3592644981336655, 'batch_size': 16} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/kq/hk1l39ys077bc7f9741ypg800000gn/T/ipykernel_36027/799185669.py\", line 65, in objective\n",
      "    history = model.fit(\n",
      "              ^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py\", line 1783, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 831, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 867, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 132, in call_function\n",
      "    function = trace_function(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 181, in trace_function\n",
      "    _set_arg_keywords(concrete_function)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 363, in _set_arg_keywords\n",
      "    user_arg_name = compat.as_str(arg.op.get_attr(\"_user_specified_name\"))\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 1546, in get_attr\n",
      "    with c_api_util.tf_buffer() as buf:   # pytype: disable=wrong-arg-count\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/c_api_util.py\", line 191, in tf_buffer\n",
      "    @tf_contextlib.contextmanager\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2023-11-12 14:31:11,795] Trial 14 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb Cell 94\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest hyperparameters:\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_params)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest MSE:\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_value)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     _optimize(\n\u001b[1;32m    452\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    453\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    454\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    455\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    456\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    457\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    458\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    459\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    460\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    461\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb Cell 94\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m custom_checkpoint \u001b[39m=\u001b[39m CustomModelCheckpoint(best_weights_during_training, best_epochs_during_training, i)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     X, y,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(X_kaggle, y_hat),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     \u001b[39m#validation_split=0.2,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mtrial_params[\u001b[39m'\u001b[39;49m\u001b[39mbatch_size\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[early_stopping, custom_checkpoint],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, workers\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m best_weights_during_training:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39m# If the model didn't improve, just save the last weights and epoch number\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/teodorlindell/Repos/TDT4174-Machine-Learning/teodor/teo_pipeline.ipynb#Y160sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     best_weights_during_training[i] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mget_weights()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[39m=\u001b[39m args \u001b[39mif\u001b[39;00m args \u001b[39melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[39m=\u001b[39m kwargs \u001b[39mif\u001b[39;00m kwargs \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[39m=\u001b[39m trace_function(\n\u001b[1;32m    133\u001b[0m     args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs, tracing_options\u001b[39m=\u001b[39;49mtracing_options\n\u001b[1;32m    134\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[39m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:181\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m    178\u001b[0m   concrete_function \u001b[39m=\u001b[39m _maybe_define_function(\n\u001b[1;32m    179\u001b[0m       args, kwargs, tracing_options\n\u001b[1;32m    180\u001b[0m   )\n\u001b[0;32m--> 181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tracing_options\u001b[39m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    184\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:363\u001b[0m, in \u001b[0;36m_set_arg_keywords\u001b[0;34m(concrete_function)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minputs[:num_positional]:\n\u001b[1;32m    362\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m     user_arg_name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(arg\u001b[39m.\u001b[39;49mop\u001b[39m.\u001b[39;49mget_attr(\u001b[39m\"\u001b[39;49m\u001b[39m_user_specified_name\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    364\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m     user_arg_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtensor_arg\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:1546\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1544\u001b[0m fields \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtensor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfunc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1545\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1546\u001b[0m   \u001b[39mwith\u001b[39;49;00m c_api_util\u001b[39m.\u001b[39;49mtf_buffer() \u001b[39mas\u001b[39;49;00m buf:   \u001b[39m# pytype: disable=wrong-arg-count\u001b[39;49;00m\n\u001b[1;32m   1547\u001b[0m     pywrap_tf_session\u001b[39m.\u001b[39;49mTF_OperationGetAttrValueProto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_op, name, buf)\n\u001b[1;32m   1548\u001b[0m     data \u001b[39m=\u001b[39;49m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_GetBuffer(buf)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/framework/c_api_util.py:191\u001b[0m, in \u001b[0;36mtf_buffer\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39mop_names\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op_per_name\u001b[39m.\u001b[39mkeys()\n\u001b[0;32m--> 191\u001b[0m \u001b[39m@tf_contextlib\u001b[39m\u001b[39m.\u001b[39mcontextmanager\n\u001b[1;32m    192\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtf_buffer\u001b[39m(data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    193\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Context manager that creates and deletes TF_Buffer.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[39m  Example usage:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m    Created TF_Buffer\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m   \u001b[39mif\u001b[39;00m data:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=1000)\n",
    "\n",
    "print('Best hyperparameters:', study.best_params)\n",
    "print('Best MSE:', study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
