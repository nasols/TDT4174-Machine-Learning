{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r dm\n",
    "\n",
    "dm = dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = dm.data.drop(\"date_forecast\", axis=1)\n",
    "\n",
    "data_A = dm.data_A.drop(\"date_forecast\", axis=1)\n",
    "data_B = dm.data_B.drop(\"date_forecast\", axis=1)\n",
    "data_C = dm.data_C.drop(\"date_forecast\", axis=1)\n",
    "\n",
    "X = dm.data.iloc[:, 2:]\n",
    "y = dm.data.iloc[:, 1]\n",
    "\n",
    "X_A = dm.data_A.iloc[:, 2:]\n",
    "y_A = dm.data_A.iloc[:, 1]\n",
    "X_B = dm.data_B.iloc[:, 2:]\n",
    "y_B = dm.data_B.iloc[:, 1]\n",
    "X_C = dm.data_C.iloc[:, 2:]\n",
    "y_C = dm.data_C.iloc[:, 1]\n",
    "\n",
    "X_A = dm.add_location(X_A, \"A\")\n",
    "X_B = dm.add_location(X_B, \"B\")\n",
    "X_C = dm.add_location(X_C, \"C\")\n",
    "\n",
    "X_train_A = X_A.iloc[0:int(0.7*X_A.shape[0]):]\n",
    "y_train_A = y_A.iloc[0:int(0.7*y_A.shape[0]):]\n",
    "X_test_A = X_A.iloc[-int(0.3*X_A.shape[0]):] \n",
    "y_test_A = y_A.iloc[-int(0.3*y_A.shape[0]):]\n",
    "\n",
    "#X_test_A, X_validate_A, y_test_A, y_validate_A = train_test_split(X_test_A, y_test_A, train_size=0.4, shuffle=False)\n",
    "\n",
    "X_train_B = X_B.iloc[0:int(0.7*X_B.shape[0]):]\n",
    "y_train_B = y_B.iloc[0:int(0.7*y_B.shape[0]):]\n",
    "X_test_B = X_B.iloc[-int(0.3*X_B.shape[0]):] \n",
    "y_test_B = y_B.iloc[-int(0.3*y_B.shape[0]):] \n",
    "\n",
    "#X_test_B, X_validate_B, y_test_B, y_validate_B = train_test_split(X_test_B, y_test_B, train_size=0.4, shuffle=False)\n",
    "\n",
    "X_train_C = X_C.iloc[0:int(0.7*X_C.shape[0]):]\n",
    "y_train_C = y_C.iloc[0:int(0.7*y_C.shape[0]):]\n",
    "X_test_C = X_C.iloc[-int(0.3*X_C.shape[0]):] \n",
    "y_test_C = y_C.iloc[-int(0.3*y_C.shape[0]):] \n",
    "\n",
    "#X_test_C, X_validate_C, y_test_C, y_validate_C = train_test_split(X_test_C, y_test_C, train_size=0.4, shuffle=False)\n",
    "\n",
    "X_train = pd.concat([X_train_A, X_train_B, X_train_C], ignore_index=True)\n",
    "#X_validate = pd.concat([X_validate_A, X_validate_B, X_validate_C], ignore_index=True)\n",
    "X_test = pd.concat([X_test_A, X_test_B, X_test_C], ignore_index=True)\n",
    "\n",
    "y_train = pd.concat([y_train_A, y_train_B, y_train_C], ignore_index=True)\n",
    "#y_validate = pd.concat([y_validate_A, y_validate_B, y_validate_C], ignore_index=True)\n",
    "y_test = pd.concat([y_test_A, y_test_B, y_test_C], ignore_index=True)\n",
    "\n",
    "X_submission = dm.X_test_estimated[dm.X_test_estimated.columns.intersection(X.columns)]\n",
    "\n",
    "X_submission_A = dm.X_test_estimated_a[dm.X_test_estimated_a.columns.intersection(X_A.columns)]\n",
    "X_submission_B = dm.X_test_estimated_b[dm.X_test_estimated_b.columns.intersection(X_B.columns)]\n",
    "X_submission_C = dm.X_test_estimated_c[dm.X_test_estimated_c.columns.intersection(X_C.columns)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:41:43 PDT 2023; root:xnu-10002.1.13~1/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   153.94 GB / 494.38 GB (31.1%)\n",
      "Train Data Rows:    34037\n",
      "Train Data Columns: 35\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (5733.42, 0.0, 631.44224, 1166.50284)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5631.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 5.17 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 34 | ['is_day:idx', 'is_in_shadow:idx', 'clear_sky_energy_1h:J', 'diffuse_rad_1h:J', 'direct_rad_1h:J', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 32 | ['clear_sky_energy_1h:J', 'diffuse_rad_1h:J', 'direct_rad_1h:J', 'fresh_snow_12h:cm', 'fresh_snow_24h:cm', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['is_day:idx', 'is_in_shadow:idx']\n",
      "\t0.1s = Fit runtime\n",
      "\t34 features in original data used to generate 34 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 4.7 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-154.8331\t = Validation score   (-mean_absolute_error)\n",
      "\t20.99s\t = Training   runtime\n",
      "\t60.73s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-161.687\t = Validation score   (-mean_absolute_error)\n",
      "\t24.94s\t = Training   runtime\n",
      "\t69.3s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-182.2869\t = Validation score   (-mean_absolute_error)\n",
      "\t17.25s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-167.733\t = Validation score   (-mean_absolute_error)\n",
      "\t184.97s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-184.1191\t = Validation score   (-mean_absolute_error)\n",
      "\t2.73s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-185.7826\t = Validation score   (-mean_absolute_error)\n",
      "\t21.06s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-171.6662\t = Validation score   (-mean_absolute_error)\n",
      "\t82.88s\t = Training   runtime\n",
      "\t31.85s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-168.628\t = Validation score   (-mean_absolute_error)\n",
      "\t54.64s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-158.7905\t = Validation score   (-mean_absolute_error)\n",
      "\t63.07s\t = Training   runtime\n",
      "\t182.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-151.0444\t = Validation score   (-mean_absolute_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-153.7795\t = Validation score   (-mean_absolute_error)\n",
      "\t2.59s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-150.4716\t = Validation score   (-mean_absolute_error)\n",
      "\t2.19s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-149.4015\t = Validation score   (-mean_absolute_error)\n",
      "\t27.87s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-150.9045\t = Validation score   (-mean_absolute_error)\n",
      "\t6.11s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-149.0216\t = Validation score   (-mean_absolute_error)\n",
      "\t3.16s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-149.8382\t = Validation score   (-mean_absolute_error)\n",
      "\t20.06s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-150.1688\t = Validation score   (-mean_absolute_error)\n",
      "\t2.77s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-149.8683\t = Validation score   (-mean_absolute_error)\n",
      "\t32.09s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-151.6187\t = Validation score   (-mean_absolute_error)\n",
      "\t4.42s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-146.6071\t = Validation score   (-mean_absolute_error)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 659.61s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t37.02s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t36.04s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t17.25s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t59.91s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.73s\t = Training   runtime\n",
      "\t0.72s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "No improvement since epoch 2: early stopping\n",
      "\t15.29s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t19.74s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t35.64s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t179.81s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.21s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/autogluon.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mautogluon\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtabular\u001b[39;00m \u001b[39mimport\u001b[39;00m TabularPredictor\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m predictor_A \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpv_measurement\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                              eval_metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmean_absolute_error\u001b[39;49m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                              path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon\u001b[39;49m\u001b[39m'\u001b[39;49m)\\\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m.\u001b[39;49mfit(data_A, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m          presets\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mgood_quality\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m predictor_B \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpv_measurement\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                              eval_metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean_absolute_error\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                              path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon\u001b[39m\u001b[39m'\u001b[39m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m.\u001b[39mfit(data_B, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m          presets\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mgood_quality\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m predictor_C \u001b[39m=\u001b[39m TabularPredictor(label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpv_measurement\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                              eval_metric\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmean_absolute_error\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                              path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon\u001b[39m\u001b[39m'\u001b[39m)\\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m.\u001b[39mfit(data_C, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173%20-%20Maskinl%C3%A6ring/ve/group_project/autogluon.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m          presets\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mgood_quality\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/utils/decorators.py:31\u001b[0m, in \u001b[0;36munpack.<locals>._unpack_inner.<locals>._call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     30\u001b[0m     gargs, gkwargs \u001b[39m=\u001b[39m g(\u001b[39m*\u001b[39mother_args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mgargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgkwargs)\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1005\u001b[0m, in \u001b[0;36mTabularPredictor.fit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_learner\u001b[39m.\u001b[39mfit(\n\u001b[1;32m    987\u001b[0m     X\u001b[39m=\u001b[39mtrain_data,\n\u001b[1;32m    988\u001b[0m     X_val\u001b[39m=\u001b[39mtuning_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1001\u001b[0m     use_bag_holdout\u001b[39m=\u001b[39muse_bag_holdout,\n\u001b[1;32m   1002\u001b[0m )\n\u001b[1;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_post_fit_vars()\n\u001b[0;32m-> 1005\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post_fit(\n\u001b[1;32m   1006\u001b[0m     keep_only_best\u001b[39m=\u001b[39;49mkwargs[\u001b[39m\"\u001b[39;49m\u001b[39mkeep_only_best\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1007\u001b[0m     refit_full\u001b[39m=\u001b[39;49mkwargs[\u001b[39m\"\u001b[39;49m\u001b[39mrefit_full\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1008\u001b[0m     set_best_to_refit_full\u001b[39m=\u001b[39;49mkwargs[\u001b[39m\"\u001b[39;49m\u001b[39mset_best_to_refit_full\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1009\u001b[0m     save_space\u001b[39m=\u001b[39;49mkwargs[\u001b[39m\"\u001b[39;49m\u001b[39msave_space\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1010\u001b[0m     calibrate\u001b[39m=\u001b[39;49mkwargs[\u001b[39m\"\u001b[39;49m\u001b[39mcalibrate\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m   1011\u001b[0m     calibrate_decision_threshold\u001b[39m=\u001b[39;49mcalibrate_decision_threshold,\n\u001b[1;32m   1012\u001b[0m     infer_limit\u001b[39m=\u001b[39;49minfer_limit,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[1;32m   1014\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m   1015\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:1044\u001b[0m, in \u001b[0;36mTabularPredictor._post_fit\u001b[0;34m(self, keep_only_best, refit_full, set_best_to_refit_full, save_space, calibrate, calibrate_decision_threshold, infer_limit)\u001b[0m\n\u001b[1;32m   1042\u001b[0m trainer_model_best \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\u001b[39m.\u001b[39mget_model_best(infer_limit\u001b[39m=\u001b[39minfer_limit)\n\u001b[1;32m   1043\u001b[0m logger\u001b[39m.\u001b[39mlog(\u001b[39m20\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mAutomatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1044\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrefit_full(model\u001b[39m=\u001b[39;49mrefit_full, set_best_to_refit_full\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1045\u001b[0m \u001b[39mif\u001b[39;00m set_best_to_refit_full:\n\u001b[1;32m   1046\u001b[0m     model_full_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\u001b[39m.\u001b[39mget_model_full_dict()\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/tabular/predictor/predictor.py:2617\u001b[0m, in \u001b[0;36mTabularPredictor.refit_full\u001b[0;34m(self, model, set_best_to_refit_full)\u001b[0m\n\u001b[1;32m   2609\u001b[0m     model \u001b[39m=\u001b[39m model_best\n\u001b[1;32m   2610\u001b[0m logger\u001b[39m.\u001b[39mlog(\n\u001b[1;32m   2611\u001b[0m     \u001b[39m20\u001b[39m,\n\u001b[1;32m   2612\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRefitting models via `predictor.refit_full` using all of the data (combined train and validation)...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2615\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mTo learn more, refer to the `.refit_full` method docstring which explains how \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_FULL\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m models differ from normal models.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   2616\u001b[0m )\n\u001b[0;32m-> 2617\u001b[0m refit_full_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_learner\u001b[39m.\u001b[39;49mrefit_ensemble_full(model\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m   2619\u001b[0m \u001b[39mif\u001b[39;00m set_best_to_refit_full:\n\u001b[1;32m   2620\u001b[0m     model_full_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trainer\u001b[39m.\u001b[39mget_model_full_dict()\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/tabular/learner/abstract_learner.py:448\u001b[0m, in \u001b[0;36mAbstractTabularLearner.refit_ensemble_full\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrefit_ensemble_full\u001b[39m(\u001b[39mself\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_trainer()\u001b[39m.\u001b[39;49mrefit_ensemble_full(model\u001b[39m=\u001b[39;49mmodel)\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:1334\u001b[0m, in \u001b[0;36mAbstractTrainer.refit_ensemble_full\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         ensemble_set_valid\u001b[39m.\u001b[39mappend(model)\n\u001b[1;32m   1333\u001b[0m \u001b[39mif\u001b[39;00m ensemble_set_valid:\n\u001b[0;32m-> 1334\u001b[0m     models_trained_full \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrefit_single_full(models\u001b[39m=\u001b[39;49mensemble_set_valid)\n\u001b[1;32m   1335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1336\u001b[0m     models_trained_full \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:1276\u001b[0m, in \u001b[0;36mAbstractTrainer.refit_single_full\u001b[0;34m(self, X, y, X_val, y_val, X_unlabeled, models)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39m# TODO: Do it for all models in the level at once to avoid repeated processing of data?\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m     base_model_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_base_model_names(model_name)\n\u001b[0;32m-> 1276\u001b[0m     models_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstack_new_level_core(\n\u001b[1;32m   1277\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   1278\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   1279\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m   1280\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m   1281\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m   1282\u001b[0m         models\u001b[39m=\u001b[39;49m[model_full],\n\u001b[1;32m   1283\u001b[0m         base_model_names\u001b[39m=\u001b[39;49mbase_model_names,\n\u001b[1;32m   1284\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   1285\u001b[0m         stack_name\u001b[39m=\u001b[39;49mREFIT_FULL_NAME,\n\u001b[1;32m   1286\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1287\u001b[0m         feature_prune\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1288\u001b[0m         k_fold\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   1289\u001b[0m         n_repeats\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1290\u001b[0m         ensemble_type\u001b[39m=\u001b[39;49m\u001b[39mtype\u001b[39;49m(model),\n\u001b[1;32m   1291\u001b[0m         refit_full\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1292\u001b[0m     )\n\u001b[1;32m   1293\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(models_trained) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1294\u001b[0m     model_full_dict[model_name] \u001b[39m=\u001b[39m models_trained[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:673\u001b[0m, in \u001b[0;36mAbstractTrainer.stack_new_level_core\u001b[0;34m(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, included_model_types, excluded_model_types, ensemble_type, name_suffix, get_models_func, refit_full, infer_limit, infer_limit_batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m fit_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes)\n\u001b[1;32m    672\u001b[0m \u001b[39m# FIXME: TODO: v0.1 X_unlabeled isn't cached so it won't be available during refit_full or fit_extra.\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi(\n\u001b[1;32m    674\u001b[0m     X\u001b[39m=\u001b[39;49mX_init,\n\u001b[1;32m    675\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    676\u001b[0m     X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m    677\u001b[0m     y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m    678\u001b[0m     X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m    679\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m    680\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m    681\u001b[0m     stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[1;32m    682\u001b[0m     compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[1;32m    683\u001b[0m     fit_kwargs\u001b[39m=\u001b[39;49mfit_kwargs,\n\u001b[1;32m    684\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    685\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:2321\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi\u001b[0;34m(self, X, y, models, hyperparameter_tune_kwargs, feature_prune_kwargs, k_fold, n_repeats, n_repeat_start, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[39mif\u001b[39;00m n_repeat_start \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2320\u001b[0m     time_start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m-> 2321\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_initial(\n\u001b[1;32m   2322\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   2323\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   2324\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m   2325\u001b[0m         k_fold\u001b[39m=\u001b[39;49mk_fold,\n\u001b[1;32m   2326\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats_initial,\n\u001b[1;32m   2327\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[1;32m   2328\u001b[0m         feature_prune_kwargs\u001b[39m=\u001b[39;49mfeature_prune_kwargs,\n\u001b[1;32m   2329\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2330\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2331\u001b[0m     )\n\u001b[1;32m   2332\u001b[0m     n_repeat_start \u001b[39m=\u001b[39m n_repeats_initial\n\u001b[1;32m   2333\u001b[0m     \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:2160\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_initial\u001b[0;34m(self, X, y, models, k_fold, n_repeats, hyperparameter_tune_kwargs, time_limit, feature_prune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m bagged:\n\u001b[1;32m   2159\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 2160\u001b[0m     models \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_multi_fold(\n\u001b[1;32m   2161\u001b[0m         models\u001b[39m=\u001b[39;49mmodels,\n\u001b[1;32m   2162\u001b[0m         hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs,\n\u001b[1;32m   2163\u001b[0m         time_limit\u001b[39m=\u001b[39;49mtime_limit,\n\u001b[1;32m   2164\u001b[0m         time_split\u001b[39m=\u001b[39;49mtime_split,\n\u001b[1;32m   2165\u001b[0m         time_ratio\u001b[39m=\u001b[39;49mtime_ratio,\n\u001b[1;32m   2166\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args,\n\u001b[1;32m   2167\u001b[0m     )\n\u001b[1;32m   2168\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2169\u001b[0m     time_ratio \u001b[39m=\u001b[39m hpo_time_ratio \u001b[39mif\u001b[39;00m hpo_enabled \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:2278\u001b[0m, in \u001b[0;36mAbstractTrainer._train_multi_fold\u001b[0;34m(self, X, y, models, time_limit, time_split, time_ratio, hyperparameter_tune_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m   2276\u001b[0m         time_start_model \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   2277\u001b[0m         time_left \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time_start_model \u001b[39m-\u001b[39m time_start)\n\u001b[0;32m-> 2278\u001b[0m model_name_trained_lst \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single_full(\n\u001b[1;32m   2279\u001b[0m     X, y, model, time_limit\u001b[39m=\u001b[39;49mtime_left, hyperparameter_tune_kwargs\u001b[39m=\u001b[39;49mhyperparameter_tune_kwargs_model, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m   2280\u001b[0m )\n\u001b[1;32m   2282\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m   2283\u001b[0m     \u001b[39mdel\u001b[39;00m model\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:2051\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single_full\u001b[0;34m(self, X, y, model, X_unlabeled, X_val, y_val, X_pseudo, y_pseudo, feature_prune, hyperparameter_tune_kwargs, stack_name, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, level, time_limit, fit_kwargs, compute_score, total_resources, **kwargs)\u001b[0m\n\u001b[1;32m   2047\u001b[0m         bagged_model_fit_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_bagged_model_fit_kwargs(\n\u001b[1;32m   2048\u001b[0m             k_fold\u001b[39m=\u001b[39mk_fold, k_fold_start\u001b[39m=\u001b[39mk_fold_start, k_fold_end\u001b[39m=\u001b[39mk_fold_end, n_repeats\u001b[39m=\u001b[39mn_repeats, n_repeat_start\u001b[39m=\u001b[39mn_repeat_start\n\u001b[1;32m   2049\u001b[0m         )\n\u001b[1;32m   2050\u001b[0m         model_fit_kwargs\u001b[39m.\u001b[39mupdate(bagged_model_fit_kwargs)\n\u001b[0;32m-> 2051\u001b[0m     model_names_trained \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_and_save(\n\u001b[1;32m   2052\u001b[0m         X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m   2053\u001b[0m         y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   2054\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   2055\u001b[0m         X_val\u001b[39m=\u001b[39;49mX_val,\n\u001b[1;32m   2056\u001b[0m         y_val\u001b[39m=\u001b[39;49my_val,\n\u001b[1;32m   2057\u001b[0m         X_unlabeled\u001b[39m=\u001b[39;49mX_unlabeled,\n\u001b[1;32m   2058\u001b[0m         stack_name\u001b[39m=\u001b[39;49mstack_name,\n\u001b[1;32m   2059\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   2060\u001b[0m         compute_score\u001b[39m=\u001b[39;49mcompute_score,\n\u001b[1;32m   2061\u001b[0m         total_resources\u001b[39m=\u001b[39;49mtotal_resources,\n\u001b[1;32m   2062\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs,\n\u001b[1;32m   2063\u001b[0m     )\n\u001b[1;32m   2064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave()\n\u001b[1;32m   2065\u001b[0m \u001b[39mreturn\u001b[39;00m model_names_trained\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:1733\u001b[0m, in \u001b[0;36mAbstractTrainer._train_and_save\u001b[0;34m(self, X, y, model, X_val, y_val, stack_name, level, compute_score, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1731\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_single(X_w_pseudo, y_w_pseudo, model, X_val, y_val, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs)\n\u001b[1;32m   1732\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1733\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_single(X, y, model, X_val, y_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[1;32m   1735\u001b[0m fit_end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_evaluation:\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/trainer/abstract_trainer.py:1684\u001b[0m, in \u001b[0;36mAbstractTrainer._train_single\u001b[0;34m(self, X, y, model, X_val, y_val, total_resources, **model_fit_kwargs)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_single\u001b[39m(\u001b[39mself\u001b[39m, X, y, model: AbstractModel, X_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, y_val\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, total_resources\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_fit_kwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AbstractModel:\n\u001b[1;32m   1680\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[39m    Trains model but does not add the trained model to this Trainer.\u001b[39;00m\n\u001b[1;32m   1682\u001b[0m \u001b[39m    Returns trained model object.\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1684\u001b[0m     model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, X_val\u001b[39m=\u001b[39;49mX_val, y_val\u001b[39m=\u001b[39;49my_val, total_resources\u001b[39m=\u001b[39;49mtotal_resources, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_fit_kwargs)\n\u001b[1;32m   1685\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py:169\u001b[0m, in \u001b[0;36mStackerEnsembleModel._fit\u001b[0;34m(self, X, y, compute_base_preds, time_limit, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mif\u001b[39;00m time_limit \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     time_limit \u001b[39m=\u001b[39m time_limit \u001b[39m-\u001b[39m (time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time)\n\u001b[0;32m--> 169\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, time_limit\u001b[39m=\u001b[39;49mtime_limit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:250\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit\u001b[0;34m(self, X, y, X_val, y_val, X_pseudo, y_pseudo, k_fold, k_fold_start, k_fold_end, n_repeats, n_repeat_start, groups, _skip_oof, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m save_bag_folds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39msave_bag_folds\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    249\u001b[0m \u001b[39mif\u001b[39;00m k_fold \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_single(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, model_base\u001b[39m=\u001b[39;49mmodel_base, use_child_oof\u001b[39m=\u001b[39;49muse_child_oof, skip_oof\u001b[39m=\u001b[39;49m_skip_oof, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py:379\u001b[0m, in \u001b[0;36mBaggedEnsembleModel._fit_single\u001b[0;34m(self, X, y, model_base, use_child_oof, time_limit, skip_oof, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m model_base\u001b[39m.\u001b[39mset_contexts(path_context\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpath \u001b[39m+\u001b[39m model_base\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msep)\n\u001b[1;32m    378\u001b[0m time_start_fit \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 379\u001b[0m model_base\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, time_limit\u001b[39m=\u001b[39;49mtime_limit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    380\u001b[0m model_base\u001b[39m.\u001b[39mfit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m time_start_fit\n\u001b[1;32m    381\u001b[0m model_base\u001b[39m.\u001b[39mpredict_time \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/core/models/abstract/abstract_model.py:829\u001b[0m, in \u001b[0;36mAbstractModel.fit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalidate_fit_resources(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    828\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_fit_memory_usage(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 829\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    831\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_model.py:194\u001b[0m, in \u001b[0;36mLGBModel._fit\u001b[0;34m(self, X, y, X_val, y_val, time_limit, num_gpus, num_cpus, sample_weight, sample_weight_val, verbosity, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_column in param dict is overridden.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    193\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 194\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m train_lgb_model(early_stopping_callback_kwargs\u001b[39m=\u001b[39;49mearly_stopping_callback_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_params)\n\u001b[1;32m    195\u001b[0m \u001b[39mexcept\u001b[39;00m LightGBMError:\n\u001b[1;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m train_params[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgpu\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/autogluon/tabular/models/lgb/lgb_utils.py:124\u001b[0m, in \u001b[0;36mtrain_lgb_model\u001b[0;34m(early_stopping_callback_kwargs, **train_params)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m booster\u001b[39m.\u001b[39mfit(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrain_params)\n\u001b[1;32m    123\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m lgb\u001b[39m.\u001b[39;49mtrain(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtrain_params)\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/.venv/lib/python3.9/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "\n",
    "predictor_A = TabularPredictor(label=\"pv_measurement\", \n",
    "                             eval_metric=\"mean_absolute_error\", \n",
    "                             path='/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/A')\\\n",
    "    .fit(data_A, \n",
    "         presets=['good_quality'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/B\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/B/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:41:43 PDT 2023; root:xnu-10002.1.13~1/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   151.47 GB / 494.38 GB (30.6%)\n",
      "Train Data Rows:    26583\n",
      "Train Data Columns: 35\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (1152.3, -0.0, 104.12049, 210.24923)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4982.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 4.04 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 34 | ['is_day:idx', 'is_in_shadow:idx', 'clear_sky_energy_1h:J', 'diffuse_rad_1h:J', 'direct_rad_1h:J', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 32 | ['clear_sky_energy_1h:J', 'diffuse_rad_1h:J', 'direct_rad_1h:J', 'fresh_snow_12h:cm', 'fresh_snow_24h:cm', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['is_day:idx', 'is_in_shadow:idx']\n",
      "\t0.1s = Fit runtime\n",
      "\t34 features in original data used to generate 34 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.67 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.6744\t = Validation score   (-mean_absolute_error)\n",
      "\t17.38s\t = Training   runtime\n",
      "\t49.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.0572\t = Validation score   (-mean_absolute_error)\n",
      "\t20.91s\t = Training   runtime\n",
      "\t36.6s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-25.9397\t = Validation score   (-mean_absolute_error)\n",
      "\t15.13s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.6756\t = Validation score   (-mean_absolute_error)\n",
      "\t181.78s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-26.0574\t = Validation score   (-mean_absolute_error)\n",
      "\t2.27s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-26.6457\t = Validation score   (-mean_absolute_error)\n",
      "\t16.6s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-24.295\t = Validation score   (-mean_absolute_error)\n",
      "\t81.26s\t = Training   runtime\n",
      "\t40.34s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.3827\t = Validation score   (-mean_absolute_error)\n",
      "\t52.7s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.3964\t = Validation score   (-mean_absolute_error)\n",
      "\t60.02s\t = Training   runtime\n",
      "\t110.42s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-20.954\t = Validation score   (-mean_absolute_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.84\t = Validation score   (-mean_absolute_error)\n",
      "\t2.87s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.3687\t = Validation score   (-mean_absolute_error)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-20.953\t = Validation score   (-mean_absolute_error)\n",
      "\t24.07s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.4637\t = Validation score   (-mean_absolute_error)\n",
      "\t7.39s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-20.8598\t = Validation score   (-mean_absolute_error)\n",
      "\t2.56s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.9248\t = Validation score   (-mean_absolute_error)\n",
      "\t17.88s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.0714\t = Validation score   (-mean_absolute_error)\n",
      "\t2.63s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.4224\t = Validation score   (-mean_absolute_error)\n",
      "\t24.78s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.3708\t = Validation score   (-mean_absolute_error)\n",
      "\t4.32s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-20.5391\t = Validation score   (-mean_absolute_error)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 608.3s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t56.27s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t37.61s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t15.13s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t58.39s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t2.27s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 27.\n",
      "\t13.83s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t27.6s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t38.05s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t162.13s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.23s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.97s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t24.07s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.98s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t2.56s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 26.\n",
      "\t12.79s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.26s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\t10.26s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t5.78s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.2s\t = Training   runtime\n",
      "Refit complete, total runtime = 429.98s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/B/\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictor_B = TabularPredictor(label=\"pv_measurement\", \n",
    "                             eval_metric=\"mean_absolute_error\", \n",
    "                             path='/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/B')\\\n",
    "    .fit(data_B, \n",
    "         presets=['good_quality'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/C\"\n",
      "Presets specified: ['good_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/C/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.9.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.0.0: Fri Sep 15 14:41:43 PDT 2023; root:xnu-10002.1.13~1/RELEASE_ARM64_T6000\n",
      "Disk Space Avail:   150.05 GB / 494.38 GB (30.4%)\n",
      "Train Data Rows:    21393\n",
      "Train Data Columns: 35\n",
      "Label Column: pv_measurement\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and label-values can't be converted to int).\n",
      "\tLabel info (max, min, mean, stddev): (999.6, -0.0, 92.273, 177.2704)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5061.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.25 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['location']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 34 | ['is_day:idx', 'is_in_shadow:idx', 'clear_sky_energy_1h:J', 'diffuse_rad_1h:J', 'direct_rad_1h:J', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 32 | ['clear_sky_energy_1h:J', 'diffuse_rad_1h:J', 'direct_rad_1h:J', 'fresh_snow_12h:cm', 'fresh_snow_24h:cm', ...]\n",
      "\t\t('int', ['bool']) :  2 | ['is_day:idx', 'is_in_shadow:idx']\n",
      "\t0.1s = Fit runtime\n",
      "\t34 features in original data used to generate 34 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.95 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mean_absolute_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'max_depth': 15, 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'max_depth': 15, 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'max_depth': 15, 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 9 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.7541\t = Validation score   (-mean_absolute_error)\n",
      "\t26.52s\t = Training   runtime\n",
      "\t32.8s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.7059\t = Validation score   (-mean_absolute_error)\n",
      "\t20.74s\t = Training   runtime\n",
      "\t47.75s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\t-23.5127\t = Validation score   (-mean_absolute_error)\n",
      "\t10.97s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.3147\t = Validation score   (-mean_absolute_error)\n",
      "\t164.1s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\t-23.7347\t = Validation score   (-mean_absolute_error)\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-23.8649\t = Validation score   (-mean_absolute_error)\n",
      "\t13.48s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-22.009\t = Validation score   (-mean_absolute_error)\n",
      "\t68.81s\t = Training   runtime\n",
      "\t28.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-21.686\t = Validation score   (-mean_absolute_error)\n",
      "\t30.88s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.639\t = Validation score   (-mean_absolute_error)\n",
      "\t68.63s\t = Training   runtime\n",
      "\t92.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-19.4005\t = Validation score   (-mean_absolute_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 9 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-20.1359\t = Validation score   (-mean_absolute_error)\n",
      "\t2.47s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.8274\t = Validation score   (-mean_absolute_error)\n",
      "\t2.66s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\t-19.431\t = Validation score   (-mean_absolute_error)\n",
      "\t16.7s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.8757\t = Validation score   (-mean_absolute_error)\n",
      "\t6.45s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\t-19.3137\t = Validation score   (-mean_absolute_error)\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.5024\t = Validation score   (-mean_absolute_error)\n",
      "\t13.27s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.6343\t = Validation score   (-mean_absolute_error)\n",
      "\t2.6s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.7835\t = Validation score   (-mean_absolute_error)\n",
      "\t18.96s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "\t-19.7829\t = Validation score   (-mean_absolute_error)\n",
      "\t4.2s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\t-19.0702\t = Validation score   (-mean_absolute_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 530.91s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
      "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
      "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
      "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
      "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
      "\t45.58s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM_BAG_L1_FULL ...\n",
      "\t41.94s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t10.97s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: CatBoost_BAG_L1_FULL ...\n",
      "\t55.43s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
      "\t1.91s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
      "No improvement since epoch 1: early stopping\n",
      "\t8.3s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: XGBoost_BAG_L1_FULL ...\n",
      "\t22.53s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
      "\t20.84s\t = Training   runtime\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
      "\t207.11s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t0.16s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
      "\t2.27s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBM_BAG_L2_FULL ...\n",
      "\t0.89s\t = Training   runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t16.7s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: CatBoost_BAG_L2_FULL ...\n",
      "\t0.98s\t = Training   runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
      "\t2.09s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
      "\tStopping at the best epoch learned earlier - 26.\n",
      "\t11.27s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: XGBoost_BAG_L2_FULL ...\n",
      "\t0.26s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
      "\t10.17s\t = Training   runtime\n",
      "Fitting 1 L2 models ...\n",
      "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
      "\t5.51s\t = Training   runtime\n",
      "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
      "\t0.19s\t = Training   runtime\n",
      "Refit complete, total runtime = 435.93s\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/C/\")\n"
     ]
    }
   ],
   "source": [
    "predictor_C = TabularPredictor(label=\"pv_measurement\", \n",
    "                             eval_metric=\"mean_absolute_error\", \n",
    "                             path='/Users/jonasolsen/Documents/Skole/IIkt/5_semester/TDT4173 - Maskinlæring/ve/group_project/gluon/C')\\\n",
    "    .fit(data_C, \n",
    "         presets=['good_quality'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
