{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the project, we experimented a lot with different models, stacks and hyperparameters. We noticed pretty early on that catboost models performed pretty well with our early pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\loghe\\OneDrive\\Dokumenter\\Skole\\Host23\\ML\\main_project\\TDT4174-Machine-Learning\\log_preds\\long_notebook.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loghe/OneDrive/Dokumenter/Skole/Host23/ML/main_project/TDT4174-Machine-Learning/log_preds/long_notebook.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loghe/OneDrive/Dokumenter/Skole/Host23/ML/main_project/TDT4174-Machine-Learning/log_preds/long_notebook.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/loghe/OneDrive/Dokumenter/Skole/Host23/ML/main_project/TDT4174-Machine-Learning/log_preds/long_notebook.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loghe/OneDrive/Dokumenter/Skole/Host23/ML/main_project/TDT4174-Machine-Learning/log_preds/long_notebook.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcatboost\u001b[39;00m \u001b[39mimport\u001b[39;00m CatBoostRegressor\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/loghe/OneDrive/Dokumenter/Skole/Host23/ML/main_project/TDT4174-Machine-Learning/log_preds/long_notebook.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_A_train \u001b[39m=\u001b[39m dm\u001b[39m.\u001b[39mdata_A\u001b[39m.\u001b[39miloc[:, \u001b[39m2\u001b[39m:]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\__init__.py:83\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[39m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[39m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[39m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[1;32m---> 83\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[0;32m     86\u001b[0m     __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     87\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mshow_versions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    130\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_estimator_html_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_metadata_requests\u001b[39;00m \u001b[39mimport\u001b[39;00m _MetadataRequester\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_bunch\u001b[39;00m \u001b[39mimport\u001b[39;00m Bunch\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_estimator_html_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_param_validation\u001b[39;00m \u001b[39mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mclass_weight\u001b[39;00m \u001b[39mimport\u001b[39;00m compute_class_weight, compute_sample_weight\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeprecation\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mInvalidParameterError\u001b[39;00m(\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m     19\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config \u001b[39mas\u001b[39;00m _get_config\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning, NotFittedError, PositiveSpectrumWarning\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_array_api\u001b[39;00m \u001b[39mimport\u001b[39;00m _asarray_with_order, _is_numpy_namespace, get_namespace\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_isfinite\u001b[39;00m \u001b[39mimport\u001b[39;00m FiniteStatus, cy_isfinite\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m _object_dtype_isnan\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\_array_api.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mspecial\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m parse_version\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_array_api_dispatch\u001b[39m(array_api_dispatch):\n\u001b[0;32m     13\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that array_api_compat is installed and NumPy version is compatible.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[39m    array_api_compat follows NEP29, which has a higher minimum NumPy version than\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m    scikit-learn.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\fixes.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreadpoolctl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msklearn\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\__init__.py:608\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m \n\u001b[0;32m    604\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    606\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_warnings_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    607\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 608\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    609\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_variation\u001b[39;00m \u001b[39mimport\u001b[39;00m variation\n\u001b[0;32m    610\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\_stats_py.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mspecial\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m linalg\n\u001b[1;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m distributions\n\u001b[0;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _mstats_basic \u001b[39mas\u001b[39;00m mstats_basic\n\u001b[0;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_mstats_common\u001b[39;00m \u001b[39mimport\u001b[39;00m (_find_repeats, linregress, theilslopes,\n\u001b[0;32m     49\u001b[0m                                    siegelslopes)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\distributions.py:8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Author:  Travis Oliphant  2002-2011 with contributions from\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m#          SciPy Developers 2004-2011\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39m#       instead of `git blame -Lxxx,+x`.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_distn_infrastructure\u001b[39;00m \u001b[39mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _continuous_distns\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _discrete_distns\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\stats\\_distn_infrastructure.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m optimize\n\u001b[0;32m     25\u001b[0m \u001b[39m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m integrate\n\u001b[0;32m     28\u001b[0m \u001b[39m# to approximate the pdf of a continuous distribution given its cdf\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_finite_differences\u001b[39;00m \u001b[39mimport\u001b[39;00m _derivative\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1075\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\__init__.py:202\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(name):\n\u001b[0;32m    201\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m submodules:\n\u001b[1;32m--> 202\u001b[0m         \u001b[39mreturn\u001b[39;00m _importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mscipy.\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    203\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\integrate\\__init__.py:93\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m=============================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mIntegration and ODEs (:mod:`scipy.integrate`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39m   solve_bvp     -- Solve a boundary value problem for a system of ODEs.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m\"\"\"\u001b[39;00m  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_quadrature\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m---> 93\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_odepack_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_quadpack_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m     95\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_ode\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\scipy\\integrate\\_odepack_py.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39modeint\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _odepack\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m copy\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "X_A_train = dm.data_A.iloc[:, 2:]\n",
    "Y_A_train = dm.data_A.iloc[:, 1]\n",
    "\n",
    "X_B_train = dm.data_B.iloc[:, 2:]\n",
    "Y_B_train = dm.data_B.iloc[:, 1]\n",
    "\n",
    "X_C_train = dm.data_C.iloc[:, 2:]\n",
    "Y_C_train = dm.data_C.iloc[:, 1]\n",
    "\n",
    "X_A_test = dm.X_test_estimated_a[dm.X_test_estimated_a.columns.intersection(X_A_train.columns)]\n",
    "X_B_test = dm.X_test_estimated_b[dm.X_test_estimated_a.columns.intersection(X_A_train.columns)]\n",
    "X_C_test = dm.X_test_estimated_c[dm.X_test_estimated_a.columns.intersection(X_A_train.columns)]\n",
    "\n",
    "\n",
    "catModel_a = CatBoostRegressor()\n",
    "catModel_b = CatBoostRegressor()\n",
    "catModel_c = CatBoostRegressor()\n",
    "\n",
    "catModel_a.fit(X_A_train,Y_A_train)\n",
    "catModel_b.fit(X_B_train,Y_B_train)\n",
    "catModel_c.fit(X_C_train,Y_C_train)\n",
    "\n",
    "pred_A = catModel_a.predict(X_A_test)\n",
    "pred_B = catModel_b.predict(X_B_test)\n",
    "pred_C = catModel_c.predict(X_C_test)\n",
    "\n",
    "df_A = pd.DataFrame()\n",
    "\n",
    "df_A[\"predict\"] = pred_A\n",
    "df_A[\"location\"] = \"A\"\n",
    "\n",
    "df_B = pd.DataFrame()\n",
    "\n",
    "df_B[\"predict\"] = pred_B\n",
    "df_B[\"location\"] = \"B\"\n",
    "\n",
    "df_C = pd.DataFrame()\n",
    "\n",
    "df_C[\"predict\"] = pred_C\n",
    "df_C[\"location\"] = \"C\"\n",
    "\n",
    "df_mid = pd.concat([df_A, df_B], ignore_index=True)\n",
    "\n",
    "df = pd.concat([df_mid, df_C], join=\"inner\", ignore_index=True)\n",
    "\n",
    "df = df.drop(\"location\", axis=1)\n",
    "\n",
    "df[df<0] = 0\n",
    "\n",
    "# NAME THE FILE \n",
    "df.to_csv(\"./ext_preds/short_notebook_150.csv\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These predictions consisted of separate models for dataset A, B and C. Since these simple models performed well, we used them a lot for testing feature engineering and other data preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also experimented with iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catModel_a = CatBoostRegressor(iterations=10000)\n",
    "catModel_b = CatBoostRegressor(iterations=10000)\n",
    "catModel_c = CatBoostRegressor(iterations=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no luck.\n",
    "\n",
    "Additionally, we tried combining dataset B and C since they have very similar training data. The thought behind this is that we get more data to train on, and thus better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catModel_bc = CatBoostRegressor()\n",
    "\n",
    "X_BC_train = pd.concat([X_B_train, X_C_train])\n",
    "Y_BC_train = pd.concat([Y_B_train, Y_C_train])\n",
    "\n",
    "pred_B = catModel_bc.predict(X_B_test)\n",
    "pred_C = catModel_bc.predict(X_C_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generally led to worse results.\n",
    "\n",
    "Though a combined model for all 3 worked in some instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catModel_abc = CatBoostRegressor()\n",
    "\n",
    "X_BC_train = pd.concat([X_B_train, X_C_train])\n",
    "Y_BC_train = pd.concat([Y_B_train, Y_C_train])\n",
    "\n",
    "X_ABC_train = pd.concat([X_A_train, X_BC_train])\n",
    "Y_ABC_train = pd.concat([Y_A_train, Y_BC_train])\n",
    "\n",
    "catModel_abc.fit(X_ABC_train,Y_ABC_train)\n",
    "\n",
    "pred_A = catModel_abc.predict(X_A_test)\n",
    "pred_B = catModel_abc.predict(X_B_test)\n",
    "pred_C = catModel_abc.predict(X_C_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other regressor models were tested without any stacking or hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr_a = RandomForestRegressor()\n",
    "rfr_b = RandomForestRegressor()\n",
    "rfr_c = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_a = XGBRegressor()\n",
    "xgb_b = XGBRegressor()\n",
    "xgb_c = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "nn_a = MLPRegressor()\n",
    "nn_b = MLPRegressor()\n",
    "nn_c = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "gbm_a = lgb.LGBMRegressor()\n",
    "gbm_b = lgb.LGBMRegressor()\n",
    "gbm_c = lgb.LGBMRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But alone, these models didn't perform any better than catboost\n",
    "\n",
    "We also experimented with stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "import numpy as np\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "print(dm.data_A.columns)\n",
    "\n",
    "X_A_train = dm.data_A.iloc[:, 2:]\n",
    "Y_A_train = dm.data_A.iloc[:, 1]\n",
    "\n",
    "X_B_train = dm.data_B.iloc[:, 2:]\n",
    "Y_B_train = dm.data_B.iloc[:, 1]\n",
    "\n",
    "X_C_train = dm.data_C.iloc[:, 2:]\n",
    "Y_C_train = dm.data_C.iloc[:, 1]\n",
    "\n",
    "X_A_test = dm.X_test_estimated_a[dm.X_test_estimated_a.columns.intersection(X_A_train.columns)]\n",
    "X_B_test = dm.X_test_estimated_b[dm.X_test_estimated_a.columns.intersection(X_A_train.columns)]\n",
    "X_C_test = dm.X_test_estimated_c[dm.X_test_estimated_a.columns.intersection(X_A_train.columns)]\n",
    "\n",
    "#X_A_train['direct_rad:W_lag_12']\n",
    "\n",
    "# remove special characters from column names\n",
    "X_A_train.columns = X_A_train.columns.str.replace(':', '_')\n",
    "X_B_train.columns = X_B_train.columns.str.replace(':', '_')\n",
    "X_C_train.columns = X_C_train.columns.str.replace(':', '_')\n",
    "\n",
    "X_A_test.columns = X_A_test.columns.str.replace(':', '_')\n",
    "X_B_test.columns = X_B_test.columns.str.replace(':', '_')\n",
    "X_C_test.columns = X_C_test.columns.str.replace(':', '_')\n",
    "\n",
    "# meta models\n",
    "metaModel_a = LinearRegression()\n",
    "metaModel_b = LinearRegression()\n",
    "metaModel_c = LinearRegression()\n",
    "\n",
    "# stacking classifier\n",
    "stacking_model_a = StackingRegressor(\n",
    "    estimators=[('rfr', rfr_a), ('nn', nn_a), ('gbm', gbm_a)],\n",
    "    final_estimator=metaModel_a\n",
    ")\n",
    "\n",
    "stacking_model_b = StackingRegressor(\n",
    "    estimators=[('rfr', rfr_b), ('nn', nn_b), ('gbm', gbm_b)],\n",
    "    final_estimator=metaModel_b\n",
    ")\n",
    "\n",
    "stacking_model_c = StackingRegressor(\n",
    "    estimators=[('rfr', rfr_c), ('nn', nn_c), ('gbm', gbm_c)],\n",
    "    final_estimator=metaModel_c\n",
    ")\n",
    "\n",
    "# fit stacking models\n",
    "stacking_model_a.fit(X_A_train, Y_A_train)\n",
    "stacking_model_b.fit(X_B_train, Y_B_train)\n",
    "stacking_model_c.fit(X_C_train, Y_C_train)\n",
    "\n",
    "# preds for stacking models\n",
    "stacking_preds_a = stacking_model_a.predict(X_A_test)\n",
    "stacking_preds_b = stacking_model_b.predict(X_B_test)\n",
    "stacking_preds_c = stacking_model_c.predict(X_C_test)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking models with catboost gave us some promising results. We calculated the mae between stack predictions and older predictions to determine if the new models could be better.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "These stacks did not end up being better than our basic catboost model.\n",
    "\n",
    "We also tried calculating the mean between our best prediction and our stack models, which didnt work either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_A_new = np.mean([pred_a, stacking_preds_a], axis=0)\n",
    "pred_B_new = np.mean([pred_b, stacking_preds_b], axis=0)\n",
    "pred_C_new = np.mean([pred_c, stacking_preds_c], axis=0)\n",
    "\n",
    "df_A = pd.DataFrame()\n",
    "\n",
    "df_A[\"predict\"] = pred_A_new\n",
    "df_A[\"location\"] = \"A\"\n",
    "\n",
    "df_B = pd.DataFrame()\n",
    "\n",
    "df_B[\"predict\"] = pred_B_new\n",
    "df_B[\"location\"] = \"B\"\n",
    "\n",
    "df_C = pd.DataFrame()\n",
    "\n",
    "df_C[\"predict\"] = pred_C_new\n",
    "df_C[\"location\"] = \"C\"\n",
    "\n",
    "df_mid = pd.concat([df_A, df_B], ignore_index=True)\n",
    "\n",
    "df = pd.concat([df_mid, df_C], join=\"inner\", ignore_index=True)\n",
    "\n",
    "df = df.drop(\"location\", axis=1)\n",
    "\n",
    "df[df<0] = 0\n",
    "\n",
    "# NAME THE FILE \n",
    "df.to_csv(\"./ext_preds/stack_4.csv\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "To improve our models, we also tried a lot of hyperparameter tuning, where we experimented with different tools like Optuna, Scikit-Optimize and H2O. As Optuna worked pretty well, we included it in our pipeline for some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X = dm.data.iloc[:, 2:]\n",
    "y = dm.data.iloc[:, 1]\n",
    "\n",
    "\n",
    "X_A = dm.data_A.iloc[:, 2:-1]\n",
    "y_A = dm.data_A.iloc[:, 1]\n",
    "X_B = dm.data_B.iloc[:, 2:-1]\n",
    "y_B = dm.data_B.iloc[:, 1]\n",
    "X_C = dm.data_C.iloc[:, 2:-1]\n",
    "y_C = dm.data_C.iloc[:, 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, train_size=0.6, shuffle=False)\n",
    "\n",
    "X_A_train, X_A_test, y_A_train, y_A_test = train_test_split(X_A, y_A)\n",
    "X_A_validate, X_A_test, y_A_validate, y_A_test = train_test_split(X_A_test, y_A_test, train_size=0.5, shuffle=False)\n",
    "\n",
    "X_B_train, X_B_test, y_B_train, y_B_test = train_test_split(X_B, y_B)\n",
    "X_B_validate, X_B_test, y_B_validate, y_B_test = train_test_split(X_B_test, y_B_test, train_size=0.5, shuffle=False)\n",
    "\n",
    "X_C_train, X_C_test, y_C_train, y_C_test = train_test_split(X_C, y_C)\n",
    "X_C_validate, X_C_test, y_C_validate, y_C_test = train_test_split(X_C_test, y_C_test, train_size=0.5, shuffle=False)\n",
    "\n",
    "X_BC = dm.data[dm.data[\"location\"] != 0]\n",
    "\n",
    "y_BC = X_BC.iloc[:, 1]\n",
    "X_BC = X_BC.iloc[:, 2:]\n",
    "\n",
    "X_BC_train, X_BC_test, y_BC_train, y_BC_test = train_test_split(X_BC, y_BC, shuffle=False)\n",
    "X_BC_validate, X_BC_test, y_BC_validate, y_BC_test = train_test_split(X_BC_test, y_BC_test, train_size=0.5, shuffle=False)\n",
    "\n",
    "X_BC_submission = dm.X_test_estimated[dm.X_test_estimated[\"location\"] != 0].iloc[:, 1:]\n",
    "\n",
    "X_submission = dm.X_test_estimated[dm.X_test_estimated.columns.intersection(X.columns)]\n",
    "\n",
    "X_A_submission = dm.X_test_estimated_a[dm.X_test_estimated_a.columns.intersection(X_A.columns)]\n",
    "X_B_submission = dm.X_test_estimated_b[dm.X_test_estimated_b.columns.intersection(X_B.columns)]\n",
    "X_C_submission = dm.X_test_estimated_c[dm.X_test_estimated_c.columns.intersection(X_C.columns)]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_validate.shape, y_validate.shape, X_test.shape, y_test.shape, X_submission.shape)\n",
    "\n",
    "print(X_A_train.shape, y_A_train.shape, X_A_validate.shape, y_A_validate.shape, X_A_test.shape, y_A_test.shape, X_A_submission.shape)\n",
    "print(X_B_train.shape, y_B_train.shape, X_B_validate.shape, y_B_validate.shape, X_B_test.shape, y_B_test.shape, X_B_submission.shape)\n",
    "print(X_C_train.shape, y_C_train.shape, X_C_validate.shape, y_C_validate.shape, X_C_test.shape, y_C_test.shape, X_C_submission.shape)\n",
    "\n",
    "print(X_BC_train.shape, y_BC_train.shape, X_BC_validate.shape, y_BC_validate.shape, X_BC_test.shape, y_BC_test.shape, X_BC_submission.shape)\n",
    "\n",
    "X_BC_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from optuna.samplers import TPESampler\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"MAE\"]),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 16),\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\n",
    "            \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "        ),\n",
    "        #\"iterations\": trial.suggest_int(\"iterations\", 10, 1500),\n",
    "        \"random_seed\": 0,\n",
    "        \n",
    "    }\n",
    "\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    cb = CatBoostRegressor(**param)\n",
    "\n",
    "    cb.fit(X_train, y_train, eval_set=[(X_validate, y_validate)], verbose=0, early_stopping_rounds=100)\n",
    "\n",
    "    preds = cb.predict(X_test)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = mean_absolute_error(y_test, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "sampler = TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=100, timeout=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried optuna with different catboost variations. A combined model for A, B and C ended up giving us the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[I 2023-11-05 16:59:05,004] Trial 5 finished with value: 116.02466557883027 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.08555204354589313, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'iterations': 1190, 'bagging_temperature': 5.833922769277539}. Best is trial 5 with value: 116.02466557883027.\n",
    "\n",
    "# these params scored 150 \n",
    "# (\"cat\", CatBoostRegressor(**{'objective': 'MAE', 'colsample_bylevel': 0.08393035401844894, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 3.6491381658313076, \"random_seed\":0})),\n",
    "\n",
    "# [I 2023-11-05 22:37:34,489] Trial 20 finished with value: 161.77335724365003 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09961018030513795, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 5.755437017114945}. Best is trial 20 with value: 161.77335724365003.\n",
    "\n",
    "## DELETED FEATS \n",
    "\n",
    "## with validation split \n",
    "#[I 2023-11-06 10:05:05,399] Trial 26 finished with value: 165.8851952022578 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09930576154462276, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 26 with value: 165.8851952022578.\n",
    "#[I 2023-11-06 09:59:39,114] Trial 13 finished with value: 165.99023283160864 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09894236237775247, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 13 with value: 165.99023283160864.\n",
    "\n",
    "## DELETED FEATS + LAG FEATS - SUM RAD\n",
    "#[I 2023-11-06 14:18:01,581] Trial 26 finished with value: 165.43080979284372 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09922457244655024, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 26 with value: 165.43080979284372.\n",
    "#[I 2023-11-06 14:14:27,365] Trial 22 finished with value: 166.69347928436912 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.07845778545183921, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 22 with value: 166.69347928436912.\n",
    "\n",
    "\n",
    "## ALL FEATS + FE, NO LAG FEATS, BC DONATION AND REMOVING CONST INTERVALS (12/3)\n",
    "#[I 2023-11-06 18:47:26,359] Trial 12 finished with value: 169.74903878583473 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.07321108308140112, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9947382455838534}. Best is trial 12 with value: 169.74903878583473.\n",
    "#[I 2023-11-06 18:45:18,746] Trial 11 finished with value: 171.92396530956395 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.068755243871172, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9942926270291108}. Best is trial 11 with value: 171.92396530956395.\n",
    "#[I 2023-11-06 18:51:54,938] Trial 15 finished with value: 170.281074439894 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.08074887258271649, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 9.10570616951506}. Best is trial 12 with value: 169.74903878583473.\n",
    "\n",
    "\n",
    "# [I 2023-11-05 22:43:53,232] Trial 2 finished with value: 25.414357904741664 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.06927535477671466, 'depth': 14, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.10515029581800527}. Best is trial 2 with value: 25.414357904741664.\n",
    "\n",
    "# DELETED FEATS \n",
    "\n",
    "## Proper validation: \n",
    "#[I 2023-11-06 10:26:38,751] Trial 25 finished with value: 22.26772405170921 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09981161016617257, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5119008311351512}. Best is trial 25 with value: 22.26772405170921.\n",
    "#[I 2023-11-06 10:35:56,976] Trial 33 finished with value: 22.62602913068846 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.0953035979637657, 'depth': 14, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4988564621460619}. Best is trial 25 with value: 22.26772405170921.\n",
    "\n",
    "\n",
    "## DELETED FEATS + LAG FEATS - SUM RAD\n",
    "\n",
    "\n",
    "# [I 2023-11-05 23:01:43,697] Trial 12 finished with value: 22.37118032357372 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.06718168961955846, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3200703207067206}. Best is trial 12 with value: 22.37118032357372.\n",
    "\n",
    "# DELETED FEATS \n",
    "\n",
    "#proper validatioon \n",
    "#[I 2023-11-06 10:45:49,758] Trial 28 finished with value: 20.537135559921417 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09350538147690629, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 8.842124245488673}. Best is trial 28 with value: 20.537135559921417.\n",
    "#[I 2023-11-06 10:43:30,999] Trial 22 finished with value: 20.997127701375245 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.08944284279926223, 'depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 6.930004930966931}. Best is trial 22 with value: 20.997127701375245.\n",
    "#[I 2023-11-06 10:59:09,821] Trial 33 finished with value: 19.716058939096268 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09644126188381036, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9881316487405227}. Best is trial 33 with value: 19.716058939096268.\n",
    "#[I 2023-11-06 10:57:44,252] Trial 31 finished with value: 19.721968565815324 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09517386033361759, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9934480446809176}. Best is trial 31 with value: 19.721968565815324.\n",
    "#[I 2023-11-06 10:57:04,178] Trial 30 finished with value: 20.012184675834973 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09999890845914448, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.9877850694321213}. Best is trial 30 with value: 20.012184675834973.\n",
    "\n",
    "\n",
    "## ALL FEATS + FE, NO LAG FEATS, BC DONATION AND REMOVING CONST INTERVALS (20/3)\n",
    "#[I 2023-11-06 18:55:46,070] Trial 0 finished with value: 18.485309556165106 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09003451962386975, 'depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1912152898699087}. Best is trial 0 with value: 18.485309556165106.\n",
    "#[I 2023-11-06 19:16:42,672] Trial 3 finished with value: 17.818673155834432 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.0819245485589076, 'depth': 13, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 3 with value: 17.818673155834432.\n",
    "#[I 2023-11-06 19:16:46,131] Trial 4 finished with value: 20.735737001810563 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.03948636560626, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 3 with value: 17.818673155834432.\n",
    "\n",
    "\n",
    "#[I 2023-11-06 09:21:40,140] Trial 7 finished with value: 93.57082723599223 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.07021145849459196, 'depth': 15, 'boosting_type': 'Ordered', 'bootstrap_type': 'MVS'}. Best is trial 7 with value: 93.57082723599223.\n",
    "#[I 2023-11-06 09:18:27,362] Trial 6 finished with value: 104.18112832124598 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.07343258702862919, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 4 with value: 99.6739211164172.\n",
    "#[I 2023-11-06 09:18:19,613] Trial 4 finished with value: 99.6739211164172 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.05987187094961611, 'depth': 10, 'boosting_type': 'Ordered', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8627037092982467}. Best is trial 4 with value: 99.6739211164172.\n",
    "\n",
    "## PROPER VALIDATION \n",
    "# [I 2023-11-06 09:34:06,886] Trial 11 finished with value: 94.84395099535925 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.06788514856337621, 'depth': 9, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3089743943699958}. Best is trial 1 with value: 91.96302490499082.\n",
    "# [I 2023-11-06 09:34:12,735] Trial 12 finished with value: 90.99607534299506 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.06879424422985089, 'depth': 12, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1356440119309477}. Best is trial 12 with value: 90.99607534299506.\n",
    "# [I 2023-11-06 09:34:19,982] Trial 13 finished with value: 90.15040743548006 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.06831027771726123, 'depth': 13, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1059090481359448}. Best is trial 13 with value: 90.15040743548006.\n",
    "# [I 2023-11-06 09:34:49,324] Trial 14 finished with value: 85.26022828486518 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.0764308167143037, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.11317034357345056}. Best is trial 14 with value: 85.26022828486518.\n",
    "# [I 2023-11-06 09:36:04,025] Trial 15 finished with value: 81.02983953897846 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.08556050159260666, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.10142252384867761}. Best is trial 15 with value: 81.02983953897846.\n",
    "# USED THIS FOR SUB CATBOOST_13_SINGLE.CSV [I 2023-11-06 09:37:51,323] Trial 16 finished with value: 78.62797533658944 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09994261947773965, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3517029793822252}. Best is trial 16 with value: 78.62797533658944.\n",
    "# [I 2023-11-06 09:39:42,441] Trial 17 finished with value: 78.80238554236068 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09990666905586555, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.39528335187495645}. Best is trial 16 with value: 78.62797533658944.\n",
    "# [I 2023-11-06 09:40:12,070] Trial 18 finished with value: 82.74867457461298 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09991105102282588, 'depth': 14, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.44205347186589705}. Best is trial 16 with value: 78.62797533658944.\n",
    "# [I 2023-11-06 09:40:19,573] Trial 19 finished with value: 86.11596511811832 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.0993444194374076, 'depth': 11, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4163694923198905}. Best is trial 16 with value: 78.62797533658944.\n",
    "# [I 2023-11-06 09:40:24,566] Trial 20 finished with value: 95.64983586751998 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.08625070811470684, 'depth': 7, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5965498517007939}. Best is trial 16 with value: 78.62797533658944.\n",
    "# [I 2023-11-06 09:41:48,783] Trial 21 finished with value: 80.34018050497714 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.08828388798152162, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.29136732663727677}. Best is trial 16 with value: 78.62797533658944.\n",
    "# [I 2023-11-06 09:42:34,832] Trial 22 finished with value: 81.1204320957182 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.0918243857157667, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.35999148599335806}. Best is trial 16 with value: 78.62797533658944.\n",
    "# [I 2023-11-06 09:44:15,154] Trial 23 finished with value: 79.2280725426542 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09386351381323012, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.29478409296370756}. Best is trial 16 with value: 78.62797533658944.\n",
    "# [I 2023-11-06 09:44:42,818] Trial 24 finished with value: 81.19963365555299 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09997495410247971, 'depth': 14, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.4802613284856091}. Best is trial 16 with value: 78.62797533658944.\n",
    "# [I 2023-11-06 09:45:01,658] Trial 25 finished with value: 85.19633893372021 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.07924963444764457, 'depth': 14, 'boosting_type': 'Plain', 'bootstrap_type': 'MVS'}. Best is trial 16 with value: 78.62797533658944.\n",
    "\n",
    "## DELETED FEATS + LAG FEATS - SUM RAD\n",
    "# USED THIS FOR SUB CATBOOST_14_SINGLE.CSV [I 2023-11-06 16:04:47,625] Trial 41 finished with value: 83.411573402198 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09618156200475811, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.21387042043411192}. Best is trial 41 with value: 83.411573402198.\n",
    "# [I 2023-11-06 15:44:49,977] Trial 30 finished with value: 83.51429978562304 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09926156367081514, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.271617400472478}. Best is trial 30 with value: 83.51429978562304.\n",
    "# [I 2023-11-06 15:29:27,387] Trial 24 finished with value: 84.02207338155672 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09850904799670648, 'depth': 15, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.2994539222163096}. Best is trial 24 with value: 84.02207338155672.\n",
    "\n",
    "## ALL FEATS + FE, NO LAG FEATS, BC DONATION AND REMOVING CONST INTERVALS (20/3)\n",
    "#[I 2023-11-06 21:22:41,277] Trial 18 finished with value: 19.06275303157211 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.08101231188824651, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.1203886158980404}. Best is trial 18 with value: 19.06275303157211.\n",
    "#[I 2023-11-06 21:25:20,073] Trial 21 finished with value: 19.02159924912772 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.07731293544992492, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.3756198315698245}. Best is trial 21 with value: 19.02159924912772.\n",
    "#[I 2023-11-06 21:30:31,243] Trial 25 finished with value: 18.844086323227387 and parameters: {'objective': 'MAE', 'colsample_bylevel': 0.09981161016617257, 'depth': 16, 'boosting_type': 'Plain', 'bootstrap_type': 'Bernoulli', 'subsample': 0.5119008311351512}. Best is trial 25 with value: 18.844086323227387.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on summer months exclusively\n",
    "Since we are doing predictions on summer months solely, we had an idea to try and remove all training data for other seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_month(df: pd.DataFrame, months: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter a dataframe by keeping only rows where the 'date_forecast' column is within the specified months.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The dataframe to filter.\n",
    "    months (list[str]): A list of months to keep, in the format 'MM'.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The filtered dataframe.\n",
    "    \"\"\"\n",
    "    return df[df['date_forecast'].dt.strftime('%m').isin(months)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import filter_by_month\n",
    "\n",
    "dml.data_A = filter_by_month(dml.data_A, ['04','05','06','07'])\n",
    "dml.data_B = filter_by_month(dml.data_B, ['04','05','06','07'])\n",
    "dml.data_C = filter_by_month(dml.data_C, ['04','05','06','07'])\n",
    "%store dml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this did not improve the score. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
